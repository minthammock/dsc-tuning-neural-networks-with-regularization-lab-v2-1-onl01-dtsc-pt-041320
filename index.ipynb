{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df_sample['Product']\n",
    "X = df_sample['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 2000)\n",
    "tokenizer.fit_on_texts(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode = 'binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode = 'binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final), 7)[:,:,1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val),7)[:,:,1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test),7)[:,:,1]\n",
    "y_test_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.4952 - accuracy: 0.5275 - val_loss: 1.4947 - val_accuracy: 0.5100\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.4447 - accuracy: 0.5525 - val_loss: 1.4439 - val_accuracy: 0.5460\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 1.3937 - accuracy: 0.5796 - val_loss: 1.3971 - val_accuracy: 0.5800\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 1.3428 - accuracy: 0.6036 - val_loss: 1.3468 - val_accuracy: 0.5930\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 1.2940 - accuracy: 0.6187 - val_loss: 1.3013 - val_accuracy: 0.6160\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 1s 111us/step - loss: 1.2459 - accuracy: 0.6367 - val_loss: 1.2550 - val_accuracy: 0.6250\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 1.1997 - accuracy: 0.6492 - val_loss: 1.2126 - val_accuracy: 0.6350\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 1.1561 - accuracy: 0.6624 - val_loss: 1.1716 - val_accuracy: 0.6440\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 1s 113us/step - loss: 1.1147 - accuracy: 0.6744 - val_loss: 1.1315 - val_accuracy: 0.6580\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 1s 105us/step - loss: 1.0751 - accuracy: 0.6839 - val_loss: 1.0961 - val_accuracy: 0.6760\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.0385 - accuracy: 0.6959 - val_loss: 1.0617 - val_accuracy: 0.6720\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.0037 - accuracy: 0.7027 - val_loss: 1.0335 - val_accuracy: 0.6730\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 1s 100us/step - loss: 0.9716 - accuracy: 0.7071 - val_loss: 1.0029 - val_accuracy: 0.6860\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.9414 - accuracy: 0.7168 - val_loss: 0.9743 - val_accuracy: 0.6890s: 0.9411 - accuracy: 0.\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.9137 - accuracy: 0.7228 - val_loss: 0.9482 - val_accuracy: 0.7020\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.8879 - accuracy: 0.7273 - val_loss: 0.9248 - val_accuracy: 0.7060\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 1s 110us/step - loss: 0.8638 - accuracy: 0.7332 - val_loss: 0.9045 - val_accuracy: 0.7030\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.8416 - accuracy: 0.7355 - val_loss: 0.8872 - val_accuracy: 0.7060\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.8210 - accuracy: 0.7393 - val_loss: 0.8672 - val_accuracy: 0.7080\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.8021 - accuracy: 0.7433 - val_loss: 0.8496 - val_accuracy: 0.7180\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.7844 - accuracy: 0.7471 - val_loss: 0.8364 - val_accuracy: 0.7140\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.7681 - accuracy: 0.7507 - val_loss: 0.8244 - val_accuracy: 0.7160\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 1s 119us/step - loss: 0.7531 - accuracy: 0.7540 - val_loss: 0.8111 - val_accuracy: 0.7200\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 1s 110us/step - loss: 0.7389 - accuracy: 0.7548 - val_loss: 0.7979 - val_accuracy: 0.7260\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 0.7253 - accuracy: 0.7595 - val_loss: 0.7844 - val_accuracy: 0.7290\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 0.7129 - accuracy: 0.7631 - val_loss: 0.7765 - val_accuracy: 0.7260\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 1s 96us/step - loss: 0.7012 - accuracy: 0.7655 - val_loss: 0.7751 - val_accuracy: 0.7180\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 1s 121us/step - loss: 0.6905 - accuracy: 0.7685 - val_loss: 0.7610 - val_accuracy: 0.7310\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 0.6803 - accuracy: 0.7693 - val_loss: 0.7552 - val_accuracy: 0.7240\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 0.6704 - accuracy: 0.7707 - val_loss: 0.7451 - val_accuracy: 0.7320\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.6612 - accuracy: 0.7757 - val_loss: 0.7382 - val_accuracy: 0.7390 loss: 0.6574 - accura\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 1s 118us/step - loss: 0.6523 - accuracy: 0.7787 - val_loss: 0.7349 - val_accuracy: 0.7330\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 1s 122us/step - loss: 0.6443 - accuracy: 0.7803 - val_loss: 0.7232 - val_accuracy: 0.7390\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 0.6360 - accuracy: 0.7831 - val_loss: 0.7238 - val_accuracy: 0.7320\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.6286 - accuracy: 0.7860 - val_loss: 0.7159 - val_accuracy: 0.7390\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.6210 - accuracy: 0.7883 - val_loss: 0.7160 - val_accuracy: 0.7330\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.6145 - accuracy: 0.7896 - val_loss: 0.7078 - val_accuracy: 0.7370\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.6071 - accuracy: 0.7917 - val_loss: 0.7018 - val_accuracy: 0.7450\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.6006 - accuracy: 0.7961 - val_loss: 0.6991 - val_accuracy: 0.7500\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5950 - accuracy: 0.7972 - val_loss: 0.6982 - val_accuracy: 0.7420\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.5886 - accuracy: 0.8011 - val_loss: 0.6927 - val_accuracy: 0.7420\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.5825 - accuracy: 0.8012 - val_loss: 0.6862 - val_accuracy: 0.7490\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.5767 - accuracy: 0.8061 - val_loss: 0.6844 - val_accuracy: 0.7470\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.5715 - accuracy: 0.8067 - val_loss: 0.6820 - val_accuracy: 0.7470\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.5657 - accuracy: 0.8085 - val_loss: 0.6851 - val_accuracy: 0.7370\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 1s 99us/step - loss: 0.5610 - accuracy: 0.8105 - val_loss: 0.6791 - val_accuracy: 0.7460\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.5555 - accuracy: 0.8124 - val_loss: 0.6769 - val_accuracy: 0.7450\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5506 - accuracy: 0.8157 - val_loss: 0.6704 - val_accuracy: 0.7510\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.5455 - accuracy: 0.8175 - val_loss: 0.6713 - val_accuracy: 0.7520\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 0.5405 - accuracy: 0.8184 - val_loss: 0.6672 - val_accuracy: 0.7580\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.5356 - accuracy: 0.8193 - val_loss: 0.6655 - val_accuracy: 0.7540\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 1s 105us/step - loss: 0.5313 - accuracy: 0.8215 - val_loss: 0.6633 - val_accuracy: 0.7580\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.5273 - accuracy: 0.8237 - val_loss: 0.6615 - val_accuracy: 0.7470\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 0.5222 - accuracy: 0.8263 - val_loss: 0.6582 - val_accuracy: 0.7580\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 0.5178 - accuracy: 0.8256 - val_loss: 0.6574 - val_accuracy: 0.7520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5137 - accuracy: 0.8280 - val_loss: 0.6591 - val_accuracy: 0.7520\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.5095 - accuracy: 0.8297 - val_loss: 0.6588 - val_accuracy: 0.7540\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.5055 - accuracy: 0.8311 - val_loss: 0.6544 - val_accuracy: 0.7510\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.5014 - accuracy: 0.8324 - val_loss: 0.6576 - val_accuracy: 0.7470\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4974 - accuracy: 0.8355 - val_loss: 0.6507 - val_accuracy: 0.7550\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4935 - accuracy: 0.8355 - val_loss: 0.6488 - val_accuracy: 0.7570\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.4894 - accuracy: 0.8383 - val_loss: 0.6487 - val_accuracy: 0.7560\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 0.4853 - accuracy: 0.8385 - val_loss: 0.6488 - val_accuracy: 0.7550\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 1s 119us/step - loss: 0.4817 - accuracy: 0.8415 - val_loss: 0.6507 - val_accuracy: 0.7550\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 1s 111us/step - loss: 0.4781 - accuracy: 0.8397 - val_loss: 0.6463 - val_accuracy: 0.7580\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 0.4744 - accuracy: 0.8415 - val_loss: 0.6495 - val_accuracy: 0.7520\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4709 - accuracy: 0.8428 - val_loss: 0.6480 - val_accuracy: 0.7520\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4672 - accuracy: 0.8439 - val_loss: 0.6457 - val_accuracy: 0.7540\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.4633 - accuracy: 0.8468 - val_loss: 0.6442 - val_accuracy: 0.7590\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4602 - accuracy: 0.8484 - val_loss: 0.6469 - val_accuracy: 0.7480\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4568 - accuracy: 0.8479 - val_loss: 0.6446 - val_accuracy: 0.7620\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4531 - accuracy: 0.8508 - val_loss: 0.6422 - val_accuracy: 0.7630\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4497 - accuracy: 0.8515 - val_loss: 0.6437 - val_accuracy: 0.7630\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4460 - accuracy: 0.8539 - val_loss: 0.6433 - val_accuracy: 0.7570\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4427 - accuracy: 0.8539 - val_loss: 0.6408 - val_accuracy: 0.7610\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 1s 106us/step - loss: 0.4395 - accuracy: 0.8575 - val_loss: 0.6420 - val_accuracy: 0.7640\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 1s 118us/step - loss: 0.4364 - accuracy: 0.8559 - val_loss: 0.6402 - val_accuracy: 0.7600\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4331 - accuracy: 0.8568 - val_loss: 0.6412 - val_accuracy: 0.7600\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4295 - accuracy: 0.8589 - val_loss: 0.6388 - val_accuracy: 0.7640\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4269 - accuracy: 0.8617 - val_loss: 0.6398 - val_accuracy: 0.7580\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.4232 - accuracy: 0.8604 - val_loss: 0.6365 - val_accuracy: 0.7640\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4201 - accuracy: 0.8624 - val_loss: 0.6465 - val_accuracy: 0.7570\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 1s 108us/step - loss: 0.4172 - accuracy: 0.8633 - val_loss: 0.6409 - val_accuracy: 0.7650\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4145 - accuracy: 0.8644 - val_loss: 0.6416 - val_accuracy: 0.7590\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4109 - accuracy: 0.8656 - val_loss: 0.6370 - val_accuracy: 0.7620\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4076 - accuracy: 0.8675 - val_loss: 0.6362 - val_accuracy: 0.7600\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4048 - accuracy: 0.8680 - val_loss: 0.6392 - val_accuracy: 0.7550\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4019 - accuracy: 0.8692 - val_loss: 0.6399 - val_accuracy: 0.7580\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3991 - accuracy: 0.8699 - val_loss: 0.6359 - val_accuracy: 0.7590\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3960 - accuracy: 0.8727 - val_loss: 0.6385 - val_accuracy: 0.7570\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3930 - accuracy: 0.8737 - val_loss: 0.6392 - val_accuracy: 0.7600\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.3901 - accuracy: 0.8759 - val_loss: 0.6406 - val_accuracy: 0.7570\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3871 - accuracy: 0.8737 - val_loss: 0.6403 - val_accuracy: 0.7590\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.3845 - accuracy: 0.8763 - val_loss: 0.6436 - val_accuracy: 0.7580\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.3816 - accuracy: 0.8769 - val_loss: 0.6388 - val_accuracy: 0.7530\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 0.3788 - accuracy: 0.8787 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 0.3760 - accuracy: 0.8796 - val_loss: 0.6388 - val_accuracy: 0.7590\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.3731 - accuracy: 0.8809 - val_loss: 0.6397 - val_accuracy: 0.7550\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.3707 - accuracy: 0.8823 - val_loss: 0.6405 - val_accuracy: 0.7570\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 1s 108us/step - loss: 0.3678 - accuracy: 0.8817 - val_loss: 0.6418 - val_accuracy: 0.7560\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 1s 106us/step - loss: 0.3652 - accuracy: 0.8821 - val_loss: 0.6440 - val_accuracy: 0.7530\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3623 - accuracy: 0.8835 - val_loss: 0.6408 - val_accuracy: 0.7590\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 1s 113us/step - loss: 0.3603 - accuracy: 0.8865 - val_loss: 0.6418 - val_accuracy: 0.7550\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3572 - accuracy: 0.8860 - val_loss: 0.6416 - val_accuracy: 0.7570\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3550 - accuracy: 0.8877 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.3522 - accuracy: 0.8883 - val_loss: 0.6421 - val_accuracy: 0.7620\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3497 - accuracy: 0.8895 - val_loss: 0.6415 - val_accuracy: 0.7580\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.3469 - accuracy: 0.8907 - val_loss: 0.6494 - val_accuracy: 0.7550\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3443 - accuracy: 0.8908 - val_loss: 0.6413 - val_accuracy: 0.7550\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3417 - accuracy: 0.8917 - val_loss: 0.6486 - val_accuracy: 0.7530\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3394 - accuracy: 0.8932 - val_loss: 0.6433 - val_accuracy: 0.7610\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3366 - accuracy: 0.8944 - val_loss: 0.6457 - val_accuracy: 0.7580\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3342 - accuracy: 0.8945 - val_loss: 0.6446 - val_accuracy: 0.7620\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.3326 - accuracy: 0.8960 - val_loss: 0.6500 - val_accuracy: 0.7560\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.3298 - accuracy: 0.8987 - val_loss: 0.6525 - val_accuracy: 0.7570\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3274 - accuracy: 0.8983 - val_loss: 0.6454 - val_accuracy: 0.7630\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3249 - accuracy: 0.9001 - val_loss: 0.6540 - val_accuracy: 0.7570\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.90 - 1s 73us/step - loss: 0.3224 - accuracy: 0.9007 - val_loss: 0.6497 - val_accuracy: 0.7610\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3201 - accuracy: 0.9020 - val_loss: 0.6480 - val_accuracy: 0.7610\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 1s 98us/step - loss: 0.3178 - accuracy: 0.9029 - val_loss: 0.6526 - val_accuracy: 0.7570\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 1s 113us/step - loss: 0.3160 - accuracy: 0.9027 - val_loss: 0.6493 - val_accuracy: 0.7610\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 0.3134 - accuracy: 0.9028 - val_loss: 0.6517 - val_accuracy: 0.7600\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 1s 110us/step - loss: 0.3108 - accuracy: 0.9049 - val_loss: 0.6522 - val_accuracy: 0.7570\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 0.3096 - accuracy: 0.9056 - val_loss: 0.6512 - val_accuracy: 0.7600\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 1s 118us/step - loss: 0.3067 - accuracy: 0.9083 - val_loss: 0.6581 - val_accuracy: 0.7570\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 1s 108us/step - loss: 0.3050 - accuracy: 0.9061 - val_loss: 0.6558 - val_accuracy: 0.7600\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3028 - accuracy: 0.9083 - val_loss: 0.6528 - val_accuracy: 0.7580\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3005 - accuracy: 0.9099 - val_loss: 0.6582 - val_accuracy: 0.7590\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 0.2982 - accuracy: 0.9111 - val_loss: 0.6530 - val_accuracy: 0.7620\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 1s 109us/step - loss: 0.2961 - accuracy: 0.9101 - val_loss: 0.6593 - val_accuracy: 0.7540\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.9099 ETA: 0s - loss: 0.2960 - accuracy - 1s 102us/step - loss: 0.2941 - accuracy: 0.9103 - val_loss: 0.6553 - val_accuracy: 0.7600\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 1s 96us/step - loss: 0.2922 - accuracy: 0.9117 - val_loss: 0.6561 - val_accuracy: 0.7570\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 1s 124us/step - loss: 0.2897 - accuracy: 0.9137 - val_loss: 0.6586 - val_accuracy: 0.7620\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 1s 99us/step - loss: 0.2878 - accuracy: 0.9160 - val_loss: 0.6656 - val_accuracy: 0.7570\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 1s 108us/step - loss: 0.2860 - accuracy: 0.9133 - val_loss: 0.6575 - val_accuracy: 0.7600\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 1s 108us/step - loss: 0.2841 - accuracy: 0.9149 - val_loss: 0.6596 - val_accuracy: 0.7570\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.2818 - accuracy: 0.9153 - val_loss: 0.6642 - val_accuracy: 0.7580\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.2797 - accuracy: 0.9165 - val_loss: 0.6603 - val_accuracy: 0.7650\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.2779 - accuracy: 0.9175 - val_loss: 0.6644 - val_accuracy: 0.7590\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 1s 105us/step - loss: 0.2757 - accuracy: 0.9172 - val_loss: 0.6635 - val_accuracy: 0.7580\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.2737 - accuracy: 0.9183 - val_loss: 0.6639 - val_accuracy: 0.7550\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.2717 - accuracy: 0.9193 - val_loss: 0.6678 - val_accuracy: 0.7570\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 0.2703 - accuracy: 0.9203 - val_loss: 0.6783 - val_accuracy: 0.7590\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 1s 123us/step - loss: 0.2686 - accuracy: 0.9200 - val_loss: 0.6709 - val_accuracy: 0.7600\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.2665 - accuracy: 0.9227 - val_loss: 0.6747 - val_accuracy: 0.7590\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 1s 97us/step - loss: 0.2645 - accuracy: 0.9217 - val_loss: 0.6736 - val_accuracy: 0.7590\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 0.2628 - accuracy: 0.9251 - val_loss: 0.6717 - val_accuracy: 0.7570\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 0.2606 - accuracy: 0.9241 - val_loss: 0.6752 - val_accuracy: 0.7560\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 1s 100us/step - loss: 0.2585 - accuracy: 0.9235 - val_loss: 0.6760 - val_accuracy: 0.7570\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 0.2574 - accuracy: 0.9245 - val_loss: 0.6731 - val_accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(\n",
    "    x = X_train_tokens,\n",
    "    y = y_train_lb,\n",
    "    batch_size = 256,\n",
    "    epochs=150,\n",
    "    validation_data=(X_val_tokens,y_val_lb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.494714</td>\n",
       "      <td>0.510</td>\n",
       "      <td>1.495176</td>\n",
       "      <td>0.527467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.443945</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.444709</td>\n",
       "      <td>0.552533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.397111</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.393695</td>\n",
       "      <td>0.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.346769</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.342842</td>\n",
       "      <td>0.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.301340</td>\n",
       "      <td>0.616</td>\n",
       "      <td>1.294007</td>\n",
       "      <td>0.618667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.673621</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.264510</td>\n",
       "      <td>0.921733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.671715</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.262763</td>\n",
       "      <td>0.925067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.675156</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.260550</td>\n",
       "      <td>0.924133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.675981</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.258529</td>\n",
       "      <td>0.923467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.673052</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.257350</td>\n",
       "      <td>0.924533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss  val_accuracy      loss  accuracy\n",
       "0    1.494714         0.510  1.495176  0.527467\n",
       "1    1.443945         0.546  1.444709  0.552533\n",
       "2    1.397111         0.580  1.393695  0.579600\n",
       "3    1.346769         0.593  1.342842  0.603600\n",
       "4    1.301340         0.616  1.294007  0.618667\n",
       "..        ...           ...       ...       ...\n",
       "145  0.673621         0.759  0.264510  0.921733\n",
       "146  0.671715         0.757  0.262763  0.925067\n",
       "147  0.675156         0.756  0.260550  0.924133\n",
       "148  0.675981         0.757  0.258529  0.923467\n",
       "149  0.673052         0.760  0.257350  0.924533\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "df = pd.DataFrame().from_dict(baseline_model_val.history)\n",
    "\n",
    "# Print the keys\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 61us/step\n",
      "----------\n",
      "Training Loss: 0.255 \n",
      "Training Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(\n",
    "    x = X_train_tokens,\n",
    "    y = y_train_lb\n",
    ")\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 55us/step\n",
      "----------\n",
      "Test Loss: 0.617 \n",
      "Test Accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(\n",
    "    x = X_test_tokens,\n",
    "    y = y_test_lb\n",
    ")\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0,\n",
    "    patience = 10,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.5050 - acc: 0.8316 - val_loss: 0.6622 - val_acc: 0.7470\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.5029 - acc: 0.8316 - val_loss: 0.6620 - val_acc: 0.7450\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.5010 - acc: 0.8320 - val_loss: 0.6614 - val_acc: 0.7470\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 1s 111us/step - loss: 0.4988 - acc: 0.8325 - val_loss: 0.6632 - val_acc: 0.7490\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 0.4966 - acc: 0.8351 - val_loss: 0.6605 - val_acc: 0.7450\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4947 - acc: 0.8359 - val_loss: 0.6601 - val_acc: 0.7480\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 1s 110us/step - loss: 0.4924 - acc: 0.8363 - val_loss: 0.6611 - val_acc: 0.7530\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 0.4904 - acc: 0.8381 - val_loss: 0.6594 - val_acc: 0.7530\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.4887 - acc: 0.838 - 1s 82us/step - loss: 0.4886 - acc: 0.8385 - val_loss: 0.6573 - val_acc: 0.7490\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 0.4864 - acc: 0.8385 - val_loss: 0.6584 - val_acc: 0.7540\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4847 - acc: 0.8389 - val_loss: 0.6560 - val_acc: 0.7510\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4828 - acc: 0.8404 - val_loss: 0.6551 - val_acc: 0.7540\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4807 - acc: 0.8415 - val_loss: 0.6574 - val_acc: 0.7520\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 0.4788 - acc: 0.8403 - val_loss: 0.6556 - val_acc: 0.7530\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4768 - acc: 0.8412 - val_loss: 0.6538 - val_acc: 0.7540\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4749 - acc: 0.8429 - val_loss: 0.6532 - val_acc: 0.7520\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4731 - acc: 0.8431 - val_loss: 0.6525 - val_acc: 0.7500\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4714 - acc: 0.8457 - val_loss: 0.6527 - val_acc: 0.7530\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4691 - acc: 0.8455 - val_loss: 0.6562 - val_acc: 0.7560\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4673 - acc: 0.8451 - val_loss: 0.6538 - val_acc: 0.7540\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.4654 - acc: 0.8476 - val_loss: 0.6529 - val_acc: 0.7520\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.4643 - acc: 0.846 - 0s 66us/step - loss: 0.4639 - acc: 0.8469 - val_loss: 0.6515 - val_acc: 0.7570\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 1s 96us/step - loss: 0.4619 - acc: 0.8476 - val_loss: 0.6511 - val_acc: 0.7530\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4601 - acc: 0.8488 - val_loss: 0.6523 - val_acc: 0.7540\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4584 - acc: 0.8496 - val_loss: 0.6519 - val_acc: 0.7540\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4562 - acc: 0.8496 - val_loss: 0.6481 - val_acc: 0.7600\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.4549 - acc: 0.8492 - val_loss: 0.6505 - val_acc: 0.7560\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4527 - acc: 0.8511 - val_loss: 0.6480 - val_acc: 0.7600\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4510 - acc: 0.8508 - val_loss: 0.6503 - val_acc: 0.7520\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.4493 - acc: 0.8524 - val_loss: 0.6470 - val_acc: 0.7550\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4478 - acc: 0.8537 - val_loss: 0.6498 - val_acc: 0.7600\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.4460 - acc: 0.8523 - val_loss: 0.6482 - val_acc: 0.7550\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4440 - acc: 0.8544 - val_loss: 0.6487 - val_acc: 0.7530\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4422 - acc: 0.8537 - val_loss: 0.6473 - val_acc: 0.7560\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.4405 - acc: 0.8557 - val_loss: 0.6482 - val_acc: 0.7560\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4389 - acc: 0.8568 - val_loss: 0.6488 - val_acc: 0.7560\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.4372 - acc: 0.8575 - val_loss: 0.6471 - val_acc: 0.7580\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4355 - acc: 0.8583 - val_loss: 0.6463 - val_acc: 0.7550\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4340 - acc: 0.8577 - val_loss: 0.6461 - val_acc: 0.7560\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4320 - acc: 0.8577 - val_loss: 0.6460 - val_acc: 0.7580\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4305 - acc: 0.8599 - val_loss: 0.6458 - val_acc: 0.7520\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4287 - acc: 0.8609 - val_loss: 0.6463 - val_acc: 0.7540\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4273 - acc: 0.8604 - val_loss: 0.6486 - val_acc: 0.7570\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 0.4257 - acc: 0.8624 - val_loss: 0.6471 - val_acc: 0.7600\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4243 - acc: 0.8616 - val_loss: 0.6478 - val_acc: 0.7550\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4223 - acc: 0.8636 - val_loss: 0.6453 - val_acc: 0.7540\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 0.4205 - acc: 0.8643 - val_loss: 0.6460 - val_acc: 0.7560\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4192 - acc: 0.8651 - val_loss: 0.6466 - val_acc: 0.7560\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4178 - acc: 0.8659 - val_loss: 0.6455 - val_acc: 0.7580\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.4161 - acc: 0.8660 - val_loss: 0.6456 - val_acc: 0.7530\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4147 - acc: 0.8645 - val_loss: 0.6463 - val_acc: 0.7500\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4127 - acc: 0.8663 - val_loss: 0.6446 - val_acc: 0.7520\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.4113 - acc: 0.8685 - val_loss: 0.6484 - val_acc: 0.7570\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4101 - acc: 0.8681 - val_loss: 0.6467 - val_acc: 0.7570\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 0.4081 - acc: 0.8691 - val_loss: 0.6483 - val_acc: 0.7540\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 0.4067 - acc: 0.8695 - val_loss: 0.6465 - val_acc: 0.7570\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 0.4055 - acc: 0.8699 - val_loss: 0.6469 - val_acc: 0.7530\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.4038 - acc: 0.8723 - val_loss: 0.6481 - val_acc: 0.7560\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4024 - acc: 0.8708 - val_loss: 0.6469 - val_acc: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4006 - acc: 0.8728 - val_loss: 0.6459 - val_acc: 0.7560\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3994 - acc: 0.8735 - val_loss: 0.6461 - val_acc: 0.7510\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3976 - acc: 0.8740 - val_loss: 0.6468 - val_acc: 0.7550\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(\n",
    "    x = X_train_tokens, \n",
    "    y=y_train_lb, \n",
    "    batch_size=512, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping], \n",
    "    validation_data=(X_val_tokens,y_val_lb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 57us/step\n",
      "Training Loss: 0.411 \n",
      "Training Accuracy: 0.868\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 77us/step\n",
      "Test Loss: 0.602 \n",
      "Test Accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "results_train = model_2.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = model_2.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 134us/step - loss: 2.6197 - acc: 0.1749 - val_loss: 2.6122 - val_acc: 0.1580\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2.5945 - acc: 0.1767 - val_loss: 2.5930 - val_acc: 0.1650\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 2.5774 - acc: 0.1837 - val_loss: 2.5783 - val_acc: 0.1700\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 2.5633 - acc: 0.1967 - val_loss: 2.5656 - val_acc: 0.1830\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2.5503 - acc: 0.2084 - val_loss: 2.5535 - val_acc: 0.1920\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 2.5377 - acc: 0.2217 - val_loss: 2.5414 - val_acc: 0.2110\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 2.5247 - acc: 0.2333 - val_loss: 2.5288 - val_acc: 0.2220\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2.5111 - acc: 0.2429 - val_loss: 2.5155 - val_acc: 0.2280\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2.4970 - acc: 0.2551 - val_loss: 2.5016 - val_acc: 0.2440\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 2.4820 - acc: 0.2665 - val_loss: 2.4870 - val_acc: 0.2590\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 2.4663 - acc: 0.2740 - val_loss: 2.4717 - val_acc: 0.2700\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 1s 100us/step - loss: 2.4496 - acc: 0.2857 - val_loss: 2.4553 - val_acc: 0.2770\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 2.4321 - acc: 0.2955 - val_loss: 2.4384 - val_acc: 0.2850\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 2.4138 - acc: 0.3031 - val_loss: 2.4206 - val_acc: 0.2940\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.3947 - acc: 0.3135 - val_loss: 2.4020 - val_acc: 0.3000\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 2.3749 - acc: 0.3257 - val_loss: 2.3827 - val_acc: 0.3090\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 2.3545 - acc: 0.3329 - val_loss: 2.3626 - val_acc: 0.3140\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2.3335 - acc: 0.3415 - val_loss: 2.3415 - val_acc: 0.3220\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 2.3120 - acc: 0.3505 - val_loss: 2.3201 - val_acc: 0.3310\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 2.2900 - acc: 0.3569 - val_loss: 2.2977 - val_acc: 0.3470\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 2.2675 - acc: 0.3692 - val_loss: 2.2755 - val_acc: 0.3520\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.2447 - acc: 0.3769 - val_loss: 2.2526 - val_acc: 0.3660\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.2215 - acc: 0.3897 - val_loss: 2.2296 - val_acc: 0.3770\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1980 - acc: 0.3961 - val_loss: 2.2062 - val_acc: 0.3880\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 2.1743 - acc: 0.4127 - val_loss: 2.1826 - val_acc: 0.4040\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 2.1503 - acc: 0.4205 - val_loss: 2.1592 - val_acc: 0.4170\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 2.1263 - acc: 0.4357 - val_loss: 2.1355 - val_acc: 0.4350\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.1023 - acc: 0.4496 - val_loss: 2.1120 - val_acc: 0.4420\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 2.0784 - acc: 0.4623 - val_loss: 2.0882 - val_acc: 0.4630\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.0545 - acc: 0.4800 - val_loss: 2.0652 - val_acc: 0.4720\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 2.0310 - acc: 0.4943 - val_loss: 2.0419 - val_acc: 0.4880\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2.0078 - acc: 0.5140 - val_loss: 2.0196 - val_acc: 0.5030\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9847 - acc: 0.5288 - val_loss: 1.9968 - val_acc: 0.5160\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9620 - acc: 0.5459 - val_loss: 1.9745 - val_acc: 0.5370\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.9397 - acc: 0.5568 - val_loss: 1.9526 - val_acc: 0.5490\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.9177 - acc: 0.5700 - val_loss: 1.9313 - val_acc: 0.5540\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.8959 - acc: 0.5817 - val_loss: 1.9102 - val_acc: 0.5620\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.8748 - acc: 0.5920 - val_loss: 1.8899 - val_acc: 0.5700\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.8539 - acc: 0.6033 - val_loss: 1.8695 - val_acc: 0.5770\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.8335 - acc: 0.6124 - val_loss: 1.8495 - val_acc: 0.5810\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.8134 - acc: 0.6212 - val_loss: 1.8307 - val_acc: 0.5900\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.7939 - acc: 0.6273 - val_loss: 1.8116 - val_acc: 0.5970\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.7746 - acc: 0.6361 - val_loss: 1.7934 - val_acc: 0.6040\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 1.7561 - acc: 0.6419 - val_loss: 1.7749 - val_acc: 0.6140\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.7377 - acc: 0.6484 - val_loss: 1.7579 - val_acc: 0.6190\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.7199 - acc: 0.6541 - val_loss: 1.7397 - val_acc: 0.6260\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.7026 - acc: 0.6619 - val_loss: 1.7247 - val_acc: 0.6250\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.6857 - acc: 0.6671 - val_loss: 1.7067 - val_acc: 0.6300\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.6692 - acc: 0.6713 - val_loss: 1.6917 - val_acc: 0.6340\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.6534 - acc: 0.6743 - val_loss: 1.6754 - val_acc: 0.6420\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.6378 - acc: 0.6793 - val_loss: 1.6614 - val_acc: 0.6400\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.6227 - acc: 0.6836 - val_loss: 1.6466 - val_acc: 0.6480\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.6080 - acc: 0.6867 - val_loss: 1.6328 - val_acc: 0.6450\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.5937 - acc: 0.6888 - val_loss: 1.6190 - val_acc: 0.6560\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.5797 - acc: 0.6928 - val_loss: 1.6061 - val_acc: 0.6570\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.5664 - acc: 0.6971 - val_loss: 1.5939 - val_acc: 0.6640\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.5531 - acc: 0.7007 - val_loss: 1.5817 - val_acc: 0.6610\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.5405 - acc: 0.7060 - val_loss: 1.5699 - val_acc: 0.6630\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.5281 - acc: 0.7073 - val_loss: 1.5582 - val_acc: 0.6660\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.5161 - acc: 0.7121 - val_loss: 1.5488 - val_acc: 0.6690\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 1.5047 - acc: 0.7144 - val_loss: 1.5385 - val_acc: 0.6700\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 1.4932 - acc: 0.7167 - val_loss: 1.5256 - val_acc: 0.6680\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 1.4824 - acc: 0.7188 - val_loss: 1.5154 - val_acc: 0.6720\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 1.4718 - acc: 0.7233 - val_loss: 1.5056 - val_acc: 0.6760\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 1.4613 - acc: 0.7249 - val_loss: 1.4974 - val_acc: 0.6780\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.4511 - acc: 0.7292 - val_loss: 1.4883 - val_acc: 0.6870\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.4413 - acc: 0.7320 - val_loss: 1.4785 - val_acc: 0.6810\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.4318 - acc: 0.7323 - val_loss: 1.4704 - val_acc: 0.6900\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.4230 - acc: 0.7352 - val_loss: 1.4619 - val_acc: 0.6870\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.4137 - acc: 0.7381 - val_loss: 1.4538 - val_acc: 0.6900\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.4049 - acc: 0.7409 - val_loss: 1.4455 - val_acc: 0.6910\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3966 - acc: 0.7420 - val_loss: 1.4391 - val_acc: 0.6950\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.3883 - acc: 0.7428 - val_loss: 1.4321 - val_acc: 0.6960\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.3800 - acc: 0.7452 - val_loss: 1.4247 - val_acc: 0.6960\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3720 - acc: 0.7473 - val_loss: 1.4176 - val_acc: 0.6980\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3642 - acc: 0.7485 - val_loss: 1.4106 - val_acc: 0.6970\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.3568 - acc: 0.7503 - val_loss: 1.4033 - val_acc: 0.6940\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.3495 - acc: 0.7528 - val_loss: 1.3964 - val_acc: 0.6950\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.3421 - acc: 0.7547 - val_loss: 1.3924 - val_acc: 0.7030\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3354 - acc: 0.7549 - val_loss: 1.3866 - val_acc: 0.7030\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.3285 - acc: 0.7564 - val_loss: 1.3806 - val_acc: 0.7030\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.3218 - acc: 0.7620 - val_loss: 1.3745 - val_acc: 0.7010\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3152 - acc: 0.7601 - val_loss: 1.3690 - val_acc: 0.7050\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3091 - acc: 0.7628 - val_loss: 1.3628 - val_acc: 0.7030\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.3030 - acc: 0.7628 - val_loss: 1.3575 - val_acc: 0.7060\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.2968 - acc: 0.7659 - val_loss: 1.3531 - val_acc: 0.7100\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2907 - acc: 0.7664 - val_loss: 1.3468 - val_acc: 0.7110\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.2848 - acc: 0.7684 - val_loss: 1.3429 - val_acc: 0.7120\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.2790 - acc: 0.7707 - val_loss: 1.3376 - val_acc: 0.7180\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2735 - acc: 0.7717 - val_loss: 1.3338 - val_acc: 0.7160\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2679 - acc: 0.7731 - val_loss: 1.3299 - val_acc: 0.7150\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2624 - acc: 0.7753 - val_loss: 1.3246 - val_acc: 0.7190\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.2570 - acc: 0.7771 - val_loss: 1.3204 - val_acc: 0.7230\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.2517 - acc: 0.7787 - val_loss: 1.3157 - val_acc: 0.7200\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.2466 - acc: 0.7784 - val_loss: 1.3123 - val_acc: 0.7190\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.2413 - acc: 0.7792 - val_loss: 1.3076 - val_acc: 0.7210\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2366 - acc: 0.7836 - val_loss: 1.3056 - val_acc: 0.7200\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.2319 - acc: 0.7844 - val_loss: 1.2998 - val_acc: 0.7190\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.2269 - acc: 0.7835 - val_loss: 1.2954 - val_acc: 0.7210\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.2221 - acc: 0.7860 - val_loss: 1.2919 - val_acc: 0.7270\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.2173 - acc: 0.7869 - val_loss: 1.2895 - val_acc: 0.7220\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.2127 - acc: 0.7876 - val_loss: 1.2866 - val_acc: 0.7240\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.2082 - acc: 0.7897 - val_loss: 1.2829 - val_acc: 0.7250\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.2038 - acc: 0.7904 - val_loss: 1.2788 - val_acc: 0.7280\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1992 - acc: 0.7925 - val_loss: 1.2743 - val_acc: 0.7260\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1949 - acc: 0.7915 - val_loss: 1.2710 - val_acc: 0.7300\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1909 - acc: 0.7947 - val_loss: 1.2694 - val_acc: 0.7320\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1862 - acc: 0.7967 - val_loss: 1.2645 - val_acc: 0.7320\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.1821 - acc: 0.7953 - val_loss: 1.2622 - val_acc: 0.7330\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.1781 - acc: 0.7971 - val_loss: 1.2594 - val_acc: 0.7300\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.1741 - acc: 0.7989 - val_loss: 1.2552 - val_acc: 0.7330\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1700 - acc: 0.7985 - val_loss: 1.2522 - val_acc: 0.7350\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.1660 - acc: 0.8015 - val_loss: 1.2525 - val_acc: 0.7330\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.1618 - acc: 0.8020 - val_loss: 1.2464 - val_acc: 0.7360\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1580 - acc: 0.8043 - val_loss: 1.2444 - val_acc: 0.7330\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.1542 - acc: 0.8029 - val_loss: 1.2404 - val_acc: 0.7360\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.1504 - acc: 0.8064 - val_loss: 1.2404 - val_acc: 0.7350\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1466 - acc: 0.8060 - val_loss: 1.2369 - val_acc: 0.7360\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.1429 - acc: 0.8076 - val_loss: 1.2339 - val_acc: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.1392 - acc: 0.8081 - val_loss: 1.2304 - val_acc: 0.7380\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1355 - acc: 0.8080 - val_loss: 1.2273 - val_acc: 0.7410\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1318 - acc: 0.8125 - val_loss: 1.2236 - val_acc: 0.7430\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1282 - acc: 0.8133 - val_loss: 1.2224 - val_acc: 0.7390\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1246 - acc: 0.8131 - val_loss: 1.2216 - val_acc: 0.7390\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1212 - acc: 0.8151 - val_loss: 1.2181 - val_acc: 0.7400\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1175 - acc: 0.8164 - val_loss: 1.2147 - val_acc: 0.7440\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1142 - acc: 0.8160 - val_loss: 1.2155 - val_acc: 0.7400\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1109 - acc: 0.8155 - val_loss: 1.2109 - val_acc: 0.7430\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1076 - acc: 0.8181 - val_loss: 1.2100 - val_acc: 0.7420\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.1038 - acc: 0.8181 - val_loss: 1.2065 - val_acc: 0.7450\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1007 - acc: 0.8193 - val_loss: 1.2044 - val_acc: 0.7400\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.0973 - acc: 0.8200 - val_loss: 1.2017 - val_acc: 0.7410\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.0943 - acc: 0.8197 - val_loss: 1.2008 - val_acc: 0.7430\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0910 - acc: 0.8204 - val_loss: 1.1973 - val_acc: 0.7440\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.0881 - acc: 0.8220 - val_loss: 1.1956 - val_acc: 0.7420\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.0843 - acc: 0.8216 - val_loss: 1.1922 - val_acc: 0.7470\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0813 - acc: 0.8237 - val_loss: 1.1916 - val_acc: 0.7460\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.0781 - acc: 0.8247 - val_loss: 1.1898 - val_acc: 0.7460\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.0753 - acc: 0.8263 - val_loss: 1.1864 - val_acc: 0.7480\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.0721 - acc: 0.8239 - val_loss: 1.1841 - val_acc: 0.7480\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.0687 - acc: 0.8275 - val_loss: 1.1842 - val_acc: 0.7490\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.0661 - acc: 0.8263 - val_loss: 1.1801 - val_acc: 0.7490\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.0631 - acc: 0.8271 - val_loss: 1.1794 - val_acc: 0.7470\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.0600 - acc: 0.8284 - val_loss: 1.1758 - val_acc: 0.7490\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.0569 - acc: 0.8287 - val_loss: 1.1762 - val_acc: 0.7530\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.0540 - acc: 0.8291 - val_loss: 1.1742 - val_acc: 0.7520\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.0508 - acc: 0.8303 - val_loss: 1.1726 - val_acc: 0.7500\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0484 - acc: 0.8296 - val_loss: 1.1702 - val_acc: 0.7460\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.0454 - acc: 0.8335 - val_loss: 1.1704 - val_acc: 0.7470\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0423 - acc: 0.8316 - val_loss: 1.1675 - val_acc: 0.7490\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(\n",
    "    50, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=keras.regularizers.l2(.005),\n",
    "    input_shape=(2000,)))\n",
    "L2_model.add(layers.Dense(\n",
    "    25, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=keras.regularizers.l2(.005)))\n",
    "# Add another hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=512, \n",
    "                            validation_data=(X_val_tokens, y_val_lb),\n",
    "                            callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACvxUlEQVR4nOzdd3iUVfbA8e+dkknvjRSSEHovoYgoYEVFmrqKroquigVde1t1LWtZ11V/rn3tWFBWQHEBV1QQkRYgIDW0QHrvyfT7++MNgdDRhIRwPs8zT5K33ncyk5y577nnKq01QgghhBBCiGNjau0GCCGEEEIIcTKRAFoIIYQQQojjIAG0EEIIIYQQx0ECaCGEEEIIIY6DBNBCCCGEEEIcBwmghRBCCCGEOA4SQAshjkgpNV8pdW1zb9uWKaWmKKV+3u/nGqVUp2PZ9jecq108Z+LEU0p9oJT6W2u3Q4hTkQTQQrRDDQHf3odXKVW/389XHc+xtNYXaK0/bO5tj5dSKlwpNVcpVamUylNK3d8S5zkUrXWg1nrn7z2OUupxpdTHBxy7xZ6zU8GhntOG5Tal1LtKqd1KqWql1Fql1AWt0UYhRPtjae0GCCGan9Y6cO/3Sqks4Aat9cIDt1NKWbTW7hPZtt/hPsAX6ADYgJ6t2xxxJG3gtWUBsoGRwB7gQuALpVQfrXXWiWhAG3gODkkppQCltfa2dluEOFlJD7QQpxCl1CilVI5S6gGlVAHwvlIqTCn1jVKqWClV3vB9wn77LFJK3dDw/RSl1M9KqRcatt21f6/ecW6bopT6qaF3cKFS6rVD9STuxw0Uaa3rtNblWuulR7nWN5VSLxyw7Cul1N0N3z+olNrRcP5NSqmJRziWVkp1bvg+Qin1tVKqSim1Ekg9YNv/U0plN6xfrZQ6o2H5GOBh4PKGOwHrDvGcmZRSjzT0mhYppT5SSoU0rEtuaMe1Sqk9SqkSpdRfjtDmixp6Xasa2vP4AetHKKV+UUpVNKyf0rDcTyn1z4Y2VDb8Dv32vnYOOEaWUuqchu8fV0r9Ryn1sVKqCpiilBqilFrWcI58pdSrSimf/fbvpZT6TilVppQqVEo9rJSKVUrVKaUi9ttuUMPr03q46z2Q1rpWa/241jpLa+3VWn8D7AIGHeK5sjW0sfd+y6KUcecmWikV2fC+qGho6xKl1CH/fzb8jm5TSm0DtjUsG6uUymjY/xelVN/9th/Y8HuqVkrNVEp9rhrSMtQh0oP2fy0esDxMHf19/LRSailQBxwyJUkIcWwkgBbi1BMLhANJwE0Yfwfeb/i5I1APvHqE/YcCW4FI4HngXaWU+g3bfgqsBCKAx4Grj9LulcBkpdT1R9lur08xglUFRoABnAfMaFi/AzgDCAGeAD5WSnU4huO+BtgxesKvb3jsbxXQH+M5/hSYqZTy1VovAJ4BPm9ICel3iGNPaXiMxghwAjn4dzEC6AacDTymlOpxmHbWAtcAocBFwC1KqQkASqmOwHzgX0BUQ3szGvZ7ASPIHN5wDfcDx9pTOR74T8M5PwE8wF0Yv//TGtp8a0MbgoCFwAIgDugMfK+1LgAWAX/Y77h/BGZorV3H2I6DKKVigK7AxgPXaa0dwCxg8n6L/wAs1loXAfcAORjPVQzGByF9hNNNwHjt91RKDQTeA6ZivNbfAr5uCNp9gNnABxjP9WfAYT/IHcWxvI+vxnjPBwG7f+N5hBBIAC3EqcgL/FVr7dBa12utS7XWXzb07FYDT2Pc9j6c3Vrrf2utPcCHGIFkzPFs2xDADQYe01o7tdY/A18f7oQNPW5vA6OAB5VS1zUstymlnHt7aQ+wBCPIOaPh50uBZVrrPACt9UytdV5D7+TnGL2FQ45w3SilzMAlDe2u1VpvaLiuRlrrjxueU7fW+p8Y6SbdjnTc/VwFvKi13qm1rgEeAq5QSu2fbvdEw+9tHbAOOFQgjtZ6kdb614brW48RnO39vV4FLNRaf6a1djW0N6OhV/V64M9a61yttUdr/UtDgHkslmmt5zScs15rvVprvbzhucjCCB73tmEsUKC1/qfW2q61rtZar2hY9yFG0Lz3OZ8MTD/GNhykoef6E+BDrfWWw2z2KU0D6CsblgG4MF67SQ3P1xKt9ZEC6Ge11mVa63rgRuAtrfWKhufzQ8ABDGt4WIBXGo47C+OD4nE7xvfxB1rrjQ2/j9/8YUQIIQG0EKeiYq21fe8PSil/pdRbDbfsq4CfgNCGwOVQCvZ+o7Wua/g28Di3jQPK9lsGRr7q4fwJ+E5r/RNwPvBUQxA9DFirta48cIeGAGcG+4KiKzGCKACUUtfsd1u9AuiN0VN6JFHsy63dq0lPnlLqHqXU5ob0hwqMHu6jHXevuAOOt7vhfPt/QCnY7/s6DvPcK6WGKqV+bLilXwncvF87EjF64A8UiZFnfqh1x6LJ71Ap1bUhlaCg4bX1zDG0AeArjN7bTsC5QKXW+jcFlg0fCqYDTmDaETb9AfBreN6SMHrlZzes+wewHfifUmqnUurBo5x2/+chCbhn7+us4TWRiPG7jgNyDwjGj/Q+OKxjfB//pmMLIQ4mAbQQp54De87uweghHaq1DgbObFh+uLSM5pAPhCul/PdblniE7S0YOdBorXcBYzBSQt4BnjzCfp8BlzYEREOBLwEafv43RkAVobUOBTZw9GsubmjH/m3tuPcbZeQ7P4Bx+z+s4biV+x33SL2WAHkYAdf+x3YDhUfZ71A+xejVT9RahwBv7teObA7I3W5QgpGecqh1tUDj76shMIs6YJsDr+8NYAvQpeG19fAxtIGGD3hfYPSUX81v7H1uSN95F+MDyCVH6nVtGFD3BcYHriuBbxp6cmnoHb9Ha90JuBi4Wyl19hFOfWBA/LTWOnS/h7/W+jOM90H8ASlQ+7+2DnzOY49wzmN5Hx/t9SeEOEYSQAshgjDyJSuUUuHAX1v6hFrr3UA68LhSykcpdRpGYHI4szDymSc0BG5VGOkLqRwhKNBar8UIet8BvtVaVzSsCmjYrxigoTe796GOccDxPA1tebyhx68nsH8N5yCMgLcYsCilHgOC91tfCCQfbgAaRsB/lzIGWAayL2f6t1RyCMLo5bcrpYZgBIV7fQKco5T6g1LKooyBkf0bgsj3gBeVUnFKKbNS6jSllA3IBHyVMTjRCjyCkZ5ytDZUATVKqe7ALfut+waIVUrd2ZCKE6SUGrrf+o8w8sHHAUcaXApgUkr57vfY2643gB7AxQ3pFEfzKXA5RuC+N31j7yDAzg2BbhVGbrfnGI4Hxge1mxt6tpVSKqDhOQwCljUcZ1rD72E8TdOI1gG9lFL9lVK+GGMFDueEv4+FOJVJAC2EeBnww+h9XI4xqOtEuApjYFkp8Dfgc4zc0INorZdhBIB/BcqBb4F5GPnInymlBhzhPJ8B57BfQKS13gT8EyOAKQT6AEes6rGfaRhpEwUYg7/e32/dtxiD8zIx0i/sNL1tPrPha6lSas0hjv0eRm/rTxgVI+zA7cfYrgPdCjyplKoGHsPoXQVAa723rNs9QBnGAMK9udT3Ar9iDIYsA/4OmBrSZG7F+DCSi9E72qQqxyHci/F7q8YIJD/frw3VGOkZF2M8l9swBk/uXb8UI19/jT562bnJGMHj3seOhrsMUzFSMQrUMdRBb8jBrsVIrZi/36ouGAMeazBeM69rrRcdpU17j5mOkQf9KsZrdzvGBwO01k5gEkaKUgVG3vc3NLwPtNaZGHdYFmI8P0easOdlWud9LMQpSR15HIQQQpwYSqnPgS1aa+k5EwAopX4APtVav9PabTlRlFIrgDe11u8fdWMhRKuRHmghRKtQSg1WSqUqo/bxGIwSaHNauVmijVBKDQYGsl+vdXuklBqpjNrXFmVM6d4X6T0Wos2TmQiFEK0lFiOfOAIjFeCWhpxlcYpTSn2IUUv5z3sH8rVj3TDSawIxqpJcqrXOb90mCSGORlI4hBBCCCGEOA6SwiGEEEIIIcRxkABaCCGEEEKI43DS5UBHRkbq5OTk1m6GEEIIIYRo51avXl2itT5w0qiTL4BOTk4mPT29tZshhBBCCCHaOaXU7kMtlxQOIYQQQgghjoME0EIIIYQQQhwHCaCFEEIIIYQ4DiddDvShuFwucnJysNvtrd0U0QJ8fX1JSEjAarW2dlOEEEIIIdpHAJ2Tk0NQUBDJyckopVq7OaIZaa0pLS0lJyeHlJSU1m6OEEIIIUT7SOGw2+1ERERI8NwOKaWIiIiQuwtCCCGEaDPaRQANSPDcjsnvVgghhBBtSbsJoFtTaWkp/fv3p3///sTGxhIfH9/4s9PpPOK+6enp3HHHHUc9x/Dhw5uruc0uMDDwoGUvvvgiPXv2pG/fvpx99tns3n3IMopCCCGEECeddpED3doiIiLIyMgA4PHHHycwMJB77723cb3b7cZiOfRTnZaWRlpa2lHP8csvvzRLW0+UAQMGkJ6ejr+/P2+88Qb3338/n3/+eWs3SwghhBDid5Me6BYyZcoU7r77bkaPHs0DDzzAypUrGT58OAMGDGD48OFs3boVgEWLFjF27FjACL6vv/56Ro0aRadOnXjllVcaj7e3l3fRokWMGjWKSy+9lO7du3PVVVehtQZg3rx5dO/enREjRnDHHXc0Hnd/WVlZnHHGGQwcOJCBAwc2Ccyff/55+vTpQ79+/XjwwQcB2L59O+eccw79+vVj4MCB7Nix45iuf/To0fj7+wMwbNgwcnJyjvcpFEIIIYRok9pdD/QTczeyKa+qWY/ZMy6Yv17c67j3y8zMZOHChZjNZqqqqvjpp5+wWCwsXLiQhx9+mC+//PKgfbZs2cKPP/5IdXU13bp145ZbbjmofNvatWvZuHEjcXFxnH766SxdupS0tDSmTp3KTz/9REpKCpMnTz5km6Kjo/nuu+/w9fVl27ZtTJ48mfT0dObPn8+cOXNYsWIF/v7+lJWVAXDVVVfx4IMPMnHiROx2O16v97ifh3fffZcLLrjguPcTQgghhGiL2l0A3ZZcdtllmM1mACorK7n22mvZtm0bSilcLtch97nooouw2WzYbDaio6MpLCwkISGhyTZDhgxpXNa/f3+ysrIIDAykU6dOjaXeJk+ezNtvv33Q8V0uF9OmTSMjIwOz2UxmZiYACxcu5LrrrmvsNQ4PD6e6uprc3FwmTpwIGPWYj9fHH39Meno6ixcvPu59hRBCCCHaonYXQP+WnuKWEhAQ0Pj9o48+yujRo5k9ezZZWVmMGjXqkPvYbLbG781mM263+5i22ZvGcTQvvfQSMTExrFu3Dq/X2xgUa60PqnZxrMc8nIULF/L000+zePHiJm0WQgghhDiZSQ70CVJZWUl8fDwAH3zwQbMfv3v37uzcuZOsrCyAww7Yq6yspEOHDphMJqZPn47H4wHgvPPO47333qOurg6AsrIygoODSUhIYM6cOQA4HI7G9Uezdu1apk6dytdff010dPTvuzghhBBCiDZEAugT5P777+ehhx7i9NNPbwxam5Ofnx+vv/46Y8aMYcSIEcTExBASEnLQdrfeeisffvghw4YNIzMzs7GXfMyYMYwbN460tDT69+/PCy+8AMD06dN55ZVX6Nu3L8OHD6egoOCgY9bV1ZGQkND4ePHFF7nvvvuoqanhsssuo3///owbN67Zr1kIIYQQojWo33ub/kRLS0vT6enpTZZt3ryZHj16tFKL2o6amhoCAwPRWnPbbbfRpUsX7rrrrtZuVrOQ37EQQgghTjSl1Gqt9UH1hqUHuh3597//Tf/+/enVqxeVlZVMnTq1tZskhBBCCNFIa43Lc+hCCieTdjeI8FR21113tZseZyGEEEK0H5WOSmZvm82MrTPIrcklwjeCDgEd6BDYgRj/GMJ9wwnzDSPcNxyryUpuTS451TlkV2eTU5PD+2PeJ9gnuLUvo5EE0EIIIYQQ4nepdFTy/Z7v+W73d9S6aokNiKVDQAdiA2LZXLqZebvm4fA4GBg9kItTL6a4rpj82ny2V2znl7xfqHXVHnRMm9lGQmACCUEJ1LvqJYAWQgghhBBtX62rlpzqHHJrcsmrySO3Jhev9mKz2PA1+2IxWVhTtIYVeStwazeJQYnEBsSyoWQDC3cvxOV14Wfx4+LUi7mi2xV0C+92yPM4PA7K7eWU2ctwepzEBcYR6ReJSbXNbGMJoIUQQgghTgF1rjpK7aVYTVZsZhs2sw2TMlFQW0BuTa6RNlGTQ251buPPFY6KJsfws/hhURYcHgdOrxOA+MB4rul1Decnn0+P8B6N80p4tZfS+lL8rf4EWAMObE4TNrON2IBYYgNiW+Tam5sE0EIIIYQQbYzdbWdN4RosJgsDYwZiMR09ZHN73VQ4KthVuYusqix2V+5md/VuCmoLyK/Np9JRedRjWEwW4gLiiA+Mp0dSD+ID40kITCA+MJ74oHjCbGFNAmSnx4nNbDtoMjYAkzIR5R91/Bd/EpAAuhmMGjWKhx56iPPPP79x2csvv0xmZiavv/76Yfd54YUXSEtL48ILL+TTTz8lNDS0yTaPP/44gYGB3HvvvYc995w5c+jatSs9e/YE4LHHHuPMM8/knHPO+f0X1swCAwOpqalpsuzFF1/knXfewWKxEBUVxXvvvUdSUlIrtVAIIYRoHVpr9lTvYWnuUn7O/ZlVBauwe+wAhPuGc07Hczg/+XwSghLYXLqZjaUb2Vi6kezqbGpdtdS56hq338tmtpEYlEhcYBz9ovrRIaADEX4ReLwe7B47To8Tt9dNTEAMcQFxJAQlEOUXhdlkPqY2m5QJX4tvsz8XJwMJoJvB5MmTmTFjRpMAesaMGfzjH/84pv3nzZv3m889Z84cxo4d2xhAP/nkk7/5WK1hwIABpKen4+/vzxtvvMH9999/2FkUhRBCiPbCq73srtrNmsI1rCpcxaqCVRTVFQHQMagjl3S9hBHxI3C4HSzIWsDcnXP5IvOLxv0tykLnsM70juhNoE8gAdYA/K3+hPiEkBycTHJIMrEBsW02h/hkJwF0M7j00kt55JFHcDgc2Gw2srKyyMvLY8SIEdxyyy2sWrWK+vp6Lr30Up544omD9k9OTiY9PZ3IyEiefvppPvroIxITE4mKimLQoEGAUeP57bffxul00rlzZ6ZPn05GRgZff/01ixcv5m9/+xtffvklTz31FGPHjuXSSy/l+++/595778XtdjN48GDeeOMNbDYbycnJXHvttcydOxeXy8XMmTPp3r17kzZlZWVx9dVXU1trjIp99dVXGT58OADPP/8806dPx2QyccEFF/Dcc8+xfft2br75ZoqLizGbzcycOZPU1NSjPnejR49u/H7YsGF8/PHHv/n3IIQQQpwoNc4atpZvNdIlKrPIqsoirzaPUFtoY/WJ2IBYLMqCW7txe904PU72VO1hS/kWtpVvo95dDxg9zENihzA4djDDOgyjY3DHJuc6O+ls6t31LMlZQrm9nJ4RPeka3hWb2dYaly5ojwH0/Aeh4NfmPWZsH7jgucOujoiIYMiQISxYsIDx48czY8YMLr/8cpRSPP3004SHh+PxeDj77LNZv349ffv2PeRxVq9ezYwZM1i7di1ut5uBAwc2BtCTJk3ixhtvBOCRRx7h3Xff5fbbb2fcuHGNAfP+7HY7U6ZM4fvvv6dr165cc801vPHGG9x5550AREZGsmbNGl5//XVeeOEF3nnnnSb7R0dH89133+Hr68u2bduYPHky6enpzJ8/nzlz5rBixQr8/f0pKysD4KqrruLBBx9k4sSJ2O12vF7vcT/N7777LhdccMFx7yeEEEL8HlprNpVuIrsmm0HRgw7K2/VqL1vLtrKqYBUbSzeyqXQTWVVZjet9TD50DO5IQmAClc5KVhaspKiuCK8++H9hkE8Q3cK6ManLJLqFdaNfVD9SQlIOmUO8Pz+LH+cln9cs1yt+v/YXQLeSvWkcewPo9957D4AvvviCt99+G7fbTX5+Pps2bTpsAL1kyRImTpyIv78/AOPGjWtct2HDBh555BEqKiqoqalpki5yKFu3biUlJYWuXbsCcO211/Laa681BtCTJk0CYNCgQcyaNeug/V0uF9OmTSMjIwOz2UxmZiYACxcu5LrrrmtsY3h4ONXV1eTm5jJx4kQAfH2PPx/q448/Jj09ncWLFx/3vkIIIcTx0lqzuWwz32Z9y7dZ35Jbk9u4rnNoZ06LO42koCTSC9NZkb+Cckc5ANH+0fSK6MXYTmPpEdGD1NBUYv1jD8obdnvdlNSXoLXGbDJjVmYsJgvBPsFHDZZF29eiAbRSagzwf4AZeEdr/dwB68OA94BUwA5cr7Xe8LtOeoSe4pY0YcIE7r77btasWUN9fT0DBw5k165dvPDCC6xatYqwsDCmTJmC3W4/4nEO96aaMmUKc+bMoV+/fnzwwQcsWrToiMfRWh9xvc1m3PYxm8243e6D1r/00kvExMSwbt06vF5vY1CstT6ojUc719EsXLiQp59+msWLFze2SwghhGgOta5a0gvSWZ6/nO0V2xtrDZc7ynF73ViUhaFxQ5nadyqpoamsKljFsvxlfL7lc5xeJ1F+UYyIH8FpcacxJHYIMQExx3Rei8ly0pRkE8evxQJopZQZeA04F8gBVimlvtZab9pvs4eBDK31RKVU94btz26pNrWkwMBARo0axfXXX8/kyZMBqKqqIiAggJCQEAoLC5k/fz6jRo067DHOPPNMpkyZwoMPPojb7Wbu3LlMnToVgOrqajp06IDL5eKTTz4hPj4egKCgIKqrqw86Vvfu3cnKymL79u2NOdMjR4485uuprKwkISEBk8nEhx9+iMfjAeC8887jySef5Morr2xM4QgPDychIYE5c+YwYcIEHA4HHo+nsZf6SNauXcvUqVNZsGAB0dHRx9w+IYQQpw63101OdQ55NXnk1+aTX5tPQW0BHu1prGdss9hQKNxeNx7twe11s618G+uL1+PWbnzNvnQN60qHgA70iuxFmC2MpOAkRieOJtQ3tPFcfaP68qc+f8LutlNcV0xCUIL0GIuDtGQP9BBgu9Z6J4BSagYwHtg/gO4JPAugtd6ilEpWSsVorQtbsF0tZvLkyUyaNIkZM2YA0K9fPwYMGECvXr3o1KkTp59++hH3HzhwIJdffjn9+/cnKSmJM844o3HdU089xdChQ0lKSqJPnz6NQfMVV1zBjTfeyCuvvMJ//vOfxu19fX15//33ueyyyxoHEd58883HfC233norl1xyCTNnzmT06NEEBBgF0MeMGUNGRgZpaWn4+Phw4YUX8swzzzB9+nSmTp3KY489htVqZebMmXTq1KnJMevq6khISGj8+e6772bevHnU1NRw2WWXAdCxY0e+/vrrY26nEEKIk5/T42RbxTbK7eVUOiqpclZRYa9gV9UudlTsYFflLlxeV+P2JmUi0i8Sq8mKw+MwHm4HAGaTGYuyYDaZiQuM49pe13Ja3Gn0j+5/XIPufC2+JAYnNvu1ivZB/d7b74c9sFKXAmO01jc0/Hw1MFRrPW2/bZ4BfLXWdyulhgC/NGyz+nDHTUtL0+np6U2Wbd68mR49erTEZYg2Qn7HQghxctJas7F0I2uL1mIz24xZ6SxGp8yvJb+ypmgNG0o24PA4Dtq3Q0AHUkNT6RzamdTQVBKDEukQ0IEo/yisJuuJvhRxClJKrdZapx24vCV7oA91v+PAaP054P+UUhnAr8Ba4KCEXKXUTcBNYPRQCiGEEKLt8movW8q2HHKA3v7MykyP8B78odsf6B/Vn2j/aIJtwQT7BBPiE4LVLEGyaJtaMoDOAfa/95EA5O2/gda6CrgOQBkJRrsaHhyw3dvA22D0QLdQe4UQQghxFHa3nT3VeyitL23MN/Z4PZQ5ythatpXM8kwyyzOpddU2GaA3In4EGt04a57L66JrWFf8rUcfLyNEW9OSAfQqoItSKgXIBa4Artx/A6VUKFCntXYCNwA/NQTVQgghhGhFLo+LHZU72Fq2lS1lW9hZuZOsyizya/PRB91QNgRaA+ka1pWLO11M78jejEwY2WSAnhDtRYsF0Fprt1JqGvAtRhm797TWG5VSNzesfxPoAXyklPJgDC78U0u1RwghhDjVubwucqpz2FO1h1pXbWO1CpfXRbm9vLG6RV5tHtnV2bi9Rlalr9mXlJAU+kX3Y0LwBJJDkon2j8ZisjQO2AvyCSIuIE4qVohTQovWgdZazwPmHbDszf2+XwZ0ack2CCGEEKcSp8dJub2cPdV72F21u3Ga6ayqLHKqc/Boz2H3DfcNp0NABzqHduasxLPoFt6NbuHdSApKOmiiECFOZTIToRBCCNGGuTwudlXtwt/iT7AtmEBrIFprtldsZ33JetYXr2dz6WbK7eVUOauwe5pO2GUz2+gY3JGuYV05L+k8koKTSApOItgWjFVZG2fJC7GF4Gs5/plkhTgVSQDdDEpLSzn7bGP+l4KCAsxmM1FRUQCsXLkSHx+fw+6bnp7ORx99xCuvvHLEcwwfPpxffvml+RothBCiTdtZsZNZ22Yxd+dcyuxljctNyoRZmRvrIofZwugV2YueET2N6hW2EEJsISQEJpAUkkSHgA6YlKm1LkOIdkkC6GYQERFBRkYGAI8//jiBgYHce++9jevdbjcWy6Gf6rS0NNLSDioveBAJnoUQov1yeVxkVWWxo2IH2yu2syJ/BRnFGViUhZGJIzm749m4vW6qnFVUOatweVx0De9Kv8h+MlOeEK1AAugWMmXKFMLDw1m7dm3jDIN33nkn9fX1+Pn58f7779OtWzcWLVrECy+8wDfffMPjjz/Onj172LlzJ3v27OHOO+/kjjvuAIypwmtqali0aBGPP/44kZGRbNiwgUGDBvHxxx+jlGLevHncfffdREZGMnDgQHbu3Mk333zTpF1ZWVlcffXV1NbWAvDqq68yfPhwAJ5//nmmT5+OyWTiggsu4LnnnmP79u3cfPPNFBcXYzabmTlzJqmpqSf2yRRCiJOA1ppSe2ljELyjYkfj9/XueoJ9ghtrHFtMFupcddS6aql11VLpqMStjQF7JmWic2hn7hl0D2NTxxLpF9nKVyaEOFC7C6D/vvLvbCnb0qzH7B7enQeGPHDc+2VmZrJw4ULMZjNVVVX89NNPWCwWFi5cyMMPP8yXX3550D5btmzhxx9/pLq6mm7dunHLLbdgtTYtJL927Vo2btxIXFwcp59+OkuXLiUtLY2pU6fy008/kZKSwuTJkw/ZpujoaL777jt8fX3Ztm0bkydPJj09nfnz5zNnzhxWrFiBv78/ZWXG7cKrrrqKBx98kIkTJ2K32/F6vcf9PAghRHuhtaawrpDs6mwKagvIr80nvzafXZXGlNMVjorGbUNsIaSGpDImeQyBPoFG77GjikpnJR6vh2j/aGNWPmsAYbawxhn3kkOSj2vKaSHEidfuAui25LLLLsNsNkYtV1ZWcu2117Jt2zaUUrhcrkPuc9FFF2Gz2bDZbERHR1NYWEhCQkKTbYYMGdK4rH///mRlZREYGEinTp1ISUkBYPLkybz99tsHHd/lcjFt2jQyMjIwm81kZmYCsHDhQq677jr8/Y2C9uHh4VRXV5Obm8vEiRMB8PWVwSVCiFODV3updFRSZi+juL6YTaWbWF9sDNgrri9usm2YLYyk4CTO7nh245TTnUM7E+kXKakVQrRT7S6A/i09xS0lICCg8ftHH32U0aNHM3v2bLKyshg1atQh97HZ9vU6mM1m3O6DZjY/5DZaH9sEjS+99BIxMTGsW7cOr9fbGBRrrQ/6Q3+sxxRCiLbO7XWzoWQDy/KXsbNiJ30i+3Ba3Gl0Du2MUgqnx8mK/BV8v+d7fs79meL6Yry66R23xKBEhnQYQp/IPqSEpBAXEEdsQKxUrhDiFNTuAui2qrKykvj4eAA++OCDZj9+9+7d2blzJ1lZWSQnJ/P5558fth0JCQmYTCY+/PBDPB6jHuh5553Hk08+yZVXXtmYwhEeHk5CQgJz5sxhwoQJOBwOPB5PYy+1EEK0NVpriuuLya7OJqc6h5yaHDLLMllVsIpqVzUKRZR/FAuyFgAQ5RdF1/CurCtaR42rhgBrACPiR5AUnES4b3jjo0tYF8J9w1v56oQQbYUE0CfI/fffz7XXXsuLL77IWWed1ezH9/Pz4/XXX2fMmDFERkYyZMiQQ2536623cskllzBz5kxGjx7d2Es+ZswYMjIySEtLw8fHhwsvvJBnnnmG6dOnM3XqVB577DGsViszZ86kU6dOzd5+IYT4PfZU7WHernn8d+d/yarKalxuUibiA+M5L/k8hsUNY1jsMEJ9Q8mvyWd5/nKW5S1jS/kWzks+j7M7ns2wDsPwMR++9KgQQgCok+02fVpamk5PT2+ybPPmzfTo0aOVWtR21NTUEBhoFNi/7bbb6NKlC3fddVdrN6tZyO9YCFHrqmV31W7ya/Mpt5dTZi+j3F7OuuJ1/FryKwpFWmwaZyWeRUpICglBCcQFxGE1W49+cCGEOASl1Gqt9UH1hqUHuh3597//zYcffojT6WTAgAFMnTq1tZskhBDHrMJeQUZxBnk1eVQ5q6h0VFLlrKKgtoCsyiyK6osO2ifQGkjH4I7cM+gexqSMITYgthVaLoQ41UgA3Y7cdddd7abHWQjRvpXby8mqyiKrMot1xetYW7SWnZU7m2yzd+rqaP9ohsUNIzk4meSQZOIC44jwjSDMN0zKvQkhWoUE0EIIIZqd0+Mkvzaf3JpccmtyyavJa/x+d9VuKh2VjdsGWYPoH92fi1MvZmD0QJKCkwi2BWM1SeqFEKJtkgBaCCHEMdlZsZN1xetICEqgc2hnwnzDAKhz1ZFRlMHKgpVkFGeQXZ1NcV0xmn1jbCzKQmxALHGBcZybdC7JwcmkhKSQFJxEQmACZpO5tS5LCCGOmwTQQgghDquwtpD5u+Yzb9c8NpdtbrIu3DecaP9otpdvx63dWJSFnpE9Oa3DacQHxRMfGE9cQBzxgfFE+UdhMcm/HCFE+yB/zYQQ4hRRYa+gyllFQlACJmU65DZOj5OMogyW5S9jWd4yNpVuQqPpHdGb+wffz/C44RTUFrC9Yjs7KnZQUFvAtb2uZUjsEPpH98ffKnXihRDtnwTQzWDUqFE89NBDnH/++Y3LXn75ZTIzM3n99dcPu88LL7xAWloaF154IZ9++imhoaFNtnn88ccJDAzk3nvvPey558yZQ9euXenZsycAjz32GGeeeSbnnHPO778wIUS7sKtyFx9t+oivt3+N0+sk0BpIz4ie9IzoSYRvBAV1BeTX5JNfm8+uyl3YPXbMykzfqL7c1v82xqSMISk4qfF4qaGpnB5/eitekRBCtC4JoJvB5MmTmTFjRpMAesaMGfzjH/84pv3nzZv3m889Z84cxo4d2xhAP/nkk7/5WEKIk5fdbSe9MJ0ye1njMo/Xww/ZP7AoexE+Jh/GdR5Hr4hebCnbwsaSjXyy+RNcXhf+Fn/iAo1pqQfGDGRo7FAGxw4m0Cew9S5ICCHaMAmgm8Gll17KI488gsPhwGazkZWVRV5eHiNGjOCWW25h1apV1NfXc+mll/LEE08ctH9ycjLp6elERkby9NNP89FHH5GYmEhUVBSDBg0CjBrPb7/9Nk6nk86dOzN9+nQyMjL4+uuvWbx4MX/729/48ssveeqppxg7diyXXnop33//Pffeey9ut5vBgwfzxhtvYLPZSE5O5tprr2Xu3Lm4XC5mzpxJ9+7dm7QpKyuLq6++mtraWgBeffVVhg8fDsDzzz/P9OnTMZlMXHDBBTz33HNs376dm2++meLiYsxmMzNnziQ1NbWFn3khTl0Oj4OS+hJW5q/kx+wfWZ6/nHp3/UHbhdpCubnfzVzR7Qoi/CKarHN5XNR76gmyBqGUOlFNF0KIk167C6ALnnkGx+YtzXpMW4/uxD788GHXR0REMGTIEBYsWMD48eOZMWMGl19+OUopnn76acLDw/F4PJx99tmsX7+evn37HvI4q1evZsaMGaxduxa3283AgQMbA+hJkyZx4403AvDII4/w7rvvcvvttzNu3LjGgHl/drudKVOm8P3339O1a1euueYa3njjDe68804AIiMjWbNmDa+//jovvPAC77zzTpP9o6Oj+e677/D19WXbtm1MnjyZ9PR05s+fz5w5c1ixYgX+/v6UlRm9XVdddRUPPvggEydOxG634/V6f9NzLYQ4WLWzmm+zvuXbrG/Jq8mjzF5GjaumcX1sQCzjUscxKnFUk1QLgGj/6MPWSraarTJLnxBC/AbtLoBuLXvTOPYG0O+99x4AX3zxBW+//TZut5v8/Hw2bdp02AB6yZIlTJw4EX9/YxDOuHHjGtdt2LCBRx55hIqKCmpqapqkixzK1q1bSUlJoWvXrgBce+21vPbaa40B9KRJkwAYNGgQs2bNOmh/l8vFtGnTyMjIwGw2k5mZCcDChQu57rrrGtsYHh5OdXU1ubm5TJw4EQBfX99jes6EEEaaxe6q3Wws3cjOyp3YzDaCfYIJsYVgVmZ+2PMDP2T/gMPjIDk4mV6RvRonEQnzDaN3RG+6h3eXHmQhhDiB2l0AfaSe4pY0YcIE7r77btasWUN9fT0DBw5k165dvPDCC6xatYqwsDCmTJmC3W4/4nEO909wypQpzJkzh379+vHBBx+waNGiIx5Ha33E9Tab0SNlNptxu90HrX/ppZeIiYlh3bp1eL3exqBYa31QG492LiFEU2X2Mubvms/C3QvZVLqJOncdAGZlxqM9TbYNsYUwsfNExnceT6+IXhIoCyFEG9DuAujWEhgYyKhRo7j++uuZPHkyAFVVVQQEBBASEkJhYSHz589n1KhRhz3GmWeeyZQpU3jwwQdxu93MnTuXqVOnAlBdXU2HDh1wuVx88sknxMfHAxAUFER1dfVBx+revTtZWVls3769MWd65MiRx3w9lZWVJCQkYDKZ+PDDD/F4jH/q5513Hk8++SRXXnllYwpHeHg4CQkJzJkzhwkTJuBwOPB4PI291EKc6rzaS3FdMetL1jN3x1yW5CzBrd10DevKuNRx9IrsRa+IXqSEpKC1pspZRZWzijp3HV1Cu+Bj9mntSxBCCLEfCaCb0eTJk5k0aRIzZswAoF+/fgwYMIBevXrRqVMnTj/9yGWfBg4cyOWXX07//v1JSkrijDPOaFz31FNPMXToUJKSkujTp09j0HzFFVdw44038sorr/Cf//yncXtfX1/ef/99LrvsssZBhDfffPMxX8utt97KJZdcwsyZMxk9ejQBAQEAjBkzhoyMDNLS0vDx8eHCCy/kmWeeYfr06UydOpXHHnsMq9XKzJkz6dSp0zGfT4j2oM5Vx46KHY01kndV7SKnOofcmlwcHgcAkX6RXNXjKsZ1HkfXsK6HPE6EX8RBA/6EEEK0Hepku/2elpam09PTmyzbvHkzPXr0aKUWiRNBfseitRTUFvDNzm/4787/Uu2spm9UX/pG9qVvVF98Lb78Wvwr60vWs754PVlVWY37+Zh8SA5JpmNQRxKCEkgITKBTaCcGRA+QGfmEEOIkoZRarbVOO3C5/BUXQpzyPF4PGcUZFNQW4PA4sLvt2D12luUtY0X+CjSaAdED6BLahfUl6/lu93dN9g/3DadvVF8u6nQRXUK70DmsMwmBCZhN5la6IiGEEC1JAmghxClJa83mss3M2zmP+VnzKaorOmib+MB4pvabyrhO40gMTmxcXlJfwvri9Tg8DvpE9iE+MF4G9wkhxClEAmghRLtWUFvAV9u/YkHWgia1k50eJ2X2MiwmCyPiR3Bf2n10D++OzWzDZrFhM9vwt/gfMjCO9IvkrI5nncjLEEII0Ya0mwD6UOXVRPtwsuXpi9bl1V5yq3PZULqBr3Z8xbK8ZXi1l8Gxg+kd2btxO4Wid2Rvzks6j1Df0NZrsBBCCAAKKu289dMO1uwup09CCIOTw0lLDic+1K+1m3aQdhFA+/r6UlpaSkREhATR7YzWmtLSUpmcRRzEq73k1+Y3qXqxvWI7uyp3NU5pHe0fzQ19bmBC5wkkBiUe5YhCCCFakterya2op87pITzAhzB/KxaziZzyOt5cvIMvVuXg0Zr+iaHMWZvHx8v3ABAX4stnNw0jKSKgla9gn3YRQCckJJCTk0NxcXFrN0W0AF9fXxISElq7GaKV7c07Xl+8nvUl69lYsrFxAhKAaL9oUkNTuaTLJXQO7UznsM70jugtA/mEEKKF1Ds97CiuobzOSZ3TQ73TQ53TQ53Tjd2193sPRdV2dhbXsqukFofb27i/UhDiZ6XG7kYpuHRQIreOSiUx3B+PV7OloIpVu8pYs6eCDiFtqxe6XZSxE0Kc3PbmI4faQvG1GHcbvNrLhpINLMpexKKcRWwr3waARVnoHt6d3pG96RLWhc6hnUkNTSXEFtKKVyCEEG2f2+OlvM5FVJDtkOsWbCxg9ppcQvyspEQG0CkqkKQIf+wuD4VVDgqr7BRW29lRVMu2omr2lNVxpDDSYlL4+ZiJDLTRKTKATlHGMYN8LZTXOimpcVJW68TfZuba05KJa4OpGlLGTgjRptS56liSu4Tv93zPTzk/UeuqBcDf4k+Ybxj17nrK7GWYlZkB0QO4a9BdDIweSPfw7o1BthBCiIN5vJqiajt5FfXsKqljQ24lv+ZWsjGvErvLS0pkAOf0iObsHjH06BDMrDU5vPvzLnLK64kP9cOrNbPW5h7y2FazIikigF5xwUzoH0/XmCCig234Wc34+5jx97Hg52PGz2rGx2I6wVd+4kgALYQ4IbTWZFVl8UveLyzNXcqK/BU4vU7CbGGMSR5Dz4ieVDmrKLOXUWYvQ6E4Pf50zog/Q3qXhRDiCLLL6vh5ewk/by8hY08FhVV23N59XcN+VjO944O5ckgSMcE2lu4o5cNfdvPvJbsatxmcHMZjY3tyTo8YTCZFndPNzuJa9pTVEWCzEB1kIybYlzB/q4w3Q1I4hBAtqNpZzYr8FSzNW8ovub+QV5sHQFJwEiPiR3B2x7MZGD1Q8pSFEOIAHq+mos7JjuJa1udUNPYil9Y6CfCxEGizEGAzU1rrZHepMR4kJtjGkJQIOob7ERdqPBLD/EiJDMRsahr01jjcLMksZn1uJef2jGFgx7DWuMw273ApHBJACyF+txpnDfm1+cajJp+82jwyijJYV7wOj/YQYA1gSOwQRsSPYHjccBKCZFCoEKL901pTUuNkZ3ENu0qMQXRF1Q5KahyU1Rr5v1qDzWrC12LG12qi3uWhtMZJeZ2T/TqRiQ32pXd8CLEhNuqcHmodbmodHnytZoanRnBGl0g6RwdK73AzkxxoIcTvorUmpzqHdSXr2FCygezqbPJr8ymoKaDaVd1kW4vJQtewrlzf+3qGxw2nX3Q/rCZrK7VcCCGOn9Yau8uLr9V0xKDU4fbw87YS/rs+n8WZxdhdnsZ1bq9uUnXCx2IiJthGeICRDtGjQzAmBQ63F7vLg93lpYPVTFqyD5EBPoQH+JAY7k+fhBCig2TsR1siAbQQ4rA8Xg9L85Yya9ss1hSuodxRDoCfxY/k4GQSAhMYHDOYDgEdiA2MpUNABzoEdCDSLxKTar+DR4QQ7Yvb42VDXhUZe8rZWljDtsJqMgurqbK7MSkItFkI8rUS7GclyNdCsK/xs9urWbS1iGq7mxA/K2d3jyY8wKfxuEpBXKgfnaIC6RQZQFyo30GpFOLkJAG0EOIgFfYKZm+fzedbPye3JpcovyhGJo6kb1Rf+kb2pXNoZ8lbFkK0aW6Pl4IqO4VVDoqq7BRW2alv6FG2NaRLlNQ4WLajlFVZ5dQ43IBRl7hrTCBj+8URH+pHvdNDtd1Ftd1Nld1Ntd1FXoWdakc1LrfmvJ6xjO3XgdNTI9t11QnRlATQQghqnDVkFGewunA1awrX8GvJr7i8LgbFDOKuQXdxVsezJAVDCHFS0Frzzfp8npu/hdyK+qNu3ykqgPH94xjWKYLByeHEBNskj1gclQTQQpyCyuxlrC1cS3phOqsLV7O1fCte7cWszPSK6MUfe/yRsalj6RrWtbWbKoQQx2x9TgVPzt1E+u5yenQI5rbRnekQ6ktMkC/RwTb8fcw4XN7GnOMAm+WQk4oIcTQSQAvRzmmtKawrZHXh6sbHzsqdANjMNvpG9eWmvjcxMHog/aL64W/1b+UWCyHEPsXVDn7NrWBjbhXFNQ4q6lxU1ruosrvwejUWswmzSeH1atJ3lxMZ6MNzk/pwWVriIfON/X0OcRIhjlOLBtBKqTHA/wFm4B2t9XMHrA8BPgY6NrTlBa31+y3ZJiHaM5fXxaebP+XbrG+pdFRS5ayiylmFVxujwAOsAQyIHsDFqRczKGYQvSJ64WOW/yZCiNZTWGVn+rLdfL0uD6VorHFss5rYXlRDfqUdMAbkhfhZmzxMSuHxalwe42/cLaNSuXVUKkG+knImWlaLBdBKKTPwGnAukAOsUkp9rbXetN9mtwGbtNYXK6WigK1KqU+01s6WapcQ7dW64nU8uexJMssz6RvZl14RvQi2BRPsE0ykXyT9o/vTLaybDP4TQpwwdU43v2wvZVFmEVvyq+kY4U+3mCC6xgTh72Pms5V7+GZ9Ph6tGdk1imBfK7UONzUON1X1LoamhNMnIZQ+8SH0igsmwCY3zkXb0JKvxCHAdq31TgCl1AxgPLB/AK2BIGVk6wcCZYC7BdskxEmv3l1PXk0ebq8bj/bg9rr5esfXfLH1C6L8o3h51Muc1fEsGQQjhDhhdhTXsDqrnIp6J5X1LirqXOwurWPlrjKcHi/+PmZ6dAjm520lzFqT27hfoM3CNaclM2V4Mh0jJH1MnDxaMoCOB7L3+zkHGHrANq8CXwN5QBBwudbaixDiINXOaj7d/CnTN0+n0lHZZJ1Jmbiqx1VMGzCNAGtAK7VQCNFe7U2TsFn2TSpSUedk7ro8/rMml3XZFY3bmk2KED8r0UE2rh2exKhu0aQlh2GzGHe/KutcZBZVU1zt4IwukZJuIU5KLRlAH6r768B5w88HMoCzgFTgO6XUEq11VZMDKXUTcBNAx44dm7+lQrRRXu2lsLaQL7d9yaebP6XaVc3IhJFckHIBNrMNszJjMVlIDEokOSS5tZsrhGgnquwuMvZUsHp3OWv2lLN2TwU1DjdmkyLAx0ygzUJJjROnx0v32CD+cmEPzukZQ2SgD4E2yxHvgIX4WxmcHH4Cr0aI5teSAXQOkLjfzwkYPc37uw54Tmutge1KqV1Ad2Dl/htprd8G3gZIS0s7MAgXot2oddXy6eZPySjOILs6m9zqXJxeY0jAOR3P4aa+N9Ejokcrt1IIcTIqrnawfGcpy3eWkp5Vjr/NTNfoILrEBNIlJojSGgerd5ezenc5Wwur0RpMCrrHBjNxQDyxIb7UOd3UOjzUONyE+VsZ3z+eXnHBkjImTjktGUCvAroopVKAXOAK4MoDttkDnA0sUUrFAN2AnS3YJiHaJLfXzezts3lt7WuU2kvpGtaV1JBURiaMJDEokUExg0gNTW3tZgohTjIVdU6+XJPLzPRsthRUA0be8aCkMBxuDws3F/J5+r5syyCbhQFJYVzQuwNpyWH0SwwlUAbuCXGQFntXaK3dSqlpwLcYZeze01pvVErd3LD+TeAp4AOl1K8YKR8PaK1LWqpNQrQ1da46fs79mdczXmdH5Q4GRg/kX2f9iz5RfVq7aUKINs7p9rJ2Tzk/by9hXU4lkQE+JIb7kxThT4iflf/+ms9/1+fjcHvpnxjKA2O6c1pqBL3jgrGY9005XVLjYHtRDaH+VrpGB2E6RO1kIURTysieOHmkpaXp9PT01m6GEL9JtbOa7RXbWZm/kmX5y1hXvA63103HoI7cPehuqZ4hhDhIXkU967IrKKlxUFLjpKzWSXa5UeGizunBpKBrTBBV9S7yq+zs/bceaLMwYUAcVw5JomdccOtehBAnKaXUaq112oHL5b6MEC3E6XGSXpjO8vzlZJZlsr1iO4V1hQAoFN3Du3NNz2sY1mEYabFpWE0yEl2IU5nXq6myuyitdbKzuJaftxWzZHsJO4trm2wX5m8lOsiXSQPjGdE5itNSIwjxM/5+2F0ecivqKayy0y8hVOomC9FC5J0lRDMqs5excPdCluQsYUXBCurd9VhNVlJDU0mLTaNzaGc6h3amX1Q/wnzDWru5QogTzOPVrN5dzvqcCnIr6smrqCevwk5BlZ2yWice7767wn5WM0M7hXPlkI4MTYkgJsRGuL9Pk/SLA/lazaRGBZIaFXgiLkeIU5YE0EL8Tna3nUXZi/hm5zcszV2KW7tJCExgfOp4zkg4g7SYNPytMkGAEO1Vea2TnSU1FFU5KKyyU1jtwGo2ER/qS1yoH3GhfmSX1fHtxgK+21RISY1RWcffx0x8w/qeHYKJCPQhItBGRIAPcaF+9EsMaaydLIRoWySAFuI38Gov6QXpzN05l+92f0etq5YY/xiu6XUNF3W6iC6hXSSXWYh2rtru4s3FO3hnyS4c7n1zgFlMCo/WHDjEKMDHzOju0YzpHcvpqZGE+lvl74QQJykJoIU4RhX2CjaVbmJFwQr+u/O/FNYVEmAN4NykcxnbaSxpMWmYTdJbJER75/Z4+WxVNi9/l0lprZMJ/eMYPyCemCBfYoJthPn74PZqCqvs5FbUk1teT1iAleGpkfha5W+EEO2BBNBCHEadq47vdn/H4pzFbCrdRG5NLgBmZWZ43HDuSbuHUYmj8LP4tXJLhRC/l8vjZWtBNetyKtiSb9RL9rWasFnM+FhMlNc5KapyUFRtJ6u0juJqB0NSwnn/oh70TQg96Hg+JkViuD+J4ZK+JUR7JAG0EPvxai8rC1by9favWbhnIfXuemIDYukX1Y/Lu11Or4he9IjoQZBPUGs3VQjxG2mt2VNWR0Z2BeuyK1mXU8GG3MrGNIwgmwWLWWF3ebG7PWhtlISLDrYRHWRjeGoEF/XpwLk9YyQFQ4hTlATQQjTILM/kiV+eYH3JegKtgVyYciHjO4+nf1R/+ScpxEmuqNrO4q3FLMos5pftJZTXuQCjl7l3XAh/HJZEv8RQ+ieEkhju1/ie11rj8eojVr4QQpx6JIAWpzyHx8Fb697i/Q3vE+QTxJPDn+SClAvwtfi2dtOEEMdJa01xjYNthTVkFlaTWVjD+pwKNuZVARAdZOPsHjEMSgqjb0IIXWOCsB4hOFZKYTHLB2ghRFMSQItTUpWzip0VO8ksz2T6pulkVWUxLnUc96bdK/WZhThJVNa7+HlbCetzKthdWsfusjqyy+qocbgbtwn1t9I9Noj7zu/GqG5R9OwQLHeUhBC/mwTQot3am8+8tWwrRXVFFNcVU1xfzJ6qPRTVFzVulxCYwFvnvsXwuOGt2FohxNF4vJqNeZUs2VbCoq1FrNlTgcer8bGYSAzzIykigKEp4SRF+NM1JoguMYFEBdokYBZCNDsJoEW7k1eTx5ztc5izfQ75tfkA+Jp9ifKPIsoviqEdhpIamkrn0M6khqYSFxiHSUl+oxBtgdaaGoebijoXlfXGY3N+Fct2lLJyVxnVDb3LveODuWVkKqO6RdE/MVRylIUQJ5QE0KJdyKnOYXHOYn7Y8wOrClYBMKzDMO4edDenxZ1GsI/cthXit9AeD8p8+NrF2utFmQ4dvHodDso//pjA0aOxdep0xPPsKqnl81XZzFqTQ1G146D1KZEBjO3XgWGdIjgtNYLoIBmjIMTROLOyqPruO8KvvBJTQEBrN6ddkQBanLSK64r5IvMLFu5eyPaK7QB0CunEzf1uZkLnCcQFxrVyC4X4fbTTiaugAFdODs7cXNz5+Winc98GShF0/hj8evc64nGcWVlUzJ5D5VdfgUkRedNNhE6ahPLxOew+datXU/yvV7Fv3EiHp54keMyYpm3zeCh+9VXKPvyImIceJOyyy5qs9zqd5NxxB7WLf6L4tdfp8MQTeM46jx+3FFFldzVu5/J4Wbi5iJW7yjApGN0tmqGdwgn18yHE30qIn5XkiABiQyRgPh5a6xPeaXA853QVFVH1zX8JvWQS5pCQFm7ZyaM5f291a9aSc8steCorqZzzFQkvv4StS5dmObYApQ+ca7SNS0tL0+np6a3dDNGKdlTs4MONH/LNzm9we92kxaYxKmEUoxJH0TG4Y2s3T4hm4dy9m6wrJuMpL9+30GRCWa2NP2qPB5Qi5r77CLv6j03+8Wq3m6r58ymf8Tn1q1eDyUTAGSPwVlZRn5GBJa4DkVNvJnTihCaBdN2atZS8+i9qf1mGOTISS1QUjs2bCbvqKqIfuB+Tjw/u4mJy772PuhUrsCYk4MrJIeKWW/iq/0W88uN2OgZZuHPJeyRsWYPpptuoWrSIwMyNzEs5jTd7j8NlstC5Mpdzd69kZG4GLh8/XH360/m8kXQYNQJrhw4n5Dlurypmzabw2WcJGHE6Ubfdhq1z5999zNqVK3Hn5xN0zjkH9WTWrlhJyb/+hTMnh7jn/07AkCFHPtby5eTeex+ekhKs8fHEv/wSfn36NNnGXV5O5Zyv8FZX71toMhE4atQhPzBqp5PKefPwVlVhjY/HmpCANT4ec2Dgb7/oY6TdbmqXLqVi1mxqlywh+oEHCLv8D8d9nJqlSyl48kks4RHEPv44vt26/uY2Vf3vf+Tddz/W2Fgib72Fwuf/gbeujti/PkbohAm/+bitxVNVhTk4uFXOrZRarbVOO2i5BNDiZLGzYicvrX6JRTmL8DX7Mr7zeK7peY0EzeKk5C4poWbJz4SMvahJULxX9rRp1P2yjJi/PIw1IRGfhHgsMTEoy74bh56KCvIeepiaH38k6Lzz6PD03zD5+1M1bx4lr72OMysLn5QUQiZNJGTceKwx0Witqf15KcWv/gv7uvWglPHYy+vFHB5OxA03EDb5CpTZTNGLL1H2wQf49u5N+LXXUvj3v+OtqSH2sccIuXgsOx9+FOfcr/hfxzTWTbyR8f99k67b1/KvfpOYlzIcs9fD7bsWcv6v36FTUrGaTbi3bwMfH3xHjcbi9VC/ahWeykoA/IcNI/avj2FLSTnkc+d1OnHn5eHMzcWVY8wQ6p82CJ9OnRo/RHjtdqq/W0jl7FnYM7cRdNZZhE6aiG+/fvu2cTioX7cOx+bNmMMjjMArPh5LVORh01IO5KmupubHH7EmJuI/YMAx7XM0zj17qEtfTfAFYzD5HftMp976egqe+huVs2Zh69kDV9ZuvPX1BF94IZG33XrUNJrDqf7hR3L+/GdwuVD+/gSffz4hEyeglKL4X69St3IllqgolJ8frpwcou68k4gb/nTQc6i9XkrefJOSV1/DJzmZyFtvpfjFF3EVFxPzwAOEXXUlnooKyt7/gPKPP8ZbV3fI9gSOHk3ktNvw69UL7XJRMXs2pW++hSsv76BtfVJTCZkwvvH1D8b7pvK//6Vy9hw8ZWUEX3QRIZMmNr7evPX1VC9cSMWsWTg2bca3b18Chg7Bf8gQfLt3x11ejis3F1dODvbNW6j65hvcxcWYw8KwduiAfdMmYp98grA/NA2ia5evoOCJJ7BERBAyaRLB55+HKSAAd1kZhc89R9XXc/FJSsJTVYWnupqI668n8tZbMPn64i4tpXLuXONDRV0dIWPHEjJpIj4JCQddc9lH0yl89ln8+vUj4Y3XsYSF4SoqIu+ee6lbtYrgcRcTOHIkPg0fNMwREcfU6629XhzbtlG3Kh1nVhaunBzjecjLQ9lsDR9c4vGJj8cU1DTYtURF4T9kCD4J8Uc9z15eh4Oa77+nYvYc6lasoPOPP2CJiDjm/ZuLBNDipFXjrOGNdW/w6eZP8bP6cXXPq7mi2xVSbq6NsG/ZQt6DD2GNiSFy2jT8+vRuXKe1pmbRIkrffAtrYiJx/3j+kH+oi//1KjU//kiHZ5/9Xb0ux0JrjTMri/o1a1A+Pg1BU8IxB02eqiqq5s2jcvYclNVK7FNPHjbQO9z5K7/8ksJ/vIC3spKIG28k+p67m2xTu3wFe6ZMIerOO4m8eepRj1f23vsUvfgi1vh4lMWCc+dObN26ETntNoLOPvuQ16W1pnbJEurWrm2y3BIVReiECZj8m05BXb1wIXkPPYy3uhqflBTi/+9lrJ27sGBDAQ/PWs+E9fO5YtO3mEND8VRUEPXIIxSMHsuG3Ep6x4fQKy6YmkWLKHjiSeMcl0wi+MILG3uVtNeLIzOTmp+WUPrvf6MdDiJvuZmIP/0J5ePTJOixb9wIh/jfZY6MJGDIYEwBAVQt+BZvdTXW+Hh8e/em5qef0PX1+KSmEjhiBPYtW6hfu7ZpSkwD5edH+LXXEHnLLZhstoOfO6+XuuXLqZg1m+rvvkM7jJztgOHDibx9WpNA2l1SQt2qVXhraxsDdGts7GHTZ6oWLCD/L4/gra3FHBVJ5A03EHr55Zh8jRQW7XRSv2EDjsxMLJGRjcd0l5SS++c/49i+nchbbibyttvwVFVR9t57lH3yKdpuJ+CMEYROnETgWaMxHSF9p8nv/ccfybnjz/h270703XdRNW8eVfPm462tNZ7zqEgib7yJ0Mv/gHa5KXjsMarmzSNg5JnEPfcceL2NwWbFl7OoXbqU4IsvpsPjf8UUEGB8CHzwIWoWLcI/LQ375s146+oIvmAMkbfe2qT33FNTQ/nHH1P6/gd4KysJGHkmzh07ceXk4Nu3L1G3T8O3Vy/jfLm5OLOzqflxEfVr1jTegTH5+VPz/fdolwtbzx5YoqKo/XkpeDz4DRiAT0oK1f/7H96aGqwJCfinpVH/6684d+w49BNkNhN45pmETJpI0MiRaCBn2jRqf1pCh789Reillzb94JCYCBh3mJS/P0GjRlG7dCmeujoib7yRiKk34a2ro+j5f1A5ezbWjh2xdelCzeLF4Hbj268v5oBAapctA63xHzIE/7RBuAoKG59nV24uQeeeQ9w//tH4ugGjp7z4X69S+s474PE0Ljf5+xN4ztmETpqE/5AhjX8vtNZGwLxyFXUrVlC3ahWeigpjn8DAxl5+a1wc2m5vfN5deXlo1740rf1Z4+PxHzIEv379GvaPwxoXh7JacReXNB6jfu0aKv87D29lJZYOHQiZMJ7wq6/GEh5+TK/b5iQBtDhpuL1uyuxlFNcVs7F0I69nvE6ZvYxJXSZxx8A7CPc98W8gcTCtNRUzZ1L4t6cxhQSD04WnsrKxd8hTUkLxq69h//VXzGFheMrLifnLXwi/+o9NjlOzZAnZN94EFgvKYiH20UcJvWRSs7e16r/zqFm0iLqVK3EXFR20jbJascbFNb39GxzU5Bj1q9dQvXAh2uHA1qUL7uJitMtFh789RfAFFxy1HY6dOyl47K/UpafjlzYIS1QU1Qu+peP77xEwbJhxHo+HXZdehqeygtR585r8AzySujVryL37HsxBQUROm0bQuecccy/q4ZTVOsksrMbu8mB3efHk5WD5eTE/9ziT9WVOthZUYXd56ZcQwstXDCBs8QIKnn6G6LvvJvyPV/3m87qKiih89lmq5y/Ap3Mqts5d9gU9PXoQNHo01o6JjT1o2umkduXKxn/0nqoqgs8/j5CJk/AfMhhlMuGpqaF6wQIqZs2mPiMDW/duBAwegv/Qofj17YOnsrLxn3fdqlVUzZuPNakjHZ54ovF348zOpnL2bCrmzMGdl48pOJjgiy4k5OJx1K9dS+m77+IpKyNgxAh8OiZSu2LloQMvkwlbly6EjB9PyLiLsURG4nU6Kfr785R/8gl+/fsTceMNlE3/mLrly7FERRE8diyOrVupW7sWXV9/8DGVwhwaStw//kHgiNObrHKXlVH20UdUzp6Du7AQc0gIwRdfjC21aY+0NbEj/gMHNH54qlm8mJxpt2Pr1o2O773b+GHHW1dH9cKFeO12QsaNaxqkaU3FjBkUPvMs2u1u8kFH2WzE/OVhQi+7rGm6kddL2fvvU/x/rxB41llE3XbrEXN1PdXVlE2fTvmHH2Ht2JGoabcRcOaZh+1FdezaRWXDGADtcBA87mJCJ03Ct3t3oCEfe+5cKmbNxpWXR/B55xEyaRL+g9Ma30PukhLqVq7Evm0b1ujofX8n4uIOeo96HQ5ybptG7dKlxDz4ADU/LWnywUH5+1O/di0Vs2ZRveBbfLt3J/bxvx6UalO7fAUFTz6Jp7qKkHHjCJ04sXEbV34+lV99RcXs2bh278ESFdX4d8uvT2/C/vjHww7+9dbW4srLw5mTgys3D/uWzVR/+7/GD5xB55+PKy+PupUr8ZSVGa+NuDj8hw7Ff8gQAoYMxhp/+J5k7fUav/vGBRrn7t2HDMT3UlZrk6Bb2WwEnXMOIZMmEjBs2BEHMrc0CaBFm5Zbk8vnWz9nwa4FFNYV4tXexnV9I/vy8NCH6RV55IFS4sTx1taS/8QTVH09l4DTTyfu+b+jbLYmvUNg9DZE3noLIRdfTM7td1C7bBnJM7/At1s3wPintHP8BCzh4SS88Qb5jzxC3fLlhEycSOxjjza5fb23h7JuxQpqV67CmZVF4MiRhE6aeMQcT601Rf94gbL33sMcFdkYNPkPNv4eNvaaNAzUc+Xm4crNxVNaetCxTCEhhFx0ESGTJuHbqyfuggJy77qb+oyMJjnCjef2eLBv3tLQ5hXU/bIM5edHzP33ETJpEtpuZ9ell+GtqSHlqzlYwsKo+PJL8v/yCHH/fIGQiy46rt+L9niMPOnfOAipqMrOkm0lpO8uY1VWOduLag65Xai/lR6xwfToEEzfhBAu6tuhcTa/o1XtOB7VixZR+ORTRo/kuIsJnTgR3x49jriP1ho8niapLgdt43YfcT1A7S+/kP/4E7j27CH4wgtwFxVTl54OShFw+umETppI4NlnN+mh9tbWUv7ZZ5S++x5ehwP/QYMab/2bw8Nx5TS81nJzqFm61EihsVgIPPNM3EVF2DdsIPy664i++67GtJ7alSsp+der1K1aha1rV6PHcegQ/Hr1MlIJGo7pqa4i7IorsMbEHP66PR5qf/mFytmzqV74/SF737FY8OvTB99evaj4/HNsXbrQ8f33jnugn33TJqoWfGsEdg295D6JCQfd2TiwfS0ZKGmtQevDfrA82vrj4XU4yLnlVmp/+QXl40PMX/5C6B8uO+i9eSyDBo+0jdbaSK05xjsKh22v3U71wu+pnDWL2mXLsMTGEjBkSMPrbehxpV6wZwXUFkFoR+Ph1/RusfZ6cRcU4Moz/tY6c3PRdXVY4uIaPxRb4+OPufOgpUkALdocrTXL8pbx2dbPWJy9GJMycUbCGXQL60a0fzRRflHEBMTQPby71GluRVpran/6CXtmZsM//zwcW7bgLi0lctptRE6d2uSfnqe6moovv8QcFETIxRc3/mF3l5Wxc/x4zCEhpMycibLZyL75ZuqWryD5PzPx7doV7fFQ8voblLz+OuaQEExB+3qAPZWVeKuM6ZitHTtijY+jblW6cVuzb19CJ00iZPy4pkG31hT/85+UvvMuYVdOJubRR485uPTW1R2Ug2kODj7oH5V2uYwc4fffxxwe3mSAlae8HG+NEYT6pKQQcPrpRN48FUtkZOM29k2byLr8CgLOOIO4559nxwVj8IlPIOmzT09IFYU9pXV8u7GABRsLWLOnHK0h2NdCWnI4aclh9IkPIcBmwWYx4Ws1E2SzEBV04iYn0VqD19sqPVBeu52SN96k9N138YmPJ2TiREImjMcaG3vE/fb2vh0tSHds307lnDlUfPUV2uEk7pmnCTrnnEO3xeE4ZDrJb3Xg69v4gLrN6CFcuZL6DRvw7dGDju/8G3NoaLOd91Titdspffddgs4666gf/NoSr92Osv2G93jWz/Djs7D756bLbSEQ3QOSRxiPxKHgc/gPUm2NBNCizXB6nMzbNY8PN37I9orthPuGc0mXS/hDtz8QG3Dkf0ztnXP3bopeeAHfnj2JuPnmY/oD5i4vx7lrF749ezb7J3ZPdTX5f3mE6v/9DwBzaGjjrcuwyZMJGDb0uI5X8/NSsm+4gdDJV2BLSaHwmWeJefQRwq9qeru/dtkyKud8hd7vToTJzx//gQPwHzKksUqDu7SUyq/nUjlrFo5t2xryMW8k9A9/QNlsFL/4EqX//jehk68g9rHHWjToq/7xR6oXLGD/v6mmgAD8B6XhP3hw4wCmQyn94AOKnvs7vj17Yt+0ieTPZ+DXr1+zt9Hp9rK1oJq12eVk7KlgbXYFu0qMXNZeccGM6RXL2T1i6B4bhMkkddP38jocKB+fFnv9aLcblGrV29QH+s1BlDh51VdAxR6oygXvfikYKCMADu/UdMAxgKsedi+Fpf8Hu36CwBgYcTd0HGocq2IPlO+GvLXGQ3vAZIVOo+DM+4ztjqY8C/Ysh76XH3z+E0ACaNHqqpxVfLH1Cz7d/CnF9cV0DevKtb2uZUzyGHzMv+/208lOu1yUvvc+Ja+/btyGd7uJmDqVqDv/fMR/YPYtW8i+aSruoiKUjw9+/frhP3Qovj17NPlnbIntcNyD8+ybNpFz5124cnOJvvsuQi+/vFlKQhU+/w/K3nvPuHV9xhkkvP7a7/4nrbWmbtUqSl59rbEigN+gQVQvWEDoH/5A7ON/bZbbsi1Fe71kT72Z2iVLCB47lvgX/vG7j1lYZWfp9hI25VWxs6SWncU1ZJfX4/Eaf/OjgmwMSAxlSEo45/eKJTH85OkREkI0qCuDos0QEg/BCWA+zF2P6gKjhzhrCeSvA+++QYR43VCZC47KI58rOB6Sz4COwxqOtwRyVoHHCQHRMOIuSLsOrIepHOOoNgLhXYsh4zOoK4HUs2H0w5CQZuTL15dDxW7jmnYtMdpcucfYf1o6RJ74OtYSQItWU2GvYPrm6Xy6+VNqXDUMjxvOtb2u5bQOp0nvBlC/bh35jz6GIzOToPPOI+bhhyh57XUqZs4k8tZbiLrjjkPuV/vLL+TcfgemoCCi776rMdfWvnnzISsUJLz+GkFnnXXQcsf27RT980VMfn6NuWfemmqK/+8VzGFhxL/0Iv4DBzbb9Wqnk6wrr8JdVNSY99uc9takrUtPJ/SyS4l94ok2HTzv5S4poeTtt4m44Qas0YfvrT4cu8vDsp2lLMks4eftxWQWGqkjNouJlMgAUqMC6RQVQNeYIAZ0DCU+1E/ef0K0JK8XSjIhPAUszZd+Axh/4zM+hf/9xQg6AZTZCHIDo2H/tMf6Mig1JhvDFgzxA8GyX5BrMkNQBwhLMnKWgxPAsl+nlscJuWsaAvCfjcAXBR36GgF1ypnG1+NJy3DWwsp/Gz3X9WUQngo1ReDcr+63X1hD2seZxtfoHtID/XtIAH3yKK0v5cNNH/L5ls+pc9dxbtK53NjnRnpEnDy5YC1tb4koS0QEsY892hjgaq+X/Mceo/I/XxI5bRpR025rsl/lV1+R95dHsHXqROLbbzXJyfRUVuLcvXvfxlpT8ORTOHfvJvmLL7B12ldyzVVYRNYVVxgls0JCcOXnQ0P+ZsCIEcQ9//cWKRvkdTjQTifm/XKcm5PWGldODtaEhHYbJLo9XoqqHSzdXsLCzYUs2VZCndODj8XEkORwRnSJZETnSHp2CJZ0DHHq0dpIH7AFgf9v+BvmssOajyB3NQyaAkmnHbyN1wNFm8A/AgJjYe8H9fLdsO4zI8Ct2A2RXeHi/4Ok4Udvc9lOKN6yL/2hYg/4BOzLHw5LgdId8M2dRg9w4jA4/Q6oK923fc0BVYas/pA4BFLOgNh+h++lPhZaG+cPiAS/0N9+nL0cNbDq35CTDiEJ+wYehqdCVPd9z2krkgBanDBFdUW8v+F9/pP5H5xeJ+cnn89NfW6ic9jvnw2rPWlSIurddw4a5a69XvL/8giVs2fjn5aG8jd6DLTTRd3y5fgPHUrCq/86piDUlZfHrksuxRweTvLnn2MODMBTU8PuP16Na88ekj6ejm/PnmiPB3dREZ6KCmzdup0UPbft2Z7SOnYU17C7tJY9ZfXsKaujsMpOYZWdkhoHDdkYxAb7cnaPaM7pEcNpqRH4WttOLq0QJ0xVHuz40Qgsdy2Bqhyjp3Xwn+D0OyEw6ujHcDuMwHnJi1CdZwSfrjojZ3fUw0bObsk2WPsxrP8cqvON/cw+EJJoBOz5GYCCTiOh8zmw4m0jDWHgtXDuE/uqUjjrjAA7e6XR5qyf9x0PwBpgBJN1pUZVCzB6h2uLweIL5z4OA6e0iSCzPZMAWrS4vJo83tvwHrO2zcKrvVzU6SJu7HMjySHJrd20Y6Y9Hrw1NYct2aS1xlNRccS0A3d5OebQ0CP2fNYsWULObdOwde58xBJR2uOh6MUXqVu5qslyv379iLn/vuMqXVS7fDl7rv8TQeecQ/wL/yD75luoXbGCxDffJPCMEcd8HNGyiqrtfJ2Rx6w1uWzKr2pc7mc1kxjuR1yoH9FBNmKCfYkO9mVAYii94oLbbU+7EEfkqoct/zUC2p2LAG30CCePgKTTjdSDX78wAs7BNxgD0Uz79cA6qo0gdm/v7bbvjMC742kw6iFIGAzp78HSl43ANbyT0UuszNDlXOg5AVy1TXt/O42CflcYwS8Y6Qo/PgPL3zB6w0M7GtvWFu9rR2BMQy/zGUZqRGiysa1SRq9vSaYxSC/rZyNIP+sRCDq1B92fKBJAixaTXZXNOxve4evtX4OC8anj+VOfP5EYlNjaTTsu7vJycm69DfvmzcT+9a+ETpzQZH3jtMmLFhHzyF8Oqhyhtabk1dcoee01QsaPJ/avjx2y5mnNz0vJufVWfFJTSXr/vRNaIqr0vfcpev55fDqn4ty+gw5PP93sk5aI41fv9PC/TQXMWpPLkm3FeDX0TQhhQv94+iWG0DE8gMjAlqsCIUSb5/UYPcyNqQ27jVSCzG+NwW8hHaH/ZOg5HqJ6NO2VLdkGi5+HDf+B/Sr7HMQ/AmJ6G4PhOo1qmm/rrIVV78L274xe5b5XQNDha24fUv46+P5JY9De3lSF0CTo0N8YHCfv7zZJAmjRrLzay8aSjXy25TPm7ZqHWZmZ1GUS1/e+ng6BHVq7ecfNmZND9g034srLw9atG/ZffyXkkknEPvIIJj8/6tevJ/fOu3AVF+Pbowf29euJuOFPRN19N8pkQrtc5P/1cSpnzcJvwADqMzLwSe1EwssvN07y4czOpuTNN6mc81Xj5ATNPYDuaLTW5N1zL1Xz5h0yt1qcOF6vZvmuUmavyWX+hgJqHG7iQnyZODCeiQMS6Bz9+yueCNFiPC7jcaiBY44a2PQVlGyFHuMgflDT4NDjMgLfnYuMXNq9gWRQrNGDu3+QvLd3uDLn4NJqQbHGALb+Vxk9t0dLZSjZDgXrmy7zaUiTCEkEm7znxMEkgBa/W7WzmiU5S1iSu4Rf8n6hzF6Gr9mXy7pdxnW9riPK/xjyy9qg+g0byZ46Fe12k/j6a/j160fxa69R+sab2Lp0IeiCMZS88SbWqCjiX34J3549KXj6aSo+m0HwRRcR88hfyLvvfmp//pnI224jctpt1C1bRu699+Gtryf6vntxbN5Mxew5KJOJ0CsuJ+rWW1ttcgKvw0H9unX4Dx4sPZqtYHtRNbPW5DJnbS55lXYCbRYu7BPLxAEJDE0JlwF/onW47EYe7+GCUI/bqOObtcR47FkBbrtR0WFv6oHFZpQn2zjbSGtAARoiu8GAq4wBb5u+MnKH60qMHF9XnbHNoQTG7Auu9/bYhiUZP4ckNH9lCyEOQQJo8busyF/Bg0sepKS+hDBbGMPjhzMifgRnxJ9BiO34png9kY42TWrNkp/J+fOfsYSGkvjOv7F16rTfuiXk3Xc/nooKAkePJu7ZZxqDXq01pf9+h+IXX0T5+qJdLjo88Tihl17auL+rsIi8e+6hLj0dZbUSevnlRNx44xEn1BDtg93l4YctRazKKsPu8uBwebG7Pewpq2NDbhVmk+LMLpFMHJjAuT1i8PORQX+iheytvZu9whi0tpf2Qk3hvp7e2mKjF7bfZOh/pVF6DaBwE2R8YgS9e3N2o3oYFR18Ao1JNHJX7+sd9gmEXhNhwB+NsmMb5xj7Z68w1pus0G0M9P+jkQqhPUbvcsVuo7ZwQHRDsJx4+HrCQpxAEkCL38TtdfPmujd5e/3bJIck89fT/kr/qP6YTW3/H772eNhz7RQwm4l/+aWD0iVqliwh59bb8OncmcS33jxk7V1XYSH169cTdM45hwzEK+fOpeTV14h5+CECR448uA1uN1Xffov/oEFHnf5XnNw8Xs3S7SV8lZHHtxuNlAx/HzOBNgs2qwlfi5lQfytjendgXL84ooKk90y0kOoCWPWOUZFi7+xvymxUlNhfYNS+nt3gBMhebuyDhqQRRi9y3lpj0F3XMdB7klGT98BqFo4aI0B2VEGX84y0iAOVbDOOlXo2BES02KUL0dwkgBbHraC2gAd+eoA1RWuY0HkCDw15CP8D/wCfAFpr6levpmLWbKq//x5bl86ETpxE8JjzMQUc4g91g7KPP6Hwb38Dsxmfjh1J/Pfb+CQkAA09z7fd1ioD+UT7orXmf5sK+ce3W9leVEOQr4ULescyoX88QztFYJaUDNGctDYGo+1eCrF9IGEIWH2NdTVF8PPLkP6ukWeckLYvvSJxyKED2wNV5hg1jNd/YaRI9LsS+v7ByFUW4hQkAbQ4Zk6Pk082f8Jb69/Cq708OuxRLk69+IS3w+t0UvbBh1R8+R9cu/dg8vcncNQo7Bs34ty9G+XvT/D55xN56y34JDat+OEuLmbHBRfi17cvkbfeQvZt01BWK4lvvomnssLoeU5JaZWBfKL9WLmrjOfmb2bNngo6RQVw5zldOa9njNRhFodXWwJf3WYEqhe+cOgJOg633/ovjHSIwg37lpttRnAcmgQbvjRmjet3BZx5r1FyTQjxu0gALY5Ka80P2T/wz/R/kl2dzciEkdw/+H46Bnc84W1xZmeTe+dd2DduxH/IEEImTiT4/PMw+fsbPdJrM6icPYuq/87DFBBAx48+xJayb4a93Pvup3rBAlK+/gpbSgqOHTvIvvEm3BUV4PHgk5xMxw/el+BZHDOXx8vm/CrW51Tya04l63Iq2FJQTUywjTvP6cplgxKwmGVCA3EEe5bDzOuMiTECIqEq15jl7pwn9s3q5qwz0iHy1jatT1yeZeQZxw00BuR1OR8KN+4b1Fe0GXpNgpH3Q0RqK16kEO2LBNDiiIrrinlk6SP8kvcLnUM7c1/afQyPP8q0oy2k6rvvyH/4L6AUcc8+Q9DZZx92W3tmJnumXIeyWEia/hE+SUnULl/BnilTiLz1FqLuuKNxW1dRETm33ob2eOj47jstMkW1aH+01nyzPp/n5m8ht6IegDB/K30SQjmjcyR/HJYkgwBPVvXlsOx12DTHmHRjwB8PLrnWHLSGX/4FCx838o3/8CFEdG6YXON18I800iRyVxtTGntdxn7+kftylCO7QO9LjIF5hzuHVNURotlJAC0Oa0X+Ch746QFqXbXcNegu/tDtD1j2n6npBPHW1VH8f/9H2Ycf4du7N/Evv9SYs3wk9q2Z7JkyBWWz0fHdd8i5/Q6000mnb+Zi8vVtsq3WGrxelFkCHnF063MqeHLuJtJ3l9OjQzC3jEplQGIoCWF+UgLwZFZfYcwKt/x1Y+Bb4jAjr9hdb5Rc6z/ZmNwiLMkYXGfxgerCpiXcLD77lVjbr8xaaEejnrCjxuhxzvoJdvwABb8aNZHHvwq++1Uuyl8Hc/9sfI0b0JCzfKaRluEb3FrPkBCigQTQ4iBe7eXt9W/zxro3SA5O5p8j/0nnsM7NdnxPTQ2OzZvxS0s7YrDhra+n/LMZlL77Lp7SUsKuuoroB+7HdBzTVNu3bGHPlOvw1tWhnU4S33rzkFUxhDiagko7P2UWs3BzIf/bVEhkoA/3nteNy9ISZUBgW1RTBMVbjNSGo02EYa+E5W/C8teM77uPhVEPGoPx7JUHl1wDQBkz1NWVGD/agqHjMKPHd2+Khdve9Dx+4cbxtMco25aQZkwhPWjKoXuJtTZyl6WusRBtjgTQogmnx8mff/wzP+f+zEWdLuKxYY81a4UN7XKx+7rrqE9fja1nD6KmTSNw9OgmgbSrsIiq+fMofeddPCUlBAw/jchpt+M/cMBvOqd982b2XHc9/sOGkfDyS811KaKdc7g9pGeVszizmJ8yi9lSUA1ATLCNiQMSuG10KkG+1lZupTikzP/B7JuMVAyTxQiiU86AxKEQlrKvlrCjGla8Cb+8CvYK6HaRETh36Hvo41blQdlOKG8IkKtyjRSK5DOgQz/Yv4yn1kZ95L15yntzlv3C9rXlWKpfCCHaJAmgRSOtNY8ve5xZ22bxl6F/4fJulzf77eiCp5+hfPp0wq6+mprFi3Ht2YNv796ETJqIY8tW6lauxJmVBYD/sGFE3T4N/0GDfvd5vXV1KJtNUjTEEWWV1LI4s5jFmcUs21FKvcuDj9nE4JQwzuwSxchuUXSLCZI0jbbK44Yf/wY/vwQxfYyBc/kZsGsJ5K1pOuVzQDS4HeCohK4XGIFzXP/WarkQ4iQjAbRo9OnmT3l25bPc1Pcmbh9we7Mfv/Lrr8m7/wHCr72GmIceQrtcVH49l5I33sCVk4MpMBD/tDT8hwwhYPhp+Hbv3uxtEGJ/WmuWbCth4eZCFmcWs7vUmJEtKcKfkV2jGNk1imGdIgiwnfjcf3Ec7JVQugO+/Qvs+cVIiRjzXNMZ6xw1Rpm3imyoyDJ6gz0uGHKjMUBQCCGOgwTQAjAGDE79bipnJJzB/43+P0yqectu2TdtImvylfj17UvH995FWffd+tYuF87sbHw6dkRZJFARJ8aO4hr++tVGft5egp/VzPDUCEZ2i+LMLlEkR8qt9TanKs8YULc3faJi975cY3ulsY3VH8a+DP0ub9WmCiHav8MF0BLFnEJyqnO4Z/E9JAcn8+yIZ5s9eHaXlJBz+x2Yw8KIf/mlJsEzgLJasXWSwv7ixKhzunn1h+38e8lOfK1mnhzfi8sHJ2KzSHpPm1S+G5a8ABmf7kvBsPgZlTBCOxq5xHurXSSkQcjRK/QIIURLkQD6FLG1bCsP/PQAXu3llbNeIdDnKKPVMfKJMZkOKgXXuL6+nrpVq6hdsYK6FSuxb9qEMptJ+uRjLBERzX0JQhzRzuIaNuVXkVlYw7bCatJ3l1Nc7eCSgQk8dGF3IgOlwkGbVLEHlvwT1n4MygRp10OfP0BYsjHZiOShCyHaoBYNoJVSY4D/A8zAO1rr5w5Yfx9w1X5t6QFEaa3LWrJdp5LC2kJezXiVr7Z/RbAtmBdHvXjUmQXd5eWUvfsuZZ98ijKZCLpgDKETJ+I3cCAA9WvXUjFrFtXzF+CtrQWrFb9+fYm8+WaCzjtXcprFCVVZ5+LxuRuZvTYXAJOC5IgA0pLCuO70FIakyIQ5raZoC6z5EILjjPrGsX2NChYuO2z9L6z9BHb+aFTQGDQFRtwNIfGt3WohhDiqFsuBVkqZgUzgXCAHWAVM1lpvOsz2FwN3aa3POtJxJQf62Lg8Lt7+9W0+2PABHu3hqh5XcUOfGwixhRx2H3d5OWXvvU/ZJ5+g6+sJvvBClM1G1YIF6Lo6fJKSQCmcWVkof3+Cx4wh+MIL8R80EJOf32GPK0RL+WFLIQ9++StltU5uHpnKBX1iSY0KxNcqaRrNomADrHqnaVWLA5l9jMF5ySOMdAuA4q2w+O+wYZYRHO+dWc83xCg1l7fWKCcXHA/9JkPadZKSIYRok1ojB3oIsF1rvbOhATOA8cAhA2hgMvBZC7bnlFHpqOSeRfewomAFY5LH8OeBfyYh6Mj/nDw1NeyadAnuggKCL7iAyNtuxZaaCkDsXx6m6n/fUfnVV6A1ETfdRPD552EKkAFYonUUVdv5x4KtzFydQ7eYIN6bMpje8Yf/cCh+g/x18OE4o4KF7xGeW2ctpL9rfB/aEcJTYeciY6DfiDvhtNuNSUKyfjZm8ctZBZ3PgQFXQcrIpjWVhRDiJNGSAXQ8kL3fzznA0ENtqJTyB8YA01qwPaeE7Opsbvv+NrKrs3l6xNOMSx13TPsVv/IK7oICkj76EP/Bg5usMwUEEDpxAqETJ7RAi4U4dtsKq3lnyS5mr83F7fVy2+hU7ji7iwwMPByv1/hqOs4BwwW/wkfjwScQrvuvkY98pHMUbzGC410/QeFGOP0OGH6HkcO8V9/LjIcQQrQDLRlAH2rkx+HyRS4Glh4u91kpdRNwE0DHjkfO3z2VrStexx0/3IHb6+btc99mcOzgo++EMYNf+cefEDb5ioOCZyHagozsCl75fhs/bCnC12ri8sGJ/GlEipShOzAFT3uNADZriTGpyO5fjGmmQxP3VbCIGwC9Jhy+V7lgg9HzbPWHKd8cOXgGIziP6Wk8hk5tjqsSQog2ryUD6Bwgcb+fE4C8w2x7BUdI39Bavw28DUYOdHM1sD35tfhX/vTtn4j2j+a1s18jJSTlmPbTXi8Fjz+BOSyMqD//uYVbKcTx2VFcwwvfbmX+hgLCA3y465yuXH1aEuEBPq3dtBPPUW2UeCvatG+66Ips8DgOvX1YCvQabwTKe7fPWwur34f5D0CPi400ioQhxlTV5buhfBcsehYsvkbwHH5sf0eEEOJU05IB9Cqgi1IqBcjFCJKvPHAjpVQIMBL4Ywu2pV1zeBw8svQRwnzD+PjCjwn3PfaqAxVffkn9unXE/f05zCGSQyrahsIqO//3/TY+X5WNr8XEned04YYzOhF4Ks4U6KiBlW/DL/+C+jLwjzB6k2N6Q7cLjDSL/YUlGwP6DjUoT2tjquu1n8CG/8CvXxy8TWhHuHoOhEvNdiGEOJwW+2+ktXYrpaYB32KUsXtPa71RKXVzw/o3GzadCPxPa13bUm1p795c9yY7K3fy5jlvHlfw7C4vp/iFf+KflkbwuGPLlRaiJRVV2Xl90Q4+XbkHrTVXD0ti2lmdT60azs7ahmmodxsD+Va8CXWl0PlcGPUQJPyO6aiVMipmxA+C85+BLd9A2S4jaN77CIqVgX1CCHEULdqdo7WeB8w7YNmbB/z8AfBBS7ajPdtYupH3N7zPhM4TOD3+9GPez1tfT+Ezz+KprSX2r4+hZLIC0Uq01mSV1vHx8t18vHw3bq/mkoHx3H5WFxLD/Vu7ec1nwyxY9JzRazzgjxDZxViutREoZ3wCm76GmoKm+6WebQTOic08PsHqC30ubd5jCiHEKeIUvB/afrg8Lh5d+igRvhHcN/i+o26vtaY+I4PKWbOpmj8fb00NEVOnYuvS5QS0Voh9quwufsos5udtJSzZVkJuRT0mBZMGJnD7WZ1JijgJBwfWFEN51qED3V0/waybIDDaSMVY+rKRe9xpJGydD4UbwGwzgusOffcN+AtLNvYRQgjRpkgAfRJ7+9e32Va+jVfPepVgn+AjbuuprGT3ddfh2LQZ5edH8HnnETJpEv5DpOqGODG01izfWcYX6dnM+zUfh9tLkM3CaakR3DyyE6O6RZ+8Pc51ZfD+BVC6DYbeAuc+CZaGgY6Fm2DGHyEiFa5fAG4nrP/c6HH+6R/GxCIX/RN6XwJ+Ya17HUIIIY6JBNAnqY0lG3ln/TuM7TSWkYkjj7p90csv49iyldjH/0rw2IsxB56EPXzipGR3efh4+W6mL9/N7tI6gnwtXJaWwIT+8fRPDMViPs4axW2Nyw6fTTZylvtcBivegJyVcNkHxix8n1wGVj+46j/7AuTT74Dht0N9OfjLVONCCHGykQD6JFRUV8QdP9xBlH8UDw558Kjb1//6KxUzPifs6j8SdsUVJ6CFQoDHq5m1JoeXvsskr9LOkJRw7jynC2N6dcDPp50MUvN6YfZNkL0cLn0fek8yysN9NQ3ePMNIv7BXwHXzjVrM+1NKgmchhDhJSQB9kql313PHD3dQ46rhows+IsR25NJz2uOh4PEnsERGEnXHHSeoleJU9+PWIp6dt5nMwhr6JoTwwmX9GN458ug7nmz+9whs+grOe9oIngF6jjdKzM28Foo2w5WfG3nNQggh2g0JoE8iXu3lkZ8fYVPpJl456xW6hXc76j7ln3+OfeNG4v75AubAwKNuL8TvUVzt4Im5G/lmfT7JEf68duVALuwT276qvFQXQNbPkPmtUUd56C1w2m1Nt4lIhRt+gNqiQ9djFkIIcVKTAPok8sa6N/jf7v9xz6B7ON3UhfxHHyVkwgT8Bx26Lqy7pITil17G/7RhBF944QlurTiVaK2ZuTqHp/+7mXqnh3vO7crUkan4WE7y/Oa96spg2WtGb3PpNmOZLRgG3wjnP22kYxzI4iPBsxBCtFMSQJ8kvt/9PW+ue5OJnSdyba9ryX/kESq/nEXFzP8QMPw0Iqfdjv/AAY3be51OCv/+PNpuJ/ZRqfMsWkatw82CDQV8unIPq3eXMzg5jGcn9aVzdDu521FXBstehRVvGROcpJ4FA68xZvrr0E8mHBFCiFOUBNAngXJ7OU8uf5KeET15dNijeMrKqJr7DSETJ2Lr0oXSd95h95VX4jdwIGiNKzcXd1ERABE3T8XWKaWVr0C0Nyt3lfH5qmzmb8inzumhY7g/T0/szeTBHTGZ2sGHtfpyo8d5+ZvgrIFeE2DkAxDdo7VbJoQQog2QAPok8OyKZ6lyVvHOee9gNVspnjED7XQSceON2DqlEHbF5ZR/+imVX8/FHBpKwOmnY02Ix5aSQtB557V280U7siG3kr8v2MKSbSUE2SyM6xfHpIEJDE4Oa/t3OeyVULYTyndDxR6oyjUmK0k+wxj0ZzJBfQUsfwOWvw6OKmNA4MgHIaZna7deCCFEGyIBdBv3/Z7vmZ81n9v630aXsC54nU7KP5tBwMgzG3uWTf7+RNxwAxE33NDKrRXt1e7SWl74XyZz1+UR5m/l0bE9uXJIx7Zfjs7thMwFxqQl274D7dm3zhoArlrje99QSBwC2SuMQLv7WGP67NjerdJsIYQQbZsE0G1YpaOSp5Y9Rffw7vypz58AqPrmv3hKSgi/5ppWbp04Fbg8Xt5ctINXftiGxWTi9rM6c+OZnQj2tbZ2046s4FdY+4lRJaOuFAJjjUoZiUOMXufQJPALhcpco6JG1k+wZ7nRGz3yASk7J4QQ4ogkgG7D/r7y71Q6Knnr3LewmqxorSn78ENsXboQMHx4azdPtHMbciu57z/r2ZxfxcX94nj0oh5EB/u2TmMqsmHzXOh+IYQlH3qbujL4dSas/RgK1oPZB7pdAP3/aAz+Mx/iz11IPPS73HgIIYQQx0gC6Dbqp5yfmLtzLjf3u7mx3nPdipU4tm6lw9+eavv5puKk5fZ4eXnhNt5YvIPwAB/eunoQ5/eKbb0G5WXAp3+AmkL49iGjl3jAH6HLeUagvGuJ0Yucmw5et1Ed44J/QJ9LZaY/IYQQLUIC6DbI7rbzzIpnSA1J5aY+NzUuL/vwQ8xhYQSPHduKrRPtmcvj5a7PM/hmfT6XDEzgsbE9CfFvxXSNbQvhi2uMQPiaryF7pZHPPHvqvm2UGeL6w/DbofelkrcshBCixUkA3Qa9u+Fdcmtyee/897CajeDFmZVFzaJFRN5yMybfVrqNLto1p9vL7Z+t4duNhTx8YXduOjO1dRu0ZjrM/bNRAePKmRDcATqNhDPvhT3LYPdSiO0HHYeBb3DrtlUIIcQpRQLoNia7Kpv3fn2PC1MuZHDs4Mblxa+9jrJaCZs8uRVbJ9oru8vDbZ+s4fstRfz14p5cd/oJrh1eXQAbZhnl5Sr2QMVuKNxg5C7/4SOwBe3bVilIGm48hBBCiFYgAXQborXm2ZXPYjFZuCftnsbl9evXUzV3LhFTp2KJimrFFor2qNbh5pZP1vBTZjF/m9CbPw5LOrENcNXDRxOgeLNRWi4syaiU0WMcnHE3mNt4xQ8hhBCnHAmg25BF2YtYkruEe9PuJdo/GjCC6sJnn8McGUnEjTe2bgNFu7Mht5LbP1tLVmktf7+kD5cP7njiG/G/R4zg+cqZ0OVco4dZCCGEaMMkgG4j7G47f1/1dzqHdubKHlc2Lq+eP5/6tWuJfepJzIEBrdhC0Z54vZp3f97F899uITLQxmc3DmNYp4gT35At/4VV78Bp06CrzJophBDi5CABdBvxzq/v7Bs4aDJuWXsdDope+Ce27t0JnTSplVso2ovSGgd3fbGOnzKLOb9XDH+/pC+h/j4te9LqAvA4jdSMvary4KvbILYvnP1Yy55fCCGEaEYSQLcBOyp28O6GdxnbaWyTgYNlH36EKy+Pjs88jTK38SmTxUlhc34VN3yYTkmNg6cn9ubKIR1bvqZ40Wb4YCzUlRg1nPtfBT3GGqXo3A649D2w2Fq2DUIIIUQzkgC6lXm1lyeWPUGANYD7Bt/XuNxdUkLpW28ReNZZBAwb1ootFO3Fgg0F3P1FBsG+VmbefBp9E0Jb/qRFW+DDi8FkMabI/nUmzLkZ5voYPdLj/gWRXVq+HUIIIUQzkgC6lf0n8z+sLVrL307/G+G+xqxp2u0m7+GH8TocRN93byu3UJzstNa8+sN2/vldJv0SQ/n31YOaf0puZy1oDbbAfcuKM43gWZlgyjdGoDzqIaOGc8an4BcGA65u3nYIIYQQJ4AE0K2oqK6Il1a/xNDYoYxLHQcYwU7BE09S+9MSYp98AlvKCa7HK9qVslon9/9nPQs3FzJxQDzPTuqDr7WZ04GyV8HHk8BVB3EDIXkExPaBBQ8a66/9Zl8vs9RwFkII0Q5IAN2Knlv5HC6vi8dOe6wxD7X0zTepmDmTiFtuJuwPf2jlFoqT2S/bS7jriwzKa108NrYn152e3Pz5zjmrjeDZPwJ6/QmylsIvr4DXDQFRRvAc1bV5zymEEEK0MgmgW8mPe37ku93f8eeBf6ZjsFGZoGL2HIr/7xVCxo8n6o47WrmF4mTl8nh56btM3li8g5TIAN6bMphecSHNf6LcNTB9IviHGykaIQnGckcN5KZDVHcIim3+8wohhBCtTALoVqC15pW1r5Aaksq1va4FoPaXX8h/9FEChp9Gh6eebPnKCKJd8ng1t32yhv9tKuSKwYk8dnFP/H1a4G2etxamTwC/UKOXeW/wDEYedKdRzX9OIYQQoo2QALoVLMtbxvaK7Tw94mmsJivO7Gxy7robW6dOxL/yCsqnhWvyinZJa80jczbwv02FPDa2J9ePaIH8+boyWPYaLH8DAiKMnufQxOY/jxBCCNGGSQDdCj7a/BGRfpFckHwB3vp6cm6/A7Qm4bVXMQcGHv0AQhzC/32/jc9W7uHWUanNHzzXlzcEzm+Csxp6TYRzn5LgWQghxClJAugTbGfFTpbmLmVa/2lYTBbyHn0Yx9atJL79Fj6JEoyI3+aTFbt5eeE2Lh2UwH3nd2u+A3u9sOYDWPg42Cuh53gY+SDE9Gy+cwghhBAnGQmgT7Dpm6fjY/Lhsm6XUf7RR1R98w1Rd/6ZwDPOaO2miZPUVxm5PDpnA6O7RfHspD7Nlz9ftAXm/hmylxszCI551ihPJ4QQQpziJIA+gSrsFczdMZeLUy/Gtm47e57/B4HnnE3ETTe1dtPEScjl8fL8gi38e8kuBieH8dpVA7GaTcd/oE1fw3ePgS0IQjtCWLJRhm7Vu8aAwPGvQ/8rjRrOQgghhJAA+kSamTkTh8fBVX4jyb35Dnw6diTuuedQpt8Q9IhTWlGVnWmfrmVlVhnXnJbEIxf1xMfyG15HK96C+Q9ATG8IjIGSbbD9e3DXQ9/L4fxnICCy+S9ACCGEOIlJAH2CuDwuPtvyGecEpqHufRptsZD49lsyaFAct9W7y7j54zXU2N28fHl/JgyIP/6DeL2w8DH45V/QfSxc8g5Y/Yx1WhuzCvoENG/DhRBCiHZCAugTZEHWAqoqi7hurg/usjKSPvpQBg2K47Yxr5Jr31tFZKAPH/9pKN1ig47/IK56mHMrbJwFQ26CMc+Bab/pvZWS4FkIIYQ4AgmgTwCv9vLR+vd5+Bsb1u3ZxL/2Kn59ZDCWOD455XVMeX8VQb4WPrtpGB1C/I7/IDsXwdw7oXwXnPskDL9DcpuFEEKI4yQB9Anwbda3DJm1hR5bNbGPP07Q6NGt3SRxkqmoc3LteytxuDx8csvw4w+ea0vg27/A+hkQngrXzoWUM1umsUIIIUQ7JwF0C3N5Xby94hUez4Dg8eMIu+Ly1m6SOMnYXR5u/Cid7LJ6PvrTELrGHGfaRtbP8PnV4KiCM++DM+4Fq2/LNFYIIYQ4BUgA3cK+2v4VUWv34OPShF5ySWs3R5xkPF7NXZ9nsCqrnFevHMCwThHHd4CKPUbw7B8BU/4rE6AIIYQQzUDqp7Ugu9vOG+ve4MIdQViio/EfNKi1myROIlprnvpmE/M3FPDIRT0Y2zfu+A7gqofP/2jUdJ48Q4JnIYQQoplIAN2CPt/6OTVlhXTdWkvwBWNQZvPRdxKiwb+X7OSDX7L404gUbjij0/HtrDV8czfkr4NJ/4bIzi3TSCGEEOIUJAF0C6lx1vDOr+9wZVEqyuUm+MILW7tJ4iTyVUYuz8zbwkV9O/CXC3sc/wFWvQPrPoWRD0K3Mc3fQCGEEOIU1qIBtFJqjFJqq1Jqu1LqwcNsM0oplaGU2qiUWtyS7TmRpm+aToWjgnO3+WNNSMC3b9/WbpI4SfyyvYR7Z65jaEo4/7ysHybTcZaZ2/UTLHgQuo6BkQ+0TCOFEEKIU1iLBdBKKTPwGnAB0BOYrJTqecA2ocDrwDitdS/gspZqz4nk8rr4ZMsnXBg6ArX6V4IvvBAltXbFMSiotHPrp2tIiQzg7WvS8LUeZ9rPxjnw8aVGqbqJb4FMEy+EEEI0u5b87zoE2K613qm1dgIzgPEHbHMlMEtrvQdAa13Ugu05YVblr6LSUcnEnBjweAi+SNI3xNF5vZr7/rMOh8vLm38cRIif9fgOsOx1mDkF4vrD9QvAL7QFWimEEEKIlgyg44Hs/X7OaVi2v65A2P+3d9/xUVX5/8dfnzRIqAKhRwi9STM0ewFFUbGLgqjYdV11vyq6upZ13Z9t17YqFooFRQULIoiKiiiC9A7SQyghlEAghLTz+2OGNQtBZjCTO5N5Px+PPDL33DuTdw4J+eTk3HPM7Hszm2Nmg0t7ITO7ycxmm9nsrKysEMUtO1+t/4qkuCTq/byShBbNqdSqldeRJAK89fM6pq3cxoP92tIsuWrgTywuhi//CpMfgDb9YPBnkFQrdEFFRESiXCgL6NLmLLiDjuOA44F+wNnA38zskGrTOfe6cy7NOZeWnJxc9knLUGFxIVPSp3BO1e7kzZmn6RsSkJWZOTw5aTlntKnLwB7HBv7EgjwYex3MeBm63wyXvw3xR7HFt4iIiAQslBupZAApJY4bA5tKuWabc24vsNfMfgA6Ab+GMFdIzdoyi+z92fTdXB2co/o553gdScJcfmExd46ZT9VKcTx1ScfAf+HK3QFjroL0n+Gsf0CvP4F+WRMREQm5UI5AzwJamlmqmSUAA4DxB13zGXCymcWZWRLQA1gWwkwh9/X6r0mKrUzy94up3K4dlVJTvY4kYe65b35l6ebdPHlJR5KrVQrsSTvXw4izYeMcuGQ4nHCHimcREZFyErIRaOdcoZn9CZgMxAIjnHNLzOwW//lhzrllZvYlsBAoBt50zi0OVaZQOzB944Z1qeSvWETDp5/yOpKEue9XbGXY1NUM6JZCn3b1AnvS5oUw+lIozIOrP4GmJ4U2pIiIiPyPUE7hwDk3EZh4UNuwg46fAZ4JZY7yMidzDgU7ttPr0z0kdetG9fPP9zqShLGMnbnc9cF8WterxiPntw/sSdtXwzsXQlxlGDIZ6h7FJisiIiLyh4S0gI42X6//msFTY4jNy6f+Iw/r5kE5rP2FRdw+ei5FRY5XBx1PYkIA6z3v3eYbeXYOrvkcajcPfVARERE5hHZZKCNFxUWsmTaRU+cXUPu6a6nUooXXkSSMPT5hKQsydvHMZZ1IrVPlyE/Iz4X3roDdm+CqD1Q8i4iIeEgj0GVk7qZZXD5+J4XJNalz661ex5Ew9sm8DN6dkc7NpzSjb4f6R35CcRGMu8F3w+AV70BK99CHFBERkcPSCHQZWTP8PzTJggYPPkRMUpLXcSRMrd22l79+vJjuqbW49+zWR37Crgxf8bziCzjnKWirefUiIiJeO+IItJmdB0x0zhWXQ56IVFRYQPNP55Lerg5tzta23VK6omLHPR8tID7WeHFAF+Jif+f3110b4cd/w9y3fXOeT38QetxcfmFFRETksAKZwjEAeMHMxgEjnXMRvU5zKCyfNZkq+xw5/XrrxkE5rOE/rmHO+p08d0Un6teoXPpFxUUw5e8w4xVwxdBlEJz8f1AziN0JRUREJKSOWEA75waZWXXgSmCkmTlgJPC+cy4n1AEjweqpE2gJdDjjMq+jSJhamZnDs1/9ylnt6nFh50alX5SfC+OuhxUTodOVcNoDcEyT8g0qIiIiRxTQHGjn3G5gHDAGaABcBMw1sztCmC1i7J+/gN014klObed1FAlDhUXF3PPRAqokxPLERceV/leKvdvgrfNhxSQ491m4aJiKZxERkTAVyBzo84EhQHPgHaC7c26rf+vtZcBLoY0Y3rJys2iwOpu841p5HUXC1LCpq1mQsYuXr+pa+lbd21f71nfevQmueBfanlf+IUVERCRggcyBvgx4zjn3Q8lG51yumQ0JTazIMXP+BJrngOt5itdRJAyt2prDC1NWcl7HBvTr2ODQC7Yuh7fO8819vuZzLVEnIiISAQKZwvEI8MuBAzNLNLOmAM65KSHKFTHSp00GIPWkczxOIuHGOcfDny0hMT6Wxy4oZavurBW+4tlifdtyq3gWERGJCIEU0B8BJZewK/K3Rb2C4gJYuIyCynFUbh3Amr4SVSYs3Mz01du5t28balc9aOpG1q8w6jzAfCPPyZoCJCIiEikCKaDjnHP5Bw78jxNCFylyzN86n2bp+RS1b4nFxnodR8LInv2F/OOLpXRoVJ2ruh+0BN22lb6RZxxcO0HFs4iISIQJpIDOMrMLDhyYWX9gW+giRY7pK74mJQvq9TrV6ygSZl6aspLM3fv5e/8OxMaUWHVj+2rfyHNxEVwzAZL1lwsREZFIE8hNhLcAo83sP4ABG4DBIU0VITb+PIUYoEZaT6+jSBhZmZnD8B/XckVaCl2PPea3E/8tngt8xXPdNt6FFBERkaMWyEYqq4GeZlYVMG2e4pORk0GNXzdTHBtDYsfjvI4jYeLAjYNJCbHc17fE6PKONb51ngvzfNM26mnNcBERkUgVyAg0ZtYPaA9UPrAJhHPu7yHMFfZ+yPiBNhsccW1aEZOU5HUcCRNjZm3g5zXbebx/+99uHNyxFkadDwX74JrxUK+UFTlEREQkYhxxDrSZDQOuAO7AN4XjMiDqt0j7cf33tNxs1NT0DfFbmZnDY58v4aQWdRjYw/8tsnaab9pGwV4Y/BnU118rREREIl0gNxGe4JwbDOx0zj0G9AJSQhsrvOUW5LJt/i/EFzoSj+/qdRwJA3kFRdzx/jySEuL49+WdiMnbCZ/d7lttIybWVzw36Oh1TBERESkDgUzhyPO/zzWzhsB2IDV0kcLfT5t+okV6AQBJXVVACzw5aTnLt+Qw8tpu1F0/ASYNhX074cS74NShkKBpPiIiIhVFIAX052ZWE3gGmAs44I1Qhgp3U9Kn0GljHPFNGhBXp47XccRj3yzNZNT0dQw5MZXT86fCxzdAo+Nh8KeasiEiIlIB/W4BbWYxwBTnXDYwzswmAJWdc7vKI1w4Kigq4If0qVyxEZL6aPQ52m3NyePesQto16A6Q0+uCa/dC427wXVfQmxA9+iKiIhIhPndOdDOuWLgXyWO90dz8Qwwa8ssqmzNofKefBK7dPY6jnjs9alr2J1XyIsDOlFp8n2Qnwv9X1HxLCIiUoEFchPhV2Z2iR1Yvy7KTUmfQvst8QAkdu7sbRjx1K7cAt7/JZ3zOjagRdY3sOxzOP0Bbc0tIiJSwQUyTPYXoApQaGZ5+Jayc8656iFNFoaKXTHfbfiO23fWJabqDiq1aOF1JPHQuzPXsze/iNu61YRx90DDrtDrDq9jiYiISIgFshNhtfIIEgkWZi0ka18WzTfWI7HjcVhMIAP4UhHlFRQx8qe1nNoqmdZzH4O83dD/ZU3dEBERiQJH/GlvZqeU1u6c+6Hs44S3b9O/pUpBLJXWbaHyWed7HUc8NHZOBtv25HNfq0z45hM4/SFtzy0iIhIlAhkuu7fE48pAd2AOcEZIEoUp5xxT0qdwbn5rKFpIkuY/R62iYscb09bQKaUm7bYMh8o14QRN3RAREYkWR5yD4Jw7v8RbH6ADkBn6aOFlVfYq0nPSOSm7LgCVO2pXuWg1afFm1m/P5Y5etbFlE+C4yyC+stexREREpJwczYTNDHxFdFSZkj4Fw2iSngdNmxJ3zDFeRxIPOOcYNnU1zepU4YzCH6FoP3QZ6HUsERERKUeBzIF+Cd/ug+Abse4MLAhhprD0bfq3dKxzHEWLl1P1xBO9jiMe+XHVNhZv3M2TFx9HzIK/Q9320KCz17FERESkHAWyjMRsfHOe5wA/A0Odc4NCmirMbNyzkWU7lnFu5TSKtm0jsXMnryOJB5xzPDt5BQ1rVObilBzYOAc6XwVaIl1ERCSqBDKFYyyQ55wrAjCzWDNLcs7lhjZa+Dim0jE8efKTdJi7k1y0gUq0mrR4CwsydvHMpR1JWPQaxMRBxyu8jiUiIiLlLJAR6ClAYonjROCb0MQJT0nxSfRr1o9KK9KxxEQqtWzpdSQpZ4VFxTw7eQWt6lXl4s71YcEH0PJsqJrsdTQREREpZ4EU0JWdc3sOHPgfJ4UuUvjaN38+iR06YHHaLCPafDg7gzXb9nLv2W2IXT0F9m7VzYMiIiJRKpACeq+ZdT1wYGbHA/tCFyk8FeflkbdsmaZvRKF9+UU8/82vpDU5ht5t68L8dyGpDrQ8y+toIiIi4oFAhlLvAj4ys03+4wZA1E38zFu6FAoLdQNhFBrx01q25uznlYFdsdwdsOJL6H4TxMZ7HU1EREQ8cMQC2jk3y8zaAK0BA5Y75wpCnizM7JvvW7kvsZMK6GiSnZvPsKmr6d22LmlNa8F3/4TiAk3fEBERiWJHnMJhZrcDVZxzi51zi4CqZnZb6KOFl30LFhDfuDFxdep4HUXK0Yif1rFnfyH3nt0Gtq+GH5+HDpdCvfZeRxMRERGPBDIH+kbnXPaBA+fcTuDGkCUKU/vmz9foc5QpLCrmg1npnNoqmdb1qsLEeyE2Ac5+wutoIiIi4qFACugYs992ijCzWCAhdJHCT8GWLRRmZuoGwijz7fKtZO7ez1Xdj4Wln8HqKXDGQ1CtvtfRRERExEOB3EQ4GfjQzIbh29L7FmBSSFOFmZiqVWn4zDMkdunsdRQpR+/9kk796pU5IzURXn0A6h8H3W7wOpaIiIh4LJAR6KH4NlO5FbgdWMj/bqxyWGbW18xWmNkqM7u/lPOnmdkuM5vvf3s4mPDlJbZqVWqcfx4JjRt7HUXKyYYduUz9NYvLu6UQN+1pyNkE/Z6DWK0BLiIiEu0CWYWj2MxmAM3wLV9XCxh3pOf5p3q8DPQBMoBZZjbeObf0oEunOefOCzq5SAh9MGsDBgxM3QOjX4Wu10BKN69jiYiISBg4bAFtZq2AAcCVwHbgAwDn3OkBvnZ3YJVzbo3/9cYA/YGDC2iRsFJQVMwHszdwWuu61JvxBFSqBr0f9TqWiIiIhInfm8KxHDgTON85d5Jz7iWgKIjXbgRsKHGc4W87WC8zW2Bmk8xMa4OJ56YsyyQrZz+3Nd0Cq76Bk/8CSbW8jiUiIiJh4vcK6EuALcB3ZvaGmZ2JbyOVQJV2rTvoeC7QxDnXCXgJ+LTUFzK7ycxmm9nsrKysICKIBG/0zHQaVK/E8ategGoNfLsOioiIiPgdtoB2zn3inLsCaAN8D9wN1DOzV83srABeOwNIKXHcGNhU8gLn3G7n3B7/44lAvJkdslOJc+5151yacy4tOTk5gA8tcnTSt+cybeU27m++DsuYBacOhfiA7pkVERGRKHHEVTicc3udc6P9N/o1BuYDh6yoUYpZQEszSzWzBHzzqceXvMDM6h9YY9rMuvvzbA/uUxApO2//vI44K+bcrW9ArWbQZZDXkURERCTMBLUml3NuB/Ca/+1I1xaa2Z/wrSMdC4xwzi0xs1v854cBlwK3mlkhsA8Y4Jw7eJqHSLnYsCOXt39ez2Opy4nftBwuGQ6x8V7HEhERkTAT0kVt/dMyJh7UNqzE4/8A/wllBpFAPT15BZViCrliz9u+TVPaX+x1JBEREQlD2hVCBJiXvpPPF2zizXYLiVuTDuePhZhA9hkSERGRaKMKQaKec45/TlxGgyrGGVnvQkpPaNHb61giIiISplRAS9SbvCSTWet28kLrxcTkbILThoIFs2KjiIiIRBMV0BLV8guLeXLSMtolV6Jbxiho3B2aBbrZpoiIiEQjFdAS1d6buZ5123P5d+ul2O6NGn0WERGRI1IBLVGroKiY135YQ6+m1Wi98nVolAbNz/Q6loiIiIQ5FdAStSYu2szmXXk83HgBtmsDnHa/Rp9FRETkiFRAS1RyzvHmtLW0rFOJNqteh4ZdtPKGiIiIBEQFtESlX9buYNHGXTzedCGWnQ6navRZREREAqMCWqLSG9PWcmJiOj1WPAMpPaDV2V5HEhERkQihnQgl6qzJ2sOvyxcyqerTWJU6cPk7Gn0WERGRgGkEWqLO+1PnMyrhaRJji2HgOKhWz+tIIiIiEkE0Ai1RZWf2Ls5ZdDcpMduJuXI8JLfyOpKIiIhEGI1AS1TZOOZOOrOSrD4vQpNeXscRERGRCKQCWqLG1q2ZtNg8ganVzqXhCVd6HUdEREQilApoiRpTxr5KZSug1bl3eB1FREREIpgKaIkK3y7PpM2Wz9me1JxGbXt6HUdEREQimApoqfBy8wt58+Mv6RKzihonXKcl60REROQPUQEtFd4L36zklNyvKbY44joP8DqOiIiIRDgtYycV2pJNuxj54ypmJ/1ETPOzoGqy15FEREQkwmkEWiqs4mLHQ58u5pzKS6leuAM6D/Q6koiIiFQAKqClwhq/YBPz0rO5p95sSKoNLc/yOpKIiIhUACqgpULKzS/kyUnLOaGB0Xjr99DxCohL8DqWiIiIVAAqoKVCem3qGrbszuP/tVqBFeVD56u8jiQiIiIVhApoqXA2Ze/jtR9WM6RNIU2WvQn1O0L947yOJSIiIhWEVuGQCufpL5fTya3gwS3PQ0wsXPCi15FERESkAlEBLRXK3PSd7Fv4Ge9WeoXYpEYwaBzUauZ1LBEREalAVEBLheGc45ePnuHVhFdwDY6HgR9AlTpexxIREZEKRnOgpcKYOncx1+1+jczkE4i99nMVzyIiIhISKqClQigqdmz86iXirYjky1+EhCSvI4mIiEgFpQJaKoSJ89bQN28iW+ufTlxyC6/jiIiISAWmAloiXkFRMcsmD6e25VD3rLu9jiMiIiIVnApoiXhjZ2+gf95n5NRsQ0zqyV7HERERkQpOBbREtLyCIn7+ZiytYzKoeuqfwczrSCIiIlLBqYCWiDZ6ZjoX5X1GfuU62HGXeh1HREREooAKaIlYKzNzmDDlO06PXUBCr5shrpLXkURERCQKqICWiLRiSw4DXp/BIJtEcWwlOP46ryOJiIhIlFABLRFn+ZbdXPXGDFJisrjIfiCm4+VQNdnrWCIiIhIlVEBLRFm2eTdXvTGTuFhjdONPiImJhdPu9zqWiIiIRBEV0BIxsnPzGfTmTBJiYxjfZzdV1n4Fpw2FGo29jiYiIiJRJM7rACKBGjV9Hdv35vPFrcdT7+M+kNwGet7mdSwRERGJMiqgJSLs2V/IyJ/W0bttXdqvfA12pcO1EyE23utoIiIiEmU0hUMiwnsz17NrXwF/6QJMfwk6XQVNT/Q6loiIiEShkBbQZtbXzFaY2SozO+ydXmbWzcyKzEw7Ycgh8gqKeGPaWk5sXot2cx+DhCTo83evY4mIiEiUClkBbWaxwMvAOUA74Eoza3eY654CJocqi0S2j2ZvICtnPw+23gTrpsEZf9OydSIiIuKZUI5AdwdWOefWOOfygTFA/1KuuwMYB2wNYRaJUAVFxQybuoYuKTVo++urUCMFul7jdSwRERGJYqEsoBsBG0ocZ/jb/svMGgEXAcN+74XM7CYzm21ms7Oysso8qISvT+dtZGP2Ph5ul4llzIKT7oa4BK9jiYiISBQLZQFtpbS5g46fB4Y654p+74Wcc68759Kcc2nJyfrTfbTILyzm1amraVu/Gp3XvAbVG0GXQV7HEhERkSgXymXsMoCUEseNgU0HXZMGjDEzgDrAuWZW6Jz7NIS5JAJk5eznttFzWJO1lw/75GPTZsK5z0JcJa+jiYiISJQLZQE9C2hpZqnARmAAcFXJC5xzqQcem9koYIKKZ1mYkc3N78xhZ24+Lw7oTPe5N0C1htB1sNfRREREREI3hcM5Vwj8Cd/qGsuAD51zS8zsFjO7JVQfVyLbJ/MyuGzYz8SYMfaWE7igxmpInw4n3aXRZxEREQkLId2J0Dk3EZh4UFupNww6564NZRYJf18vzeTuDxbQI7UWrwzsSu2qlWDkU1C1vlbeEBERkbChrbwlLOzdX8gjny2mTf1qvHN9DxLiYmDJJ7D+R+j7JMRX9jqiiIiICKCtvCVMPP/Nr2zalccTF3XwFc/Z6TD+TmiUBt1u8DqeiIiIyH+pgBbPLd20mxE/rePK7sdyfJNaUFQI424EVwyXvAmx8V5HFBEREfkvTeEQTxUXO/76ySJqJsYztG9rX+O0Z2HDDLj4DaiV+vsvICIiIlLONAItnnrvl3Tmb8jmofPaUjMpAdJnwNSnoOMV0PFyr+OJiIiIHEIFtHhmy648nvpyOSc0r82FnRvBvmwYdwPUPNa3aYqIiIhIGNIUDvHE5l37uOqNmRQXOx6/sINv3/cJd0HOZhgyGSpX9zihiIiISOk0Ai3lbsOOXC5/7We25ezn7eu70zy5Kswf7Vu27vS/QuM0ryOKiIiIHJZGoKVcpW/P5co3ZpCTV8A7N/Sgc0pN2LYKJt4HTU+GE+/yOqKIiIjI71IBLeXmwMhzXmER793Ykw6NakBhPoy7HuIS4KLXICbW65giIiIiv0sFtJSL4mLH/320gL35hXx4cy/aNvDPcf72cdg8H64YDTUaeZpRREREJBCaAy3l4v1Z6fyydgcP9Wv7W/G87ieY/iKkDYG253kbUERERCRAKqAl5Dbv2sf/m+hbru7ytBRfY3ERfDkUaqTAWU94G1BEREQkCJrCISHlnONvny6msLiYJy/uiJn5Tsx/D7YsgkuGQ0KStyFFREREgqARaAmpCQs3882yrfxfn9YcW9tfKO/f45v73LgbdLjE24AiIiIiQdIItITMzr35PDp+CZ0a1+C6E5v+duKn52FPpu/GwQMj0iIiIiIRQgW0hMSGHbnc9M4cdu0r4N0behAX6/9jR/YGmP4SdLgUUrp5G1JERETkKKiAljI3ffU2bh89l8Jix5vXpP226gbAlMd873s/6kk2ERERkT9KBbSUGecco6av4x9fLCO1ThXeGJxGap0qv12w+GNY9BGcfA/UTPEuqIiIiMgfoAJaysw/Jy7jjWlr6dOuHv++vBPVKsf7TuzeBBPvheUToH5HOOlub4OKiIiI/AEqoKVMDP9xLW9MW8s1vZrwyPntiYkx31rPs0fAN49BcSH0fgx63Q6x8V7HFRERETlqKqDlD/ty8Wb+8cVS+ravz8MHimeAqU/53pqfAf3+DbVSvQ0qIiIiUgZUQMsfMmf9Tu4cM5/OKTV5fkBnYg8Uz7k74OeXoe0FcPnbWq5OREREKgxtpCJHbd22vdz49mwa1KjMm4PTqBwf+9vJGa9A/h447QEVzyIiIlKhqICWo5K5O4+rR8z0rbxxXXdqV63028l9O2Hma9CuP9Rr511IERERkRBQAS1By87NZ/DwX9ixJ5+R13Wnacml6gBmvAr7d8Mp93kTUERERCSENAdagpKbX8h1o2axdtteRl7Xjc4pNf/3gn3ZMGMYtDkP6nfwIqKIiIhISGkEWgK2v7CIm9+Zw4IN2bx4ZRdObFHn0Itmvgb7d8GpQ8s/oIiIiEg50Ai0BCSvoIg/vz+PaSu38fSlHenboX4pF+2CGS9D63OhQcfyDykiIiJSDlRAyxHtzivgxrdmM3PtDh67oD2Xpx1mG+4fnvEV0adq7rOIiIhUXCqg5Xdt3Z3HNSNnsTIzhxcGdKZ/50alXzjnLZj+EnS9Bhp2Kd+QIiIiIuVIBbQc1tptexk8Yibb9+Qz4tpunNIqufQLV34NE+6G5mdCv3+Vb0gRERGRcqYCWkq1Z38hg96cyb6CIt67seehq20csGk+fHgN1GsPl78FsfHlGVNERESk3KmAllI9O3kFm3bt46Obex2+eN65HkZfBkm1YOBHUKlauWYUERER8YIKaDnEnPU7eOvndQzu2YS0prVKv2j3Jni7PxTth2snQLVSVuUQERERqYC0DrT8j/2FRQwdt4iGNRK5t2+b0i/avQlGnQd7t8HAcZDcunxDioiIiHhII9DyP17+dhWrtu5h1HXdqFqplC+PnC3w1vmwJxOu/gRSupV/SBEREREPaQRa/mvZ5t288v1qLu7SiNNa1z30gpxM38jz7s0waBykdC//kCIiIiIeUwEtAOQXFnPf2IXUSIznb+e1O/SCZRPg9dN80zcGjYVje5Z7RhEREZFwoCkcAsA/Jy5j0cZdDBt0PMdUSfjtxO5NMPFeWD4B6nWAK9/TRikiIiIS1VRAC18s3Myo6esYcmIqfTuUWE1j3rsw6X4oLoDej0KvP2mdZxEREYl6KqCj3JqsPQwdt5Aux9bk/nNKrLqx8CP47HZoejJc8CLUauZdSBEREZEwEtI50GbW18xWmNkqM7u/lPP9zWyhmc03s9lmdlIo88j/yiso4rbRc4mPNV6+qisJcf4vh7U/wKe3QpOTfDcLqngWERER+a+QjUCbWSzwMtAHyABmmdl459zSEpdNAcY755yZdQQ+BA6z+LCUJeccf/t0MSsycxh5bTca1kz0nchcCmMGQe3mMOBdiKvkbVARERGRMBPKEejuwCrn3BrnXD4wBuhf8gLn3B7nnPMfVgEcEnLFxY5Hxi/hozkZ3HFGy9+WrNu92bc1d3yib2vuxGO8DSoiIiIShkJZQDcCNpQ4zvC3/Q8zu8jMlgNfAENCmEeAomLHfeMW8vbP67n5lGbc3bul78S2VfDOhZCX7Sueax7rZUwRERGRsBXKAtpKaTtkhNk594lzrg1wIfB4qS9kdpN/jvTsrKyssk0ZRQqKirlzzDzGzsngrt4tuf+cNpgZLP7Yt8bznky48n1o0NHrqCIiIiJhK5QFdAaQUuK4MbDpcBc7534AmptZnVLOve6cS3POpSUnJ5d90ihQUFTMbaPnMmHhZh44pw139W6FFeXDF/fA2Ougblu4eRqknuJ1VBEREZGwFspl7GYBLc0sFdgIDACuKnmBmbUAVvtvIuwKJADbQ5gpaj3xxTK+XprJo+e349oTUyFvt2/KxsY5vvWdez+qNZ5FREREAhCyAto5V2hmfwImA7HACOfcEjO7xX9+GHAJMNjMCoB9wBUlbiqUMvLBrHRGTV/H9Sel+ornwnz48GrYvAAufxva9T/yi4iIiIgIABZp9WpaWpqbPXu21zEixpz1Oxjw+gx6NqvNyGu7ERdjvjWeF7wP/V+BLgO9jigiIiISlsxsjnMu7eD2kG6kIt7avGsfN78zl4Y1E3npyi7ExcbAd0/4iufTH1TxLCIiInIUtJV3BZVXUMTN78xhX34h793Yg5pJCTBnFPzwDHQdDKfc63VEERERkYikArqCeu7rX1mYsYvXrj6eVvWq+Zaqm/AXaNEb+v0brLRVBkVERETkSDSFowKas34Hr09bw4BuKZzdvj4s+RTG3QApPeCyt7TahoiIiMgfoAK6gtmXX8Q9Hy2kYY1EHuzXFpaOh7FDoHE33w6Dlap6HVFEREQkomkKRwXz1JfLWbttL+/d0INqayf7NklpnAaDxqp4FhERESkDGoGuQGas2c6o6esY3KsJJ+R+Cx9dAw27wMCxUKma1/FEREREKgQV0BXE7rwC7h27gCa1EnmoxiT4+EY4thcMGgeVq3sdT0RERKTC0BSOCmDH3nwGj5jJ1uy9TDtuEgnfj4YOl8KFr0BcJa/jiYiIiFQoKqAj3JZdeQwaPpPMHdn81HQUdVZ8CyfeBWc+AjH6A4OIiIhIWVMBHcHSt+cycPgMdu4t4Jv23/iK53OegR43eR1NREREpMLSEGWEWr99L5cOm05OXiHjz9pD/RVvQ8/bVDyLiIiIhJhGoCNQYVExd30wn7yCIj6+ujnNxp0F9Y+D3o96HU1ERESkwlMBHYGGTV3NvPRsXhzQiRY/3Q75uXDJCN0wKCIiIlIOVEBHmMUbd/H8Nys5v1NDLtg7DtZ8D+e/AMmtvI4mIiIiEhU0BzqC5BUUcdcH86ldNYEnejmY8ndoewF0vcbraCIiIiJRQyPQEeTpL1ewause3h7SnerTboJK1X2jz2ZeRxMRERGJGhqBjhDTV29jxE9rGdyrCafEL4fV38LJf4GkWl5HExEREYkqGoGOALn5hQwdt5CmtZN4oG8beKcvVGsI3W7wOpqIiIhI1NEIdAR4dvKvbNixj6cu6Uji2smQMQtOux/iE72OJiIiIhJ1VECHuTnrdzJy+loG9TyWHk1rwpTHoXYL6DzQ62giIiIiUUlTOMLY/sIiho5bSMMaidx/TltY9BFkLYNLR0Ks/ulEREREvKAqLIy9NGUVq7bu4a0h3akaWwzfPQH1O0K7C72OJiIiIhK1NIUjTC3euItXp67mkq6NObVVMsx9C7LTofcjEKN/NhERERGvqBILQzv25nPr6DnUrpLA385rC4X74cfnIKUnND/T63giIiIiUU0FdJjJLyzm1nfnkLl7P68PTqNmUgLMexd2b4TThmrTFBERERGPqYAOI845Hv18CTPX7uDpSzrSOaUmFOb7Rp8bd4dmp3sdUURERCTqqYAOI+/MWM97M9O59bTmXNilka9x/mjYtUGjzyIiIiJhQgV0mJi+ahuPfb6U3m3rcu9ZrX2Nhfkw7d/Q6HjNfRYREREJEyqgw0B2bj53fTCf1DpVeO6KzsTE+EeaF7wPu9Lh1Ps1+iwiIiISJlRAh4GHP1vCjr35PH9FZ6pVjvc1FhXAtGehYRdo2cfbgCIiIiLyXyqgPfbFws2MX7CJP5/Zkg6NavganYNp//Kt+6zRZxEREZGwop0IPbQ1J4+HPl1Ep8Y1uO205r7GvF3w2e2w7HNo1x9ane1tSBERERH5HyqgPeKc44Fxi9ibX8S/Lu9EXGwMbJoPH10D2RvgrH9Arz9p9FlEREQkzKiA9shHczKYsnwrD/VrS4u61WDxx/DJzVAlGa6bBMf28DqiiIiIiJRCBbQHdu7N558Tl9G9aS2GnJgK21b6pm007AID3ocqtb2OKCIiIiKHoZsIPfDMVyvIySvk8Qs7EFOcD2OHQFxluGyUimcRERGRMKcR6HK2KGMX7/+SznUnpNK6fjWY/CBsWQgD3oPqDb2OJyIiIiJHoBHoclRc7Hh4/GJqV0ngrj4tYdU38PN/IO16aNPP63giIiIiEgAV0OVo7NwM5qVnc/85balemA2f3ArJbeDsJ7yOJiIiIiIB0hSOcrJrXwFPTVrO8U2O4eIujeCTm3xrPg/+FOITvY4nIiIiIgFSAV1Onvv6V3bk5vPWBd2J2ZsJSz6GHrdAvfZeRxMRERGRIGgKRzn4Ze0O3vp5HVf3bOLbrnvOKCguhLQhXkcTERERkSCFtIA2s75mtsLMVpnZ/aWcH2hmC/1v082sUyjzeGHv/kLu+WgBKcckMbRvGygqgNkjoUVvqN3c63giIiIiEqSQFdBmFgu8DJwDtAOuNLN2B122FjjVOdcReBx4PVR5vPLkpOVs2JnLM5d2pEqlOFg+AfZsgW43eh1NRERERI5CKEeguwOrnHNrnHP5wBigf8kLnHPTnXM7/YczgMYhzFPuflq1jXdmrOe6E1Lp0cy/Qcovb0KNY6FlH2/DiYiIiMhRCWUB3QjYUOI4w992ONcDk0o7YWY3mdlsM5udlZVVhhFDJyevgPvGLqRZnSrc17e1rzFzKaz/EboNgZhYbwOKiIiIyFEJZQFtpbS5Ui80Ox1fAT20tPPOudedc2nOubTk5OQyjBg6T3yxjM279vHs5Z2oHO8vlmcPh9hK0GWwt+FERERE5KiFchm7DCClxHFjYNPBF5lZR+BN4Bzn3PYQ5ik3v6zdwZhZG7j5lGZ0PfYYX2PeblgwBjpcDFVqextQRERERI5aKEegZwEtzSzVzBKAAcD4kheY2bHAx8DVzrlfQ5il3BQUFfPQp4toVDORO3u3/O3Ewg8gf49uHhQRERGJcCEbgXbOFZrZn4DJQCwwwjm3xMxu8Z8fBjwM1AZeMTOAQudcWqgylYcRP67l18w9vDE4jaQEf/dmp8MPz0DDLtCoq7cBRUREROQPCelOhM65icDEg9qGlXh8A3BDKDOUp43Z+3j+m5X0bluPPu3q+Rr37YR3L4WCPLjwVbDSpoaLiIiISKTQVt5l6LHxSwB49AL/cteF+2HMQNi5FgZ9DHXbephORERERMqCtvIuI1OWZfLV0kz+fGZLGh+TBMXF8MktsP4n38hz6sleRxQRERGRMqACugysztrDg58spmXdqlx/Uqqv8du/w5KPofdjcNyl3gYUERERkTKjKRx/0Nz0nVw/ahaxMcYLA7qQEBcDGXPgx+eh62A48U6vI4qIiIhIGVIB/Qd8vTSTO96fS/3qlXlrSHea1K4CxUXwxd1QrT6c9YRuGhQRERGpYFRAH4WsnP18Nn8j/5y4jOMa1WD4td2oU7WS7+Ss4bB5AVw6EipX9zaoiIiIiJQ5FdAByM7N5+O5G5m3IZt56TvJ2LkPgNNbJ/PywK6/rfeckwnfPg7NTof2F3mYWERERERCRQV0APILi/n7hKU0rFGZLscew7UnNKXLsTXpknIMMTElpmh89RAU5sG5z2rqhoiIiEgFpQI6AHWrV+aXv55J3eqVD3/R2h9g0Ydwyn1Qp0X5hRMRERGRcqVl7AL0u8Vz+kz47Hao2QRO/kv5hRIRERGRcqcC+o/Ylw0T7oYRZ/s2TrlkOMQnep1KREREREJIUziO1rLP4Yt7YO9W6HkbnP5XqFTV61QiIiIiEmIqoIPlHHz/JEx9Eup3hKvGQMMuXqcSERERkXKiAjoYRQXw+V0w/13oPAjOfx5i471OJSIiIiLlSAV0oPbnwIfXwOopcOr9cNr9WqpOREREJAqpgA5ETia8dxlsWQwXvARdB3udSEREREQ8ogI6EGZQVAhXfQAt+3idRkREREQ8pAI6EFXrwi3TICbW6yQiIiIi4jGtAx0oFc8iIiIiggpoEREREZGgqIAWEREREQmCCmgRERERkSCogBYRERERCYIKaBERERGRIKiAFhEREREJggpoEREREZEgqIAWEREREQmCCmgRERERkSCogBYRERERCYIKaBERERGRIKiAFhEREREJggpoEREREZEgqIAWEREREQmCCmgRERERkSCogBYRERERCYIKaBERERGRIJhzzusMQTGzLGB9OX24OsC2cvpYFZX6sGyoH8uG+vGPUx+WDfVj2VA/lg314+E1cc4lH9wYcQV0eTKz2c65NK9zRDL1YdlQP5YN9eMfpz4sG+rHsqF+LBvqx+BpCoeIiIiISBBUQIuIiIiIBEEF9O973esAFYD6sGyoH8uG+vGPUx+WDfVj2VA/lg31Y5A0B1pEREREJAgagRYRERERCYIK6FKYWV8zW2Fmq8zsfq/zRAozSzGz78xsmZktMbM7/e21zOxrM1vpf3+M11nDnZnFmtk8M5vgP1YfBsnMaprZWDNb7v+a7KV+DJ6Z3e3/fl5sZu+bWWX145GZ2Qgz22pmi0u0HbbfzOwB/8+cFWZ2tjepw8th+vAZ//f0QjP7xMxqljinPixFaf1Y4tw9ZubMrE6JNvVjAFRAH8TMYoGXgXOAdsCVZtbO21QRoxD4P+dcW6AncLu/7+4HpjjnWgJT/Mfy++4ElpU4Vh8G7wXgS+dcG6ATvv5UPwbBzBoBfwbSnHMdgFhgAOrHQIwC+h7UVmq/+f+fHAC09z/nFf/Pomg3ikP78Gugg3OuI/Ar8ACoD49gFIf2I2aWAvQB0ku0qR8DpAL6UN2BVc65Nc65fGAM0N/jTBHBObfZOTfX/zgHX8HSCF//veW/7C3gQk8CRggzawz0A94s0aw+DIKZVQdOAYYDOOfynXPZqB+PRhyQaGZxQBKwCfXjETnnfgB2HNR8uH7rD4xxzu13zq0FVuH7WRTVSutD59xXzrlC/+EMoLH/sfrwMA7ztQjwHHAfUPJmOPVjgFRAH6oRsKHEcYa/TYJgZk2BLsBMoJ5zbjP4imygrofRIsHz+P5TKy7Rpj4MTjMgCxjpnwrzpplVQf0YFOfcRuBZfCNUm4FdzrmvUD8ercP1m37uHJ0hwCT/Y/VhEMzsAmCjc27BQafUjwFSAX0oK6VNS5UEwcyqAuOAu5xzu73OE0nM7Dxgq3NujtdZIlwc0BV41TnXBdiLphkEzT9Htz+QCjQEqpjZIG9TVUj6uRMkM3sQ37TB0QeaSrlMfVgKM0sCHgQeLu10KW3qx1KogD5UBpBS4rgxvj9ZSgDMLB5f8TzaOfexvznTzBr4zzcAtnqVLwKcCFxgZuvwTR86w8zeRX0YrAwgwzk30388Fl9BrX4MTm9grXMuyzlXAHwMnID68Wgdrt/0cycIZnYNcB4w0P22Fq/6MHDN8f1SvMD/s6YxMNfM6qN+DJgK6EPNAlqaWaqZJeCbTD/e40wRwcwM35zTZc65f5c4NR64xv/4GuCz8s4WKZxzDzjnGjvnmuL72vvWOTcI9WFQnHNbgA1m1trfdCawFPVjsNKBnmaW5P/+PhPfvQ3qx6NzuH4bDwwws0pmlgq0BH7xIF/YM7O+wFDgAudcbolT6sMAOecWOefqOuea+n/WZABd/f9vqh8DFOd1gHDjnCs0sz8Bk/HdcT7CObfE41iR4kTgamCRmc33t/0VeBL40Myux/cD+TJv4kU09WHw7gBG+38RXgNch2/QQP0YIOfcTDMbC8zF9+fyefh2LKuK+vF3mdn7wGlAHTPLAB7hMN/HzrklZvYhvl/yCoHbnXNFngQPI4fpwweASsDXvt/pmOGcu0V9eHil9aNzbnhp16ofA6edCEVEREREgqApHCIiIiIiQVABLSIiIiISBBXQIiIiIiJBUAEtIiIiIhIEFdAiIiIiIkFQAS0iEubMrMjM5pd4K7NdFc2sqZktLqvXExGJBloHWkQk/O1zznX2OoSIiPhoBFpEJEKZ2Toze8rMfvG/tfC3NzGzKWa20P/+WH97PTP7xMwW+N9O8L9UrJm9YWZLzOwrM0v0X/9nM1vqf50xHn2aIiJhRwW0iEj4SzxoCscVJc7tds51B/4DPO9v+w/wtnOuIzAaeNHf/iIw1TnXCegKHNhltSXwsnOuPZANXOJvvx/o4n+dW0LzqYmIRB7tRCgiEubMbI9zrmop7euAM5xza8wsHtjinKttZtuABs65An/7ZudcHTPLAho75/aXeI2mwNfOuZb+46FAvHPuH2b2JbAH+BT41Dm3J8SfqohIRNAItIhIZHOHeXy4a0qzv8TjIn67P6Yf8DJwPDDHzHTfjIgIKqBFRCLdFSXe/+x/PB0Y4H88EPjR/3gKcCuAmcWaWfXDvaiZxQApzrnvgPuAmsAho+AiItFIowkiIuEv0czmlzj+0jl3YCm7SmY2E9+AyJX+tj8DI8zsXiALuM7ffifwupldj2+k+VZg82E+ZizwrpnVAAx4zjmXXUafj4hIRNMcaBGRCOWfA53mnNvmdRYRkWiiKRwiIiIiIkHQCLSIiIiISBA0Ai0iIiIiEgQV0CIiIiIiQVABLSIiIiISBBXQIiIiIiJBUAEtIiIiIhIEFdAiIiIiIkH4/0380EYyJIqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['accuracy'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 148us/step - loss: 16.2704 - acc: 0.1545 - val_loss: 16.1433 - val_acc: 0.1520\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 16.0619 - acc: 0.1575 - val_loss: 15.9372 - val_acc: 0.1580\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 15.8559 - acc: 0.1631 - val_loss: 15.7331 - val_acc: 0.1590\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 15.6521 - acc: 0.1669 - val_loss: 15.5309 - val_acc: 0.1700\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 15.4501 - acc: 0.1745 - val_loss: 15.3306 - val_acc: 0.1780\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 15.2498 - acc: 0.1832 - val_loss: 15.1321 - val_acc: 0.1850\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 15.0513 - acc: 0.1916 - val_loss: 14.9353 - val_acc: 0.1880\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 14.8546 - acc: 0.2016 - val_loss: 14.7402 - val_acc: 0.1970\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 14.6594 - acc: 0.2119 - val_loss: 14.5469 - val_acc: 0.2110\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 14.4660 - acc: 0.2217 - val_loss: 14.3554 - val_acc: 0.2230\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 14.2743 - acc: 0.2309 - val_loss: 14.1654 - val_acc: 0.2280\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 14.0843 - acc: 0.2380 - val_loss: 13.9770 - val_acc: 0.2230\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 13.8958 - acc: 0.2463 - val_loss: 13.7901 - val_acc: 0.2290\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 13.7090 - acc: 0.2539 - val_loss: 13.6047 - val_acc: 0.2320\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 13.5236 - acc: 0.2605 - val_loss: 13.4209 - val_acc: 0.2370\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 13.3398 - acc: 0.2640 - val_loss: 13.2386 - val_acc: 0.2420\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 13.1576 - acc: 0.2680 - val_loss: 13.0579 - val_acc: 0.2420\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 12.9770 - acc: 0.2740 - val_loss: 12.8787 - val_acc: 0.2460\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 12.7980 - acc: 0.2772 - val_loss: 12.7010 - val_acc: 0.2490\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 12.6205 - acc: 0.2815 - val_loss: 12.5247 - val_acc: 0.2550\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 12.4444 - acc: 0.2864 - val_loss: 12.3499 - val_acc: 0.2600\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 12.2699 - acc: 0.2944 - val_loss: 12.1764 - val_acc: 0.2630\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 12.0966 - acc: 0.2972 - val_loss: 12.0041 - val_acc: 0.2670\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 11.9247 - acc: 0.3008 - val_loss: 11.8335 - val_acc: 0.2770\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 11.7543 - acc: 0.3077 - val_loss: 11.6643 - val_acc: 0.2820\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 11.5854 - acc: 0.3153 - val_loss: 11.4965 - val_acc: 0.2860\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 11.4179 - acc: 0.3197 - val_loss: 11.3302 - val_acc: 0.2890\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 11.2518 - acc: 0.3243 - val_loss: 11.1652 - val_acc: 0.2960\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 11.0871 - acc: 0.3307 - val_loss: 11.0019 - val_acc: 0.3010\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 10.9239 - acc: 0.3396 - val_loss: 10.8398 - val_acc: 0.3050\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 10.7621 - acc: 0.3459 - val_loss: 10.6792 - val_acc: 0.3100\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 10.6018 - acc: 0.3524 - val_loss: 10.5202 - val_acc: 0.3150\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 10.4430 - acc: 0.3564 - val_loss: 10.3626 - val_acc: 0.3190\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 10.2857 - acc: 0.3676 - val_loss: 10.2061 - val_acc: 0.3300\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 10.1298 - acc: 0.3741 - val_loss: 10.0513 - val_acc: 0.3390\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 9.9754 - acc: 0.3835 - val_loss: 9.8979 - val_acc: 0.3490\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 9.8224 - acc: 0.3929 - val_loss: 9.7462 - val_acc: 0.3500\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 9.6710 - acc: 0.3981 - val_loss: 9.5959 - val_acc: 0.3690\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 9.5211 - acc: 0.4089 - val_loss: 9.4472 - val_acc: 0.3750\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 9.3726 - acc: 0.4119 - val_loss: 9.2997 - val_acc: 0.3880\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 9.2256 - acc: 0.4240 - val_loss: 9.1540 - val_acc: 0.3900\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 9.0800 - acc: 0.4295 - val_loss: 9.0095 - val_acc: 0.3990\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 8.9360 - acc: 0.4352 - val_loss: 8.8663 - val_acc: 0.4100\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 8.7934 - acc: 0.4425 - val_loss: 8.7249 - val_acc: 0.4310\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 8.6525 - acc: 0.4539 - val_loss: 8.5857 - val_acc: 0.4240\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 8.5130 - acc: 0.4596 - val_loss: 8.4471 - val_acc: 0.4320\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 8.3752 - acc: 0.4648 - val_loss: 8.3099 - val_acc: 0.4510\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 8.2388 - acc: 0.4731 - val_loss: 8.1745 - val_acc: 0.4590\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 8.1040 - acc: 0.4821 - val_loss: 8.0411 - val_acc: 0.4670\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 7.9707 - acc: 0.4889 - val_loss: 7.9088 - val_acc: 0.4720\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 7.8389 - acc: 0.4931 - val_loss: 7.7782 - val_acc: 0.4810\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 7.7087 - acc: 0.4975 - val_loss: 7.6490 - val_acc: 0.4880\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 7.5799 - acc: 0.5049 - val_loss: 7.5216 - val_acc: 0.4970\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 7.4526 - acc: 0.5100 - val_loss: 7.3957 - val_acc: 0.4990\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 7.3270 - acc: 0.5136 - val_loss: 7.2713 - val_acc: 0.5060\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 7.2028 - acc: 0.5219 - val_loss: 7.1480 - val_acc: 0.5080\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 7.0801 - acc: 0.5248 - val_loss: 7.0264 - val_acc: 0.5200\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 6.9590 - acc: 0.5284 - val_loss: 6.9060 - val_acc: 0.5280\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 6.8393 - acc: 0.5360 - val_loss: 6.7879 - val_acc: 0.5250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 6.7210 - acc: 0.5395 - val_loss: 6.6712 - val_acc: 0.5280\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 6.6044 - acc: 0.5413 - val_loss: 6.5560 - val_acc: 0.5370\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 6.4895 - acc: 0.5492 - val_loss: 6.4419 - val_acc: 0.5440\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 6.3759 - acc: 0.5541 - val_loss: 6.3301 - val_acc: 0.5450\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 6.2638 - acc: 0.5525 - val_loss: 6.2185 - val_acc: 0.5560\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 6.1533 - acc: 0.5639 - val_loss: 6.1094 - val_acc: 0.5550\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 6.0442 - acc: 0.5636 - val_loss: 6.0018 - val_acc: 0.5530\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 5.9368 - acc: 0.5644 - val_loss: 5.8956 - val_acc: 0.5560\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 5.8309 - acc: 0.5683 - val_loss: 5.7908 - val_acc: 0.5600\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 5.7266 - acc: 0.5731 - val_loss: 5.6871 - val_acc: 0.5680\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 5.6255 - acc: 0.579 - 0s 60us/step - loss: 5.6239 - acc: 0.5792 - val_loss: 5.5869 - val_acc: 0.5590\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 5.5228 - acc: 0.5753 - val_loss: 5.4856 - val_acc: 0.5720\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 5.4231 - acc: 0.5839 - val_loss: 5.3879 - val_acc: 0.5660\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 5.3252 - acc: 0.5843 - val_loss: 5.2912 - val_acc: 0.5730\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 5.2288 - acc: 0.5904 - val_loss: 5.1956 - val_acc: 0.5710\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 5.1341 - acc: 0.5897 - val_loss: 5.1012 - val_acc: 0.5770\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 5.0408 - acc: 0.5944 - val_loss: 5.0093 - val_acc: 0.5780\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 4.9490 - acc: 0.5971 - val_loss: 4.9182 - val_acc: 0.5780\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 4.8587 - acc: 0.6012 - val_loss: 4.8295 - val_acc: 0.5780\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 4.7698 - acc: 0.6003 - val_loss: 4.7428 - val_acc: 0.5810\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 4.6826 - acc: 0.6005 - val_loss: 4.6549 - val_acc: 0.5930\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 4.5969 - acc: 0.6115 - val_loss: 4.5707 - val_acc: 0.5950\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 4.5129 - acc: 0.6109 - val_loss: 4.4877 - val_acc: 0.5960\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 4.4304 - acc: 0.6135 - val_loss: 4.4062 - val_acc: 0.6010\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 4.3494 - acc: 0.6157 - val_loss: 4.3258 - val_acc: 0.6100\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 4.2700 - acc: 0.6212 - val_loss: 4.2477 - val_acc: 0.6080\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 4.1922 - acc: 0.6191 - val_loss: 4.1710 - val_acc: 0.6070\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 4.1159 - acc: 0.6203 - val_loss: 4.0962 - val_acc: 0.6010\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 4.0412 - acc: 0.6209 - val_loss: 4.0228 - val_acc: 0.5990\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 3.9682 - acc: 0.6200 - val_loss: 3.9492 - val_acc: 0.6120\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 3.8965 - acc: 0.6231 - val_loss: 3.8786 - val_acc: 0.6190\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 3.8266 - acc: 0.6272 - val_loss: 3.8102 - val_acc: 0.6150\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 3.7582 - acc: 0.6288 - val_loss: 3.7420 - val_acc: 0.6230\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 3.6915 - acc: 0.6312 - val_loss: 3.6766 - val_acc: 0.6150\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 3.6261 - acc: 0.6308 - val_loss: 3.6121 - val_acc: 0.6190\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 3.5625 - acc: 0.6335 - val_loss: 3.5506 - val_acc: 0.6130\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 3.5003 - acc: 0.6345 - val_loss: 3.4885 - val_acc: 0.6160\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 3.4394 - acc: 0.6328 - val_loss: 3.4276 - val_acc: 0.6250\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 3.3803 - acc: 0.6365 - val_loss: 3.3693 - val_acc: 0.6290\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 3.3226 - acc: 0.6375 - val_loss: 3.3128 - val_acc: 0.6290\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 3.2665 - acc: 0.6385 - val_loss: 3.2568 - val_acc: 0.6330\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 3.2118 - acc: 0.6412 - val_loss: 3.2032 - val_acc: 0.6290\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 3.1586 - acc: 0.6407 - val_loss: 3.1505 - val_acc: 0.6320\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 3.1069 - acc: 0.6425 - val_loss: 3.1003 - val_acc: 0.6280\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 3.0568 - acc: 0.6399 - val_loss: 3.0508 - val_acc: 0.6320\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 3.0078 - acc: 0.6420 - val_loss: 3.0025 - val_acc: 0.6310\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 2.9605 - acc: 0.6421 - val_loss: 2.9576 - val_acc: 0.6250\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.9149 - acc: 0.6431 - val_loss: 2.9113 - val_acc: 0.6350\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.8703 - acc: 0.6456 - val_loss: 2.8680 - val_acc: 0.6310\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.8275 - acc: 0.6465 - val_loss: 2.8252 - val_acc: 0.6380\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.7860 - acc: 0.6476 - val_loss: 2.7847 - val_acc: 0.6340\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.7459 - acc: 0.6500 - val_loss: 2.7451 - val_acc: 0.6350\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 2.7074 - acc: 0.6492 - val_loss: 2.7073 - val_acc: 0.6330\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.6704 - acc: 0.6479 - val_loss: 2.6720 - val_acc: 0.6300\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.6348 - acc: 0.6497 - val_loss: 2.6361 - val_acc: 0.6370\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 2.6005 - acc: 0.6508 - val_loss: 2.6025 - val_acc: 0.6400\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.5676 - acc: 0.6524 - val_loss: 2.5719 - val_acc: 0.6290\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.5364 - acc: 0.6492 - val_loss: 2.5394 - val_acc: 0.6430\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 2.5063 - acc: 0.6513 - val_loss: 2.5110 - val_acc: 0.6390\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 56us/step - loss: 2.4776 - acc: 0.6519 - val_loss: 2.4831 - val_acc: 0.6380\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 2.4505 - acc: 0.6532 - val_loss: 2.4562 - val_acc: 0.6340\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.4246 - acc: 0.6528 - val_loss: 2.4305 - val_acc: 0.6420\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.4001 - acc: 0.6535 - val_loss: 2.4072 - val_acc: 0.6340\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 2.3770 - acc: 0.6528 - val_loss: 2.3845 - val_acc: 0.6410\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.3551 - acc: 0.6551 - val_loss: 2.3625 - val_acc: 0.6430\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.3344 - acc: 0.6556 - val_loss: 2.3439 - val_acc: 0.6350\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.3149 - acc: 0.6543 - val_loss: 2.3245 - val_acc: 0.6380\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.2965 - acc: 0.6553 - val_loss: 2.3064 - val_acc: 0.6510\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.2792 - acc: 0.6561 - val_loss: 2.2885 - val_acc: 0.6440\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.2631 - acc: 0.6569 - val_loss: 2.2731 - val_acc: 0.6470\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 2.2482 - acc: 0.6571 - val_loss: 2.2592 - val_acc: 0.6450\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.2342 - acc: 0.6585 - val_loss: 2.2449 - val_acc: 0.6480\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.2213 - acc: 0.6576 - val_loss: 2.2321 - val_acc: 0.6560\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.2093 - acc: 0.6583 - val_loss: 2.2205 - val_acc: 0.6470\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.1983 - acc: 0.6591 - val_loss: 2.2096 - val_acc: 0.6460\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.1877 - acc: 0.6597 - val_loss: 2.1989 - val_acc: 0.6500\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.1779 - acc: 0.6591 - val_loss: 2.1897 - val_acc: 0.6460\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 2.1686 - acc: 0.6595 - val_loss: 2.1804 - val_acc: 0.6470\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 2.1599 - acc: 0.6600 - val_loss: 2.1722 - val_acc: 0.6480\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1516 - acc: 0.6611 - val_loss: 2.1635 - val_acc: 0.6450\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1435 - acc: 0.6615 - val_loss: 2.1563 - val_acc: 0.6430\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 2.1358 - acc: 0.6604 - val_loss: 2.1472 - val_acc: 0.6460\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1281 - acc: 0.6607 - val_loss: 2.1397 - val_acc: 0.6490\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1205 - acc: 0.6613 - val_loss: 2.1335 - val_acc: 0.6510\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 2.1136 - acc: 0.6615 - val_loss: 2.1252 - val_acc: 0.6530\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 2.1063 - acc: 0.6623 - val_loss: 2.1179 - val_acc: 0.6570\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 2.0996 - acc: 0.6640 - val_loss: 2.1105 - val_acc: 0.6560\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.0926 - acc: 0.6631 - val_loss: 2.1040 - val_acc: 0.6560\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.0862 - acc: 0.6636 - val_loss: 2.0977 - val_acc: 0.6550\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 2.0795 - acc: 0.6633 - val_loss: 2.0935 - val_acc: 0.6480\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.0733 - acc: 0.6648 - val_loss: 2.0851 - val_acc: 0.6550\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "L1_model.add(layers.Dense(\n",
    "    50, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=keras.regularizers.l1(.005),\n",
    "    input_shape=(2000,)))\n",
    "L1_model.add(layers.Dense(\n",
    "    25, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=keras.regularizers.l1(.005)))\n",
    "# Add another hidden layer\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=1024, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 2s 262us/step - loss: 1.9926 - acc: 0.1296 - val_loss: 1.9546 - val_acc: 0.1340\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 1s 136us/step - loss: 1.9638 - acc: 0.1408 - val_loss: 1.9417 - val_acc: 0.1540\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 1.9562 - acc: 0.1432 - val_loss: 1.9328 - val_acc: 0.1630\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 1s 182us/step - loss: 1.9421 - acc: 0.1571 - val_loss: 1.9263 - val_acc: 0.1740\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 1.9357 - acc: 0.1672 - val_loss: 1.9212 - val_acc: 0.1780\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.9306 - acc: 0.1739 - val_loss: 1.9157 - val_acc: 0.1930\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 1s 194us/step - loss: 1.9236 - acc: 0.1752 - val_loss: 1.9101 - val_acc: 0.1920\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 1s 187us/step - loss: 1.9180 - acc: 0.1868 - val_loss: 1.9045 - val_acc: 0.1990\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 1.9125 - acc: 0.1961 - val_loss: 1.8992 - val_acc: 0.2030\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.9090 - acc: 0.1875 - val_loss: 1.8929 - val_acc: 0.2090\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 1s 151us/step - loss: 1.8964 - acc: 0.2055 - val_loss: 1.8858 - val_acc: 0.2150\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 1s 178us/step - loss: 1.8910 - acc: 0.2120 - val_loss: 1.8785 - val_acc: 0.2200\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 1s 142us/step - loss: 1.8883 - acc: 0.2105 - val_loss: 1.8704 - val_acc: 0.2280\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 1s 182us/step - loss: 1.8789 - acc: 0.2208 - val_loss: 1.8614 - val_acc: 0.2340\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 1.8685 - acc: 0.2341 - val_loss: 1.8517 - val_acc: 0.2500\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 1s 125us/step - loss: 1.8616 - acc: 0.2444 - val_loss: 1.8402 - val_acc: 0.2610: 0s - loss: 1.8605 - acc: 0.24\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 1s 151us/step - loss: 1.8499 - acc: 0.2532 - val_loss: 1.8276 - val_acc: 0.2680\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 1.8402 - acc: 0.2591 - val_loss: 1.8147 - val_acc: 0.2740\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 1s 186us/step - loss: 1.8251 - acc: 0.2691 - val_loss: 1.7993 - val_acc: 0.2870\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.8227 - acc: 0.2728 - val_loss: 1.7836 - val_acc: 0.3150\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 1s 131us/step - loss: 1.8050 - acc: 0.2837 - val_loss: 1.7667 - val_acc: 0.3250\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 1s 129us/step - loss: 1.7903 - acc: 0.2913 - val_loss: 1.7478 - val_acc: 0.3430\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 1s 135us/step - loss: 1.7692 - acc: 0.3076 - val_loss: 1.7266 - val_acc: 0.3630\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 1s 136us/step - loss: 1.7584 - acc: 0.3167 - val_loss: 1.7042 - val_acc: 0.3780\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 1.7525 - acc: 0.3201 - val_loss: 1.6825 - val_acc: 0.4120\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 1.7228 - acc: 0.3307 - val_loss: 1.6567 - val_acc: 0.4310\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 1s 119us/step - loss: 1.7032 - acc: 0.3484 - val_loss: 1.6302 - val_acc: 0.4500\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 1s 118us/step - loss: 1.6967 - acc: 0.3415 - val_loss: 1.6046 - val_acc: 0.4670\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 1.6793 - acc: 0.3561 - val_loss: 1.5784 - val_acc: 0.4930\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 1s 127us/step - loss: 1.6498 - acc: 0.3673 - val_loss: 1.5518 - val_acc: 0.4960\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 1.6514 - acc: 0.3632 - val_loss: 1.5285 - val_acc: 0.4990\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 1s 118us/step - loss: 1.6264 - acc: 0.3729 - val_loss: 1.5040 - val_acc: 0.5180\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 1s 166us/step - loss: 1.6085 - acc: 0.3835 - val_loss: 1.4807 - val_acc: 0.5250\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 1s 181us/step - loss: 1.5854 - acc: 0.3993 - val_loss: 1.4534 - val_acc: 0.5440\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 1s 185us/step - loss: 1.5619 - acc: 0.4043 - val_loss: 1.4267 - val_acc: 0.5570\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 1s 138us/step - loss: 1.5488 - acc: 0.4125 - val_loss: 1.4049 - val_acc: 0.5540\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 1s 126us/step - loss: 1.5300 - acc: 0.4183 - val_loss: 1.3816 - val_acc: 0.5720\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5261 - acc: 0.4165 - val_loss: 1.3607 - val_acc: 0.5770\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 1.5026 - acc: 0.4296 - val_loss: 1.3391 - val_acc: 0.5840\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 1s 189us/step - loss: 1.4951 - acc: 0.4317 - val_loss: 1.3167 - val_acc: 0.6060\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.4797 - acc: 0.4373 - val_loss: 1.2985 - val_acc: 0.6080\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 1s 155us/step - loss: 1.4584 - acc: 0.4417 - val_loss: 1.2777 - val_acc: 0.6140\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.4435 - acc: 0.4532 - val_loss: 1.2588 - val_acc: 0.6180\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 1s 182us/step - loss: 1.4303 - acc: 0.4547 - val_loss: 1.2436 - val_acc: 0.6240\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 1s 152us/step - loss: 1.4152 - acc: 0.4643 - val_loss: 1.2263 - val_acc: 0.6310\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 1s 150us/step - loss: 1.4078 - acc: 0.4655 - val_loss: 1.2090 - val_acc: 0.6420\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 1s 121us/step - loss: 1.3900 - acc: 0.4701 - val_loss: 1.1915 - val_acc: 0.6450\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 1s 121us/step - loss: 1.3712 - acc: 0.4796 - val_loss: 1.1757 - val_acc: 0.6500\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 1s 123us/step - loss: 1.3687 - acc: 0.4816 - val_loss: 1.1617 - val_acc: 0.6500\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 1s 163us/step - loss: 1.3672 - acc: 0.4823 - val_loss: 1.1487 - val_acc: 0.6550\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 1.3323 - acc: 0.4975 - val_loss: 1.1327 - val_acc: 0.6620\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 1s 102us/step - loss: 1.3341 - acc: 0.4864 - val_loss: 1.1191 - val_acc: 0.6630\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.3235 - acc: 0.4987 - val_loss: 1.1092 - val_acc: 0.6700\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 1s 141us/step - loss: 1.3020 - acc: 0.5104 - val_loss: 1.0944 - val_acc: 0.6680\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.2963 - acc: 0.5145 - val_loss: 1.0825 - val_acc: 0.6760\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 1s 179us/step - loss: 1.2848 - acc: 0.5179 - val_loss: 1.0673 - val_acc: 0.6740\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 1s 183us/step - loss: 1.2906 - acc: 0.5073 - val_loss: 1.0582 - val_acc: 0.6790\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 1.2738 - acc: 0.5236 - val_loss: 1.0479 - val_acc: 0.6830\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 1.2709 - acc: 0.5224 - val_loss: 1.0359 - val_acc: 0.6870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.2569 - acc: 0.5231 - val_loss: 1.0244 - val_acc: 0.6880\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 161us/step - loss: 1.2503 - acc: 0.5265 - val_loss: 1.0168 - val_acc: 0.6910\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 1s 150us/step - loss: 1.2313 - acc: 0.5339 - val_loss: 1.0081 - val_acc: 0.6910\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 1s 151us/step - loss: 1.2245 - acc: 0.5401 - val_loss: 0.9943 - val_acc: 0.6930\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 1s 127us/step - loss: 1.2208 - acc: 0.5439 - val_loss: 0.9883 - val_acc: 0.6970\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 1s 154us/step - loss: 1.1957 - acc: 0.5524 - val_loss: 0.9772 - val_acc: 0.6970\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 1s 145us/step - loss: 1.1897 - acc: 0.5504 - val_loss: 0.9664 - val_acc: 0.6970\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 1s 102us/step - loss: 1.1932 - acc: 0.5521 - val_loss: 0.9574 - val_acc: 0.7040\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 1s 102us/step - loss: 1.1883 - acc: 0.5557 - val_loss: 0.9495 - val_acc: 0.7030\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 1.1708 - acc: 0.5579 - val_loss: 0.9423 - val_acc: 0.7040\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 1.1549 - acc: 0.5619 - val_loss: 0.9314 - val_acc: 0.7020\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 1.1551 - acc: 0.5735 - val_loss: 0.9218 - val_acc: 0.7080\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 1.1538 - acc: 0.5669 - val_loss: 0.9194 - val_acc: 0.7060\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 1s 100us/step - loss: 1.1519 - acc: 0.5693 - val_loss: 0.9117 - val_acc: 0.7120\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 1s 98us/step - loss: 1.1366 - acc: 0.5799 - val_loss: 0.9042 - val_acc: 0.7110\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.1298 - acc: 0.5781 - val_loss: 0.8954 - val_acc: 0.7120\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 1s 159us/step - loss: 1.1235 - acc: 0.5780 - val_loss: 0.8921 - val_acc: 0.7080\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.1359 - acc: 0.5751 - val_loss: 0.8889 - val_acc: 0.7090\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.1205 - acc: 0.5808 - val_loss: 0.8783 - val_acc: 0.7100\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 1s 135us/step - loss: 1.0920 - acc: 0.5923 - val_loss: 0.8700 - val_acc: 0.7160\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 1s 166us/step - loss: 1.1065 - acc: 0.5937 - val_loss: 0.8686 - val_acc: 0.7120\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 1s 122us/step - loss: 1.1070 - acc: 0.5907 - val_loss: 0.8661 - val_acc: 0.7190\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 1s 144us/step - loss: 1.0955 - acc: 0.5893 - val_loss: 0.8579 - val_acc: 0.7180\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 1.0929 - acc: 0.5936 - val_loss: 0.8506 - val_acc: 0.7190\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 1.0983 - acc: 0.5909 - val_loss: 0.8497 - val_acc: 0.7260\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 1s 107us/step - loss: 1.0793 - acc: 0.5969 - val_loss: 0.8400 - val_acc: 0.7220\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 1.0666 - acc: 0.6031 - val_loss: 0.8358 - val_acc: 0.7230\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 1s 150us/step - loss: 1.0562 - acc: 0.6128 - val_loss: 0.8333 - val_acc: 0.7250\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 1.0592 - acc: 0.6080 - val_loss: 0.8292 - val_acc: 0.7250\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 1.0459 - acc: 0.6176 - val_loss: 0.8203 - val_acc: 0.7270\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 1.0449 - acc: 0.6133 - val_loss: 0.8180 - val_acc: 0.7270\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 1s 111us/step - loss: 1.0405 - acc: 0.6144 - val_loss: 0.8140 - val_acc: 0.7220\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 1s 113us/step - loss: 1.0314 - acc: 0.6223 - val_loss: 0.8102 - val_acc: 0.7280\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 1s 112us/step - loss: 1.0290 - acc: 0.6223 - val_loss: 0.8006 - val_acc: 0.7300\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 1s 134us/step - loss: 1.0198 - acc: 0.6217 - val_loss: 0.7990 - val_acc: 0.7280\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 1s 151us/step - loss: 1.0320 - acc: 0.6177 - val_loss: 0.7948 - val_acc: 0.7280\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 1.0285 - acc: 0.6187 - val_loss: 0.7931 - val_acc: 0.7290\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 1s 178us/step - loss: 1.0169 - acc: 0.6261 - val_loss: 0.7897 - val_acc: 0.7270\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 1s 149us/step - loss: 1.0171 - acc: 0.6181 - val_loss: 0.7834 - val_acc: 0.7330\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 1s 153us/step - loss: 1.0112 - acc: 0.6241 - val_loss: 0.7815 - val_acc: 0.7330\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.9972 - acc: 0.6300 - val_loss: 0.7778 - val_acc: 0.7320\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.0078 - acc: 0.621 - 1s 112us/step - loss: 1.0082 - acc: 0.6209 - val_loss: 0.7755 - val_acc: 0.7320\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 0.9875 - acc: 0.6347 - val_loss: 0.7719 - val_acc: 0.7290\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 1.0054 - acc: 0.6241 - val_loss: 0.7700 - val_acc: 0.7300\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 1s 113us/step - loss: 0.9939 - acc: 0.6317 - val_loss: 0.7625 - val_acc: 0.7340\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 1s 134us/step - loss: 0.9940 - acc: 0.6311 - val_loss: 0.7633 - val_acc: 0.7340\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 1s 167us/step - loss: 0.9828 - acc: 0.6377 - val_loss: 0.7598 - val_acc: 0.7330\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 0.9829 - acc: 0.6407 - val_loss: 0.7582 - val_acc: 0.7340\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 1s 163us/step - loss: 0.9703 - acc: 0.6417 - val_loss: 0.7530 - val_acc: 0.7330\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 1s 162us/step - loss: 0.9862 - acc: 0.6399 - val_loss: 0.7489 - val_acc: 0.7360\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 0.9588 - acc: 0.6433 - val_loss: 0.7469 - val_acc: 0.7310\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 0.9627 - acc: 0.6351 - val_loss: 0.7439 - val_acc: 0.7360\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 1s 132us/step - loss: 0.9617 - acc: 0.6381 - val_loss: 0.7433 - val_acc: 0.7330\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 1s 123us/step - loss: 0.9563 - acc: 0.6455 - val_loss: 0.7391 - val_acc: 0.7370\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 1s 115us/step - loss: 0.9569 - acc: 0.6487 - val_loss: 0.7394 - val_acc: 0.7310\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 1s 128us/step - loss: 0.9477 - acc: 0.6475 - val_loss: 0.7357 - val_acc: 0.7330\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 1s 189us/step - loss: 0.9411 - acc: 0.6559 - val_loss: 0.7324 - val_acc: 0.7330\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 0.9356 - acc: 0.6536 - val_loss: 0.7297 - val_acc: 0.7320\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 1s 164us/step - loss: 0.9511 - acc: 0.6471 - val_loss: 0.7260 - val_acc: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 1s 181us/step - loss: 0.9402 - acc: 0.6564 - val_loss: 0.7239 - val_acc: 0.7370\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 1s 178us/step - loss: 0.9259 - acc: 0.6573 - val_loss: 0.7202 - val_acc: 0.7410\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 1s 140us/step - loss: 0.9277 - acc: 0.6547 - val_loss: 0.7193 - val_acc: 0.7360\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 1s 138us/step - loss: 0.9365 - acc: 0.6483 - val_loss: 0.7182 - val_acc: 0.7400ss: 0.9422 - acc: 0.6\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 1s 124us/step - loss: 0.9264 - acc: 0.6567 - val_loss: 0.7145 - val_acc: 0.7360\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 1s 143us/step - loss: 0.9320 - acc: 0.6569 - val_loss: 0.7158 - val_acc: 0.7340\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 1s 138us/step - loss: 0.9266 - acc: 0.6632 - val_loss: 0.7147 - val_acc: 0.7370\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 1s 188us/step - loss: 0.9134 - acc: 0.6639 - val_loss: 0.7086 - val_acc: 0.7430\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 1s 164us/step - loss: 0.9145 - acc: 0.6660 - val_loss: 0.7070 - val_acc: 0.7400\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 1s 161us/step - loss: 0.9216 - acc: 0.6641 - val_loss: 0.7064 - val_acc: 0.7390\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 1s 182us/step - loss: 0.9012 - acc: 0.6643 - val_loss: 0.7043 - val_acc: 0.7390\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 0.9133 - acc: 0.6611 - val_loss: 0.7004 - val_acc: 0.7410\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 0.8863 - acc: 0.6781 - val_loss: 0.6984 - val_acc: 0.7380\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 1s 142us/step - loss: 0.8976 - acc: 0.6713 - val_loss: 0.6961 - val_acc: 0.7400\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 1s 160us/step - loss: 0.8970 - acc: 0.6719 - val_loss: 0.6968 - val_acc: 0.7440\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 1s 142us/step - loss: 0.9048 - acc: 0.6663 - val_loss: 0.6950 - val_acc: 0.7400\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 1s 147us/step - loss: 0.8855 - acc: 0.6748 - val_loss: 0.6933 - val_acc: 0.7410\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 1s 120us/step - loss: 0.8937 - acc: 0.6664 - val_loss: 0.6897 - val_acc: 0.7470\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 1s 126us/step - loss: 0.8939 - acc: 0.6671 - val_loss: 0.6882 - val_acc: 0.7460\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 1s 128us/step - loss: 0.8782 - acc: 0.6747 - val_loss: 0.6865 - val_acc: 0.7450\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 1s 138us/step - loss: 0.8905 - acc: 0.6653 - val_loss: 0.6881 - val_acc: 0.7430\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 0.8793 - acc: 0.6736 - val_loss: 0.6883 - val_acc: 0.7450\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 1s 129us/step - loss: 0.8894 - acc: 0.6647 - val_loss: 0.6844 - val_acc: 0.7440\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 1s 191us/step - loss: 0.8656 - acc: 0.6833 - val_loss: 0.6807 - val_acc: 0.7440\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 0.8707 - acc: 0.6803 - val_loss: 0.6779 - val_acc: 0.7490\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 0.8762 - acc: 0.6757 - val_loss: 0.6757 - val_acc: 0.7480\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 1s 128us/step - loss: 0.8661 - acc: 0.6833 - val_loss: 0.6763 - val_acc: 0.7460\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 1s 123us/step - loss: 0.8610 - acc: 0.6828 - val_loss: 0.6740 - val_acc: 0.7510\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 1s 163us/step - loss: 0.8674 - acc: 0.6796 - val_loss: 0.6743 - val_acc: 0.7470\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 1s 148us/step - loss: 0.8506 - acc: 0.6796 - val_loss: 0.6720 - val_acc: 0.7440\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 1s 114us/step - loss: 0.8418 - acc: 0.6871 - val_loss: 0.6687 - val_acc: 0.7430\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 1s 145us/step - loss: 0.8561 - acc: 0.6812 - val_loss: 0.6658 - val_acc: 0.7440\n"
     ]
    }
   ],
   "source": [
    "# â° This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(.3, input_shape=(2000,)))\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "dropout_model.add(layers.Dropout(.3))\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "dropout_model.add(layers.Dropout(.3))\n",
    "# Add another hidden layer\n",
    "\n",
    "\n",
    "# Add the first hidden layer\n",
    "\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "\n",
    "\n",
    "# Add the second hidden layer\n",
    "\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s 153us/step\n",
      "Training Loss: 0.565 \n",
      "Training Accuracy: 0.804\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 130us/step\n",
      "Test Loss: 0.626 \n",
      "Test Accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9100 - acc: 0.2145 - val_loss: 1.8558 - val_acc: 0.2750\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.7574 - acc: 0.3558 - val_loss: 1.6459 - val_acc: 0.4365\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.4852 - acc: 0.5178 - val_loss: 1.3418 - val_acc: 0.5715\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 1.1863 - acc: 0.6329 - val_loss: 1.0795 - val_acc: 0.6550\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.9719 - acc: 0.6869 - val_loss: 0.9175 - val_acc: 0.6917\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.8451 - acc: 0.7137 - val_loss: 0.8233 - val_acc: 0.7107\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.7679 - acc: 0.7318 - val_loss: 0.7625 - val_acc: 0.7287\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.7168 - acc: 0.7439 - val_loss: 0.7242 - val_acc: 0.7347\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.6802 - acc: 0.7552 - val_loss: 0.6935 - val_acc: 0.7442\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.6523 - acc: 0.7624 - val_loss: 0.6707 - val_acc: 0.7515\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.6300 - acc: 0.7694 - val_loss: 0.6550 - val_acc: 0.7550\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.6119 - acc: 0.7763 - val_loss: 0.6411 - val_acc: 0.7615\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5963 - acc: 0.7824 - val_loss: 0.6301 - val_acc: 0.7670\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.5824 - acc: 0.7871 - val_loss: 0.6182 - val_acc: 0.7670\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5706 - acc: 0.7930 - val_loss: 0.6118 - val_acc: 0.7747\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5597 - acc: 0.7954 - val_loss: 0.6020 - val_acc: 0.7715\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 0.5502 - acc: 0.8008 - val_loss: 0.5964 - val_acc: 0.7800\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5410 - acc: 0.8039 - val_loss: 0.5916 - val_acc: 0.7815\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 0.5327 - acc: 0.8071 - val_loss: 0.5855 - val_acc: 0.7822\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5252 - acc: 0.8100 - val_loss: 0.5843 - val_acc: 0.7840\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5182 - acc: 0.8134 - val_loss: 0.5764 - val_acc: 0.7853\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.5117 - acc: 0.8151 - val_loss: 0.5720 - val_acc: 0.7883\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.5051 - acc: 0.8182 - val_loss: 0.5673 - val_acc: 0.7897\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4994 - acc: 0.8205 - val_loss: 0.5656 - val_acc: 0.7900\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.4938 - acc: 0.8228 - val_loss: 0.5634 - val_acc: 0.7933\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4886 - acc: 0.8237 - val_loss: 0.5581 - val_acc: 0.7952\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4836 - acc: 0.8267 - val_loss: 0.5563 - val_acc: 0.7975\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4789 - acc: 0.8290 - val_loss: 0.5546 - val_acc: 0.7952\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4746 - acc: 0.8297 - val_loss: 0.5550 - val_acc: 0.7995\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.4704 - acc: 0.8321 - val_loss: 0.5518 - val_acc: 0.7997\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 0.4666 - acc: 0.8335 - val_loss: 0.5530 - val_acc: 0.7977\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4623 - acc: 0.8354 - val_loss: 0.5495 - val_acc: 0.8025\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4588 - acc: 0.8377 - val_loss: 0.5520 - val_acc: 0.7983\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4552 - acc: 0.8385 - val_loss: 0.5446 - val_acc: 0.8027\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4514 - acc: 0.8391 - val_loss: 0.5433 - val_acc: 0.8048\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.4484 - acc: 0.8410 - val_loss: 0.5464 - val_acc: 0.8025\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4452 - acc: 0.8417 - val_loss: 0.5429 - val_acc: 0.8065\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.4420 - acc: 0.8441 - val_loss: 0.5404 - val_acc: 0.8050\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4393 - acc: 0.8447 - val_loss: 0.5425 - val_acc: 0.8027\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.4365 - acc: 0.8454 - val_loss: 0.5393 - val_acc: 0.8048\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.4334 - acc: 0.8464 - val_loss: 0.5377 - val_acc: 0.8070\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.4310 - acc: 0.8480 - val_loss: 0.5383 - val_acc: 0.8077\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4284 - acc: 0.8486 - val_loss: 0.5362 - val_acc: 0.8052\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4260 - acc: 0.8493 - val_loss: 0.5360 - val_acc: 0.8075\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4231 - acc: 0.8505 - val_loss: 0.5361 - val_acc: 0.8090\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4209 - acc: 0.8510 - val_loss: 0.5365 - val_acc: 0.8077\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.4185 - acc: 0.8528 - val_loss: 0.5394 - val_acc: 0.8083\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.4163 - acc: 0.8541 - val_loss: 0.5384 - val_acc: 0.8058\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.4142 - acc: 0.8544 - val_loss: 0.5341 - val_acc: 0.8083\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4122 - acc: 0.8554 - val_loss: 0.5334 - val_acc: 0.8105\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 0.4100 - acc: 0.8558 - val_loss: 0.5341 - val_acc: 0.8133\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.4080 - acc: 0.8571 - val_loss: 0.5357 - val_acc: 0.8043\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.4057 - acc: 0.8577 - val_loss: 0.5344 - val_acc: 0.8123\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.4036 - acc: 0.8582 - val_loss: 0.5342 - val_acc: 0.8087\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4022 - acc: 0.8583 - val_loss: 0.5351 - val_acc: 0.8098\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4002 - acc: 0.8595 - val_loss: 0.5389 - val_acc: 0.8045\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.3986 - acc: 0.8601 - val_loss: 0.5390 - val_acc: 0.8112\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 0.3969 - acc: 0.8610 - val_loss: 0.5384 - val_acc: 0.8083\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.3951 - acc: 0.8621 - val_loss: 0.5409 - val_acc: 0.8065\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 0.3934 - acc: 0.8619 - val_loss: 0.5354 - val_acc: 0.8115\n"
     ]
    }
   ],
   "source": [
    "# â° This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['acc'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger),\n",
    "                                              callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 118us/step\n",
      "Training Loss: 0.407 \n",
      "Training Accuracy: 0.857\n",
      "----------\n",
      "4000/4000 [==============================] - 1s 148us/step\n",
      "Test Loss: 0.533 \n",
      "Test Accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
